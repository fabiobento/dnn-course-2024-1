{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório Prático: Regressão Linear\n",
    "\n",
    "Bem-vindo ao seu primeiro laboratório prático! Neste laboratório, você implementará a regressão linear com uma variável para prever os lucros de uma franquia de restaurantes.\n",
    "\n",
    "\n",
    "# Tópicos\n",
    "- [ 1 - Pacotes ](#1)\n",
    "- [ 2 - Regressão Linear com uma variável ](#2)\n",
    "  - [ 2.1 Definição do problema](#2.1)\n",
    "  - [ 2.2  Conjunto de Dados](#2.2)\n",
    "  - [ 2.3 Revisão em Regressão Linear](#2.3)\n",
    "  - [ 2.4  Cálculo do custo](#2.4)\n",
    "    - [ Exercício 1](#ex01)\n",
    "  - [ 2.5 Gradiente Descendente ](#2.5)\n",
    "    - [ Exercício 2](#ex02)\n",
    "  - [ 2.6 Aprendendo os parâmetros utilizando gradiente descedente em lote (_batch gradient descent_) ](#2.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/ml_intro/class_02/5%20-%20Atividade%20Avaliativa%20-%20Regress%C3%A3o%20Linear/lab_utils_ml_intro_assig_week_2.zip\n",
    "!unzip -n -q lab_utils_ml_intro_assig_week_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 - Pacotes \n",
    "\n",
    "Primeiro, vamos executar a célula abaixo para importar todos os pacotes de que você precisará durante esta tarefa.\n",
    "- [numpy](www.numpy.org) é um pacote fundamental para trabalhar com matrizes em Python.\n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca famosa para plotar gráficos em Python.\n",
    "- ``utils.py`` contém funções auxiliares para este caderno. Não é necessário modificar o código desse arquivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "# 2 - Regressão Linear com uma variável "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.1\"></a>\n",
    "## 2.1 -  Definição do problema\n",
    "Suponha que você seja o CEO de uma franquia de restaurantes e esteja considerando diferentes cidades para abrir um novo ponto de venda.\n",
    "- Você gostaria de expandir seus negócios para cidades que possam proporcionar lucros maiores ao seu restaurante.\n",
    "- A rede já tem restaurantes em várias cidades e você tem dados sobre os lucros e a população dessas cidades.\n",
    "- Você também tem dados sobre cidades que são candidatas a um novo restaurante. \n",
    "    - Para essas cidades, você tem a população da cidade.\n",
    "\n",
    "Você pode usar os dados para ajudá-lo a identificar quais cidades podem potencialmente proporcionar maiores lucros à sua empresa?\n",
    "<a name=\"2.2\"></a>\n",
    "## 2.2 - Conjunto de Dados\n",
    "\n",
    "Você começará carregando o conjunto de dados para essa tarefa.\n",
    "- A função`load_data()` abaixo carrega os dados nas variáveis `x_train` e `y_train`\n",
    "  - `x_train` é a população da cidade\n",
    "  - `y_train` é o lucro do restaurante naquela cidade. um valor negativo para o lucro indica um prejuízo.   \n",
    "  - `x_train` e `y_train` são _numpy arrays_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados\n",
    "x_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize as variáveis\n",
    "Antes de iniciar qualquer tarefa em aprendizado de máquina, é útil se familiarizar mais com seu conjunto de dados.  \n",
    "- Um bom ponto de partida é simplesmente imprimir cada variável e ver o que ela contém.\n",
    "\n",
    "O código abaixo imprime a variável `x_train` e o tipo da variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Imprimir x_train\n",
    "print(\"Tipo de x_train:\",type(x_train))\n",
    "print(\"Os primeiros cinco elementos de x_train são:\\n\", x_train[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_train` é um _numpy array_ que contém valores decimais que são todos maiores que zero.\n",
    "- Esses valores representam os valores das popuilações da cidade vezes 10.000\n",
    "- Por exemplo, 6,1101 significa que a população dessa cidade é de 61.101 pessoas\n",
    "  \n",
    "Agora, vamos imprimir `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# imprimir y_train\n",
    "print(\"Tipo de y_train:\",type(y_train))\n",
    "print(\"Os primeiros cinco elementos de y_train são:\\n\", y_train[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, `y_train` é um _numpy array_ que tem valores decimais, alguns negativos, outros positivos.\n",
    "- Eles representam os lucros médios mensais de seu restaurante em cada cidade, em unidades de \\$10.000.\n",
    "  - Por exemplo, 17,592 representa \\$175.920 em lucros mensais médios para essa cidade.\n",
    "  -2,6807 representa -\\$26.807 de perda média mensal para aquela cidade.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifique as dimensões de suas variáveis\n",
    "\n",
    "Outra maneira útil de se familiarizar com seus dados é visualizar suas dimensões.\n",
    "\n",
    "Imprima a forma de `x_train` e `y_train` e veja quantos exemplos de treinamento você tem em seu conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O formato de x_train é:', x_train.shape)\n",
    "print ('O formato de y_train é: ', y_train.shape)\n",
    "print ('Quantidade de exemplos de treinamento (m):', len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O _numpy array_ de população da cidade tem 97 pontos de dados e a média mensal de lucros também tem 97 pontos de dados. Essas são matrizes NumPy 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize seus dados\n",
    "\n",
    "Muitas vezes é útil entender os dados visualizando-os. \n",
    "- Para esse conjunto de dados, você pode usar um gráfico de dispersão para visualizar os dados, já que ele tem apenas duas propriedades a serem plotadas (lucro e população). \n",
    "- Muitos outros problemas que você encontrará na vida real têm mais de duas propriedades (por exemplo, população, renda familiar média, lucros mensais, vendas mensais). Quando você tem mais de duas propriedades, ainda pode usar um gráfico de dispersão para ver a relação entre cada par de propriedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Crie um gráfico de dispersão dos dados. Para alterar os marcadores para \"x\" vermelho,\n",
    "# usamos os parâmetros 'marker' e 'c'\n",
    "plt.scatter(x_train, y_train, marker='x', c='r') \n",
    "\n",
    "# Defina o título\n",
    "plt.title(\"Lucros vs. População por Cidade\")\n",
    "# Defina o rótulo do eixo y\n",
    "plt.ylabel('Lucro em $10,000')\n",
    "# Defina o rótulo do eixo x\n",
    "plt.xlabel('População da cidade em 10,000s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu objetivo é criar um modelo de regressão linear para ajustar esses dados.\n",
    "- Com esse modelo, você pode inserir a população de uma nova cidade e fazer com que o modelo estime os possíveis lucros mensais do seu restaurante para essa cidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "## 2.3 - Revisão de Regressão Linear\n",
    "\n",
    "Nesse laboratório prático, você irá ajustar os parâmetros de regressão linear $(w,b)$ ao seu conjunto de dados.\n",
    "- A função do modelo para regressão linear, que é uma função que mapeia de `x` (população da cidade) para `y` (o lucro mensal de seu restaurante naquela cidade) é representada como\n",
    "    $$f_{w,b}(x) = wx + b$$\n",
    "    \n",
    "\n",
    "- Para treinar um modelo de regressão linear, você deseja encontrar os melhores parâmetros $(w,b)$ que se ajustem ao seu conjunto de dados.\n",
    "\n",
    "    - Para comparar como uma escolha de $(w,b)$ é melhor ou pior que outra escolha, você pode avaliá-la com uma função de custo J(w,b)$\n",
    "      - $J$ é uma função de $(w,b)$. Isso é, o valo do custo $J(w,b)$ depende do valor de $(w,b)$.\n",
    "  \n",
    "    - A escolha de $(w,b)$ que melhor se ajusta a seus dados é aquele que tem o menor custo $J(w,b)$.\n",
    "\n",
    "- Para encontrar os valores $(w,b)$ que obtêm o menor custo possível $J(w,b)$, você pode usar um método chamado gradiente descendente (**gradient descent**). \n",
    "  - A cada etapa da descida do gradiente, seus parâmetros $(w,b)$ se aproximam dos valores ideais que atingirão o menor custo $J(w,b)$.\n",
    "  \n",
    "\n",
    "- O modelo de regressão linear treinado pode, então, pegar o recurso de entrada $x$ (população da cidade) e gerar uma previsão $f_{w,b}(x)$ (lucro mensal previsto para um restaurante naquela cidade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "## 2.4 - Cálculo do custo\n",
    "\n",
    "A descida gradiente envolve etapas repetidas para ajustar o valor do seu parâmetro $(w,b)$ para obter gradualmente um custo cada vez menor $J(w,b)$.\n",
    "- Em cada etapa da descida do gradiente, será útil monitorar seu progresso calculando o custo $J(w,b)$ à medida que $(w,b)$ for atualizado. \n",
    "- Nesta seção, você implementará uma função para calcular $J(w,b)$ de modo que possa verificar o progresso da implementação da descida gradiente.\n",
    "\n",
    "\n",
    "#### Função de custo\n",
    "Como você deve se lembrar da aula, para uma variável, a função de custo da regressão linear $J(w,b)$ é definida como\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$ \n",
    "\n",
    "- Você pode pensar em $f_{w,b}(x^{(i)})$ como a previsão do modelo do lucro do seu restaurante, em oposição a $y^{(i)}$, que é o lucro real registrado nos dados.\n",
    "- $m$ é o número de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "\n",
    "#### Predição do modelo\n",
    "\n",
    "- Para regressão linear com uma variável, a previsão do modelo $f_{w,b}$ para um exemplo $x^{(i)}$ é representada como:\n",
    "\n",
    "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n",
    "\n",
    "Esta é a equação de uma reta, com uma interceptação $b$ e uma inclinação $w$\n",
    "\n",
    "#### Implementação\n",
    "\n",
    "Preencha a função `compute_cost()` abaixo para calcular o custo $J(w,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercício 1\n",
    "\n",
    "Complete a função `compute_cost` abaixo:\n",
    "\n",
    "* Iterar sobre os exemplos de treinamento e, para cada exemplo, calcular:\n",
    "    * A previsão do modelo para esse exemplo\n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  wx^{(i)} + b \n",
    "    $$\n",
    "   \n",
    "    * O custo para esse exemplo $$cost^{(i)} =  (f_{wb} - y^{(i)})^2$$\n",
    "    \n",
    "\n",
    "* Retorne o custo total sobre todos os exemplos\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} cost^{(i)}$$\n",
    "  * Aqui, $m$ é o número de exemplos de treinamento e $\\sum$ é o operador de soma\n",
    "\n",
    "Se tiver dúvidas, você pode conferir as dicas apresentadas após a célula abaixo para ajudá-lo com a implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_cost(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Calcula a função de custo para regressão linear.\n",
    "    \n",
    "    Args:\n",
    "        x (ndarray): Formato (m,) Entrada pra o modelo (População das cidades) \n",
    "        y (ndarray): Formato (m,) Valores alvo (Lucro real por cidade)\n",
    "        w, b (scalar): Parâmetros do modelo\n",
    "    \n",
    "    Returns\n",
    "        total_cost (float): O custo de usar w,b como parâmetros para a regressão linear\n",
    "               para ajustar os pontos de dados em x e y\n",
    "    \"\"\"\n",
    "    # quantidade de exemplos de treino\n",
    "    m = x.shape[0] \n",
    "    \n",
    "    # você precisa retornar essa variável corretamente\n",
    "    total_cost = 0\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click aqui para dicas</b></font></summary>\n",
    "   \n",
    "   * Você pode representar um operador de soma, por exemplo: $h = \\sum\\limits_{i = 0}^{m-1} 2i$ no seguinte código:\n",
    "    \n",
    "    ```python \n",
    "    h = 0\n",
    "    for i in range(m):\n",
    "        h = h + 2*i\n",
    "    ```\n",
    "  \n",
    "   * Nesse caso, você pode iterar sobre todos os exemplos em `x` usando um loop for e adicionar o `cost` de cada iteração a uma variável (`cost_sum`) inicializada fora do loop.\n",
    "\n",
    "   * Em seguida, você pode retornar o `total_cost` como `cost_sum` dividido por `2m`.\n",
    "   * Se você for novato em Python, verifique se o código está devidamente recuado com espaços ou tabulações consistentes.\n",
    "   \n",
    "   Caso contrário, ele poderá produzir uma saída diferente ou gerar um erro `IndentationError: unexpected indent`. Você pode consultar [esse tópico](https://community.deeplearning.ai/t/indentation-in-python-indentationerror-unexpected-indent/159398) in our community for details.\n",
    "   \n",
    "\n",
    "<details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b> Click para mais dicas</b></font></summary>\n",
    "        \n",
    "    * Veja como você pode estruturar a implementação geral dessa função\n",
    "    \n",
    "    ```python \n",
    "    def compute_cost(x, y, w, b):\n",
    "        # quantidade de exemplos de treino\n",
    "        m = x.shape[0] \n",
    "    \n",
    "        # Você precisa retornar essa variável corretamente\n",
    "        total_cost = 0\n",
    "    \n",
    "        ### INICIE SEU CÓDIGO AQUI ###\n",
    "        # Variável para manter o controle da soma do custo de cada exemplo\n",
    "        cost_sum = 0\n",
    "    \n",
    "        # Fazer um loop sobre os exemplos de treinamento\n",
    "        for i in range(m):\n",
    "            # Seu código aqui para obter a previsão f_wb para o i-ésimo exemplo            \n",
    "            f_wb = \n",
    "            # Seu código aqui para obter o custo associado ao i-ésimo exemplo            \n",
    "            cost = \n",
    "        \n",
    "            # Adicionar à soma do custo de cada exemplo\n",
    "            cost_sum = cost_sum + cost \n",
    "\n",
    "        # Obtenha o custo total como a soma dividida por (2*m)\n",
    "        total_cost = (1 / (2 * m)) * cost_sum\n",
    "        ### TERMINE SEU CÓDIGO AQUI ###\n",
    "\n",
    "        return total_cost\n",
    "    ```\n",
    "    \n",
    "    * Se ainda estiver com dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular `f_wb` e `cost`.\n",
    "    \n",
    "<details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Para os escalares  $a$, $b$ e $c$ (<code>x[i]</code>, <code>w</code> e <code>b</code> são todos escalares), você pode calcular a equação $h = ab + c$ no código como <code>h = a * b + c</code>\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f</b></font></summary>\n",
    "               &emsp; &emsp; Você pode calcular f_wb as <code>f_wb = w * x[i] + b </code>\n",
    "           </details>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular o custo</b></font></summary>\n",
    "          &emsp; &emsp; Você pode calcular o quadrado da variável z  como z**2\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular o custo</b></font></summary>\n",
    "              &emsp; &emsp; Você pode calcular com  <code>cost = (f_wb - y[i]) ** 2</code>\n",
    "          </details>\n",
    "    </details>\n",
    "        \n",
    "</details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode verificar se sua implementação está correta executando o seguinte código de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Calcular o custo com alguns valores iniciais para os parâmetros w, b\n",
    "initial_w = 2\n",
    "initial_b = 1\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print(type(cost))\n",
    "print(f'Custo com o w inicial: {cost:.3f}')\n",
    "\n",
    "# Testes públicos\n",
    "from public_tests import *\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo com o w inicial:<b> 75.203 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.5\"></a>\n",
    "## 2.5 - Gradiente Descendente\n",
    "\n",
    "Nesta seção, você implementará o gradiente para os parâmetros $w, b$ para regressão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme descrito na aula, o algoritmo de descida de gradiente é:\n",
    "\n",
    "$$\\begin{align*}& \\text{repetir até a convergência:} \\; \\lbrace \\newline \\; & \\phantom {0000} b := b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\newline       \\; & \\phantom {0000} w := w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{1}  \\; & \n",
    "\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "onde os parâmetros $w, b$ são atualizados simultaneamente e onde\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \\tag{3}\n",
    "$$\n",
    "\n",
    "* m é o número de exemplos de treinamento no conjunto de dados\n",
    "    \n",
    "*  $f_{w,b}(x^{(i)})$ é a predição do modelo, enquanto $y^{(i)}$, é o valor alvo\n",
    "\n",
    "\n",
    "Você implementará a função chamada `compute_gradient` que calcula $\\frac{\\partial J(w)}{\\partial w}$, $\\frac{\\partial J(w)}{\\partial b}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercício 2\n",
    "\n",
    "Complete a função `compute_gradient` para:\n",
    "\n",
    "* Iterar sobre os exemplos de treinamento e, para cada exemplo, calcular:\n",
    "    * A previsão do modelo para o exemplo $i$\n",
    "\n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  wx^{(i)} + b \n",
    "    $$\n",
    "   \n",
    "    * O gradiente para os parâmetros $w, b$ para esse exemplo\n",
    "        $$\n",
    "        \\frac{\\partial J(w,b)}{\\partial b}^{(i)}  =  (f_{w,b}(x^{(i)}) - y^{(i)}) \n",
    "        $$\n",
    "        $$\n",
    "        \\frac{\\partial J(w,b)}{\\partial w}^{(i)}  =  (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \n",
    "        $$\n",
    "    \n",
    "\n",
    "* Retorna a atualização do gradiente total de todos os exemplos\n",
    "    $$\n",
    "    \\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} \\frac{\\partial J(w,b)}{\\partial b}^{(i)}\n",
    "    $$\n",
    "    \n",
    "    $$\n",
    "    \\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} \\frac{\\partial J(w,b)}{\\partial w}^{(i)} \n",
    "    $$\n",
    "  * Aqui, $m$ é o número de exemplos de treinamento e $\\sum$ é o operador de soma  \n",
    "\n",
    "Se tiver dúvidas, você pode consultar as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Calcula o gradiente para regressão linear\n",
    "    Args:\n",
    "      x (ndarray): Formato (m,) Entrada para o Modelo (Populaçao das cidades) \n",
    "      y (ndarray): Formato (m,) Valores Alvo (Lucro real para as cidades)\n",
    "      w, b (scalar): Parâmetros do modelo  \n",
    "    Returns\n",
    "      dj_dw (scalar): O gradiente do custo em relação aos parâmetros w\n",
    "      dj_db (scalar): O gradiente do custo em relação ao parâmetro b\n",
    "     \"\"\"\n",
    "    \n",
    "    # Número de exemplos de treinamento\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # Você precisa retornar as seguintes variáveis corretamente\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "        \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click aqui para dicas</b></font></summary>\n",
    "    \n",
    "   * Você pode representar um operador de soma, por exemplo: $h = \\sum\\limits_{i = 0}^{m-1} 2i$ com o seguinte código:\n",
    "    \n",
    "   ```python \n",
    "    h = 0\n",
    "    for i in range(m):\n",
    "        h = h + 2*i\n",
    "   ```\n",
    "  * Nesse caso, você pode iterar todos os exemplos em `x` usando um loop for e, para cada exemplo, continuar adicionando o gradiente desse exemplo às variáveis `dj_dw` e `dj_db`, que são inicializadas fora do loop.\n",
    "\n",
    "   * Então, você pode retornar `dj_dw` e `dj_db`, ambos divididos por `m`.    \n",
    "<details>\n",
    "      <summary><font size=\"2\" color=\"darkblue\"><b> Click aqui para mais dicas</b></font></summary>\n",
    "        \n",
    "    * Veja como você pode estruturar a implementação geral dessa função\n",
    "    \n",
    "    ```python \n",
    "    def compute_gradient(x, y, w, b): \n",
    "        \"\"\"\n",
    "        Calcula o gradiente para regressão linear\n",
    "        Args:\n",
    "          x (ndarray): Formato (m,) Entrada para o Modelo (Populaçao das cidades) \n",
    "          y (ndarray): Formato (m,) Valores Alvo (Lucro real para as cidades)\n",
    "          w, b (scalar): Parâmetros do modelo  \n",
    "        Returns\n",
    "          dj_dw (scalar): O gradiente do custo em relação aos parâmetros w\n",
    "          dj_db (scalar): O gradiente do custo em relação ao parâmetro b\n",
    "        \"\"\"\n",
    "        # Número de exemplos de treinamento\n",
    "        m = x.shape[0]\n",
    "    \n",
    "        # Você precisa retornar as seguintes variáveis corretamente\n",
    "        dj_dw = 0\n",
    "        dj_db = 0\n",
    "    \n",
    "        ### INICIE SEU CÓDIGO AQUI ###\n",
    "        # Faça um loop pelos exemplos\n",
    "        for i in range(m):  \n",
    "            # Seu código aqui para obter a previsão f_wb para o i-ésimo exemplo\n",
    "            f_wb = \n",
    "            \n",
    "            # Seu código aqui para obter o gradiente para w do i-ésimo exemplo\n",
    "            dj_dw_i = \n",
    "        \n",
    "            # Seu código aqui para obter o gradiente para b do i-ésimo exemplo\n",
    "            dj_db_i = \n",
    "     \n",
    "            # Atualize dj_db : Em Python, a += 1  é o mesmo que a = a + 1\n",
    "            dj_db += dj_db_i\n",
    "        \n",
    "            # Atualize dj_dw\n",
    "            dj_dw += dj_dw_i\n",
    "    \n",
    "        # Divida tanto dj_dw quanto dj_db po m\n",
    "        dj_dw = dj_dw / m\n",
    "        dj_db = dj_db / m\n",
    "        ### TERMINE SEU CÓDIGO AQUI ###\n",
    "        \n",
    "        return dj_dw, dj_db\n",
    "    ```\n",
    "        \n",
    "    * Se ainda estiver com dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular `f_wb` and `cost`.\n",
    "    \n",
    "\n",
    "  <details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Você fez isso no exercício anterior! Para os escalares $a$, $b$ e $c$ (<code>x[i]</code>, <code>w</code> and <code>b</code> são todos escalares), você pode calcular a equação $h = ab + c$ em código como <code>h = a * b + c</code>\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f</b></font></summary>\n",
    "               &emsp; &emsp; Você pode calcular f_wb como <code>f_wb = w * x[i] + b </code>\n",
    "           </details>\n",
    "    </details>\n",
    "        \n",
    "  <details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_dw_i</b></font></summary>\n",
    "           &emsp; &emsp; Para os escalares $a$, $b$ e $c$ (<code>f_wb</code>, <code>y[i]</code> e <code>x[i]</code> são todos escalares), você pode calcular a equação $h = (a - b)c$ em código como <code>h = (a-b)*c</code>\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f</b></font></summary>\n",
    "               &emsp; &emsp; Você pode calcular dj_dw_i como <code>dj_dw_i = (f_wb - y[i]) * x[i] </code>\n",
    "          </details>\n",
    "  </details>\n",
    "        \n",
    "  <details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_db_i</b></font></summary>\n",
    "             &emsp; &emsp; Você pode calcular dj_db_i como <code> dj_db_i = f_wb - y[i] </code>\n",
    "  </details>\n",
    "        \n",
    "  </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to check your implementation of the `compute_gradient` function with two different initializations of the parameters $w$,$b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Compute and display gradient with w initialized to zeroes\n",
    "initial_w = 0\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)\n",
    "\n",
    "compute_gradient_test(compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the gradient descent algorithm implemented above on our dataset.\n",
    "\n",
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Gradient at initial , b (zeros)<b></td>\n",
    "    <td> -65.32884975 -5.83913505154639</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Compute and display cost and gradient with non-zero w\n",
    "test_w = 0.2\n",
    "test_b = 0.2\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Gradient at test w, b:', tmp_dj_dw, tmp_dj_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Gradient at test w<b></td>\n",
    "    <td> -47.41610118 -4.007175051546391</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Learning parameters using batch gradient descent \n",
    "\n",
    "You will now find the optimal parameters of a linear regression model by using batch gradient descent. Recall batch refers to running all the examples in one iteration.\n",
    "- You don't need to implement anything for this part. Simply run the cells below. \n",
    "\n",
    "- A good way to verify that gradient descent is working correctly is to look\n",
    "at the value of $J(w,b)$ and check that it is decreasing with each step. \n",
    "\n",
    "- Assuming you have implemented the gradient and computed the cost correctly and you have an appropriate value for the learning rate alpha, $J(w,b)$ should never increase and should converge to a steady value by the end of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      x :    (ndarray): Shape (m,)\n",
    "      y :    (ndarray): Shape (m,)\n",
    "      w_in, b_in : (scalar) Initial values of parameters of the model\n",
    "      cost_function: function to compute cost\n",
    "      gradient_function: function to compute the gradient\n",
    "      alpha : (float) Learning rate\n",
    "      num_iters : (int) number of iterations to run gradient descent\n",
    "    Returns\n",
    "      w : (ndarray): Shape (1,) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(x)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration — primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b )  \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the gradient descent algorithm above to learn the parameters for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# initialize fitting parameters. Recall that the shape of w is (n,)\n",
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "w,b,_,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \n",
    "                     compute_cost, compute_gradient, alpha, iterations)\n",
    "print(\"w,b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b> w, b found by gradient descent<b></td>\n",
    "    <td> 1.16636235 -3.63029143940436</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the final parameters from gradient descent to plot the linear fit. \n",
    "\n",
    "Recall that we can get the prediction for a single example $f(x^{(i)})= wx^{(i)}+b$. \n",
    "\n",
    "To calculate the predictions on the entire dataset, we can loop through all the training examples and calculate the prediction for each example. This is shown in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "m = x_train.shape[0]\n",
    "predicted = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    predicted[i] = w * x_train[i] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the predicted values to see the linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plot the linear fit\n",
    "plt.plot(x_train, predicted, c = \"b\")\n",
    "\n",
    "# Create a scatter plot of the data. \n",
    "plt.scatter(x_train, y_train, marker='x', c='r') \n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Profits vs. Population per city\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Profit in $10,000')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Population of City in 10,000s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your final values of $w,b$ can also be used to make predictions on profits. Let's predict what the profit would be in areas of 35,000 and 70,000 people. \n",
    "\n",
    "- The model takes in population of a city in 10,000s as input. \n",
    "\n",
    "- Therefore, 35,000 people can be translated into an input to the model as `np.array([3.5])`\n",
    "\n",
    "- Similarly, 70,000 people can be translated into an input to the model as `np.array([7.])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "predict1 = 3.5 * w + b\n",
    "print('For population = 35,000, we predict a profit of $%.2f' % (predict1*10000))\n",
    "\n",
    "predict2 = 7.0 * w + b\n",
    "print('For population = 70,000, we predict a profit of $%.2f' % (predict2*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b> For population = 35,000, we predict a profit of<b></td>\n",
    "    <td> $4519.77 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td> <b> For population = 70,000, we predict a profit of<b></td>\n",
    "    <td> $45342.45 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on completing this practice lab on linear regression! Next week, you will create models to solve a different type of problem: classification. See you there!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Please click here if you want to experiment with any of the non-graded code.</b></font></summary>\n",
    "    <p><i><b>Important Note: Please only do this when you've already passed the assignment to avoid problems with the autograder.</b></i>\n",
    "    <ol>\n",
    "        <li> On the notebook’s menu, click “View” > “Cell Toolbar” > “Edit Metadata”</li>\n",
    "        <li> Hit the “Edit Metadata” button next to the code cell which you want to lock/unlock</li>\n",
    "        <li> Set the attribute value for “editable” to:\n",
    "            <ul>\n",
    "                <li> “true” if you want to unlock it </li>\n",
    "                <li> “false” if you want to lock it </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li> On the notebook’s menu, click “View” > “Cell Toolbar” > “None” </li>\n",
    "    </ol>\n",
    "    <p> Here's a short demo of how to do the steps above: \n",
    "        <br>\n",
    "        <img src=\"https://drive.google.com/uc?export=view&id=14Xy_Mb17CZVgzVAgq7NCjMVBvSae3xO1\" align=\"center\" alt=\"unlock_cells.gif\">\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
