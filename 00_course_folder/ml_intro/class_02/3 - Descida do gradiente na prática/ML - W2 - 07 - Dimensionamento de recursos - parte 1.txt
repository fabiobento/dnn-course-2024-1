Então, bem-vindo de volta. Vamos dar uma olhada em algumas técnicas que fazem com que o ótimo inter sense funcione muito melhor. Neste vídeo, você vê uma técnica chamada dimensionamento de recursos que permitirá que a descida de gradiente seja executada muito mais rápido. Vamos começar examinando a relação entre o tamanho de um recurso, que é o tamanho dos números desse recurso, e o tamanho do parâmetro associado. Como exemplo concreto, vamos prever o preço de uma casa usando duas características: x1 do tamanho da casa e x2 do número de quartos. Digamos que x1 normalmente varia de 300 a 2.000 pés quadrados. E x2 no conjunto de dados varia de 0 a 5 quartos. Portanto, neste exemplo, x1 assume uma faixa relativamente grande de valores e x2 assume uma faixa relativamente pequena de valores. Agora, vamos dar um exemplo de uma casa com um tamanho de 2.000 pés quadrados, cinco quartos e um preço de 500 mil ou $500.000. Para este exemplo de treinamento, o que você acha que são valores razoáveis para o tamanho dos parâmetros w1 e w2? Bem, vamos dar uma olhada em um possível conjunto de parâmetros. Digamos que w1 seja 50 e w2 seja 0,1 e b seja 50 para fins de discussão.
Reproduza o vídeo começando em :1:34 e siga a transcrição1:34
Então, neste caso, o preço estimado em milhares de dólares é de 100.000 mil aqui mais 0,5 k mais 50 mil, o que é um pouco mais de 100 milhões de dólares. Então, isso está claramente muito longe do preço real de $500.000. Portanto, esse não é um conjunto muito bom de opções de parâmetros para w1 e w2. Agora vamos dar uma olhada em outra possibilidade. Digamos que w1 e w2 fossem o contrário. W1 é 0,1 e w2 é 50 e b ainda é 50. Nessa escolha de w1 e w2, w1 é relativamente pequeno e w2 é relativamente grande, 50 é muito maior que 0,1. Então, aqui o preço previsto é 0,1 vezes 2000 mais 50 vezes cinco mais 50. O primeiro termo se torna 200k, o segundo termo se torna 250k e o mais 50. Portanto, essa versão do modelo prevê um preço de $500.000, que é uma estimativa muito mais razoável e é o mesmo preço do preço real da casa.
Reproduza o vídeo começando em :2:56 e siga a transcrição2:56
Então, espero que você perceba isso quando um possível intervalo de valores de um recurso é grande, como o tamanho e os pés quadrados, que vão até 2000. É mais provável que um bom modelo aprenda a escolher um valor de parâmetro relativamente pequeno, como 0,1. Da mesma forma, quando os valores possíveis do recurso são pequenos, como o número de quartos, um valor razoável para seus parâmetros será relativamente grande, como 50. Então, como isso se relaciona com a classificação da descendência? Bem, vamos dar uma olhada no gráfico de dispersão das características em que o tamanho dos pés quadrados é o eixo horizontal x1 e o número de quartos exala está no eixo vertical. Se você representar graficamente os dados de treinamento, notará que o eixo horizontal está em uma escala muito maior ou em uma faixa de valores muito maior em comparação com o eixo vertical.
Reproduza o vídeo começando em :3:55 e siga a transcrição3:55
Em seguida, vamos ver como a função de custo pode aparecer em um gráfico de contorno. Você pode ver um gráfico de contorno em que o eixo horizontal tem uma faixa muito mais estreita, digamos, entre zero e um, enquanto o eixo vertical assume valores muito maiores, digamos, entre 10 e 100. Assim, os contornos formam ovais ou elipses e são curtos de um lado e mais longos do outro. E isso ocorre porque uma mudança muito pequena em w1 pode ter um impacto muito grande no preço estimado e isso é um impacto muito grande no custo J. Porque w1 tende a ser multiplicado por um número muito grande, o tamanho e os pés quadrados. Em contraste, é necessária uma mudança muito maior em w2 para mudar muito as previsões. E, portanto, pequenas mudanças em w2 não alteram tanto a função de custo. Então, onde isso nos deixa? Isso é o que poderia acabar acontecendo se você se saísse bem em dissidência, se usasse seus dados de treinamento como estão. Como os contornos são muito altos e estreitos, a descida em gradiente pode acabar oscilando para frente e para trás por um longo tempo antes de finalmente chegar ao mínimo global. Em situações como essa, uma coisa útil a fazer é escalar os recursos. Isso significa realizar alguma transformação de seus dados de treinamento para que x1, digamos, agora possa variar de 0 a 1 e x2 também possa variar de 0 a 1. Portanto, os pontos de dados agora se parecem mais com isso e você pode notar que a escala do gráfico na parte inferior agora é bem diferente da escala na parte superior.
Reproduza o vídeo começando em :5:45 e siga a transcrição5:45
O ponto principal é que as escalas re x1 e x2 agora estão adotando faixas de valores comparáveis entre si. E se você executar o gradiente descendente em uma função de custo para encontrar isso, redimensionar novamente x1 e x2 usando esses dados transformados, os contornos ficarão mais parecidos com isso, mais parecidos com círculos e menos altos e finos. E o gradiente descendente pode encontrar um caminho muito mais direto para o mínimo global.
Reproduza o vídeo começando em :6:14 e siga a transcrição6:14
Então, para recapitular, quando você tem características diferentes que assumem faixas de valores muito diferentes, isso pode fazer com que a descida do gradiente ocorra lentamente, mas redimensionando as diferentes características para que todas assumam uma faixa de valores comparável. porque aceleram, atualizam e discordam significativamente. Como você realmente faz isso? Vamos dar uma olhada nisso no próximo vídeo.
