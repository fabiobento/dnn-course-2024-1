Seu algoritmo de aprendizado funcionará muito melhor com uma escolha apropriada de taxa de aprendizado. Se for muito pequeno, ele funcionará muito lentamente e, se for muito grande, pode nem mesmo convergir. Vamos dar uma olhada em como você pode escolher uma boa taxa de aprendizado para seu modelo. Concretamente, se você traçar o custo de várias iterações e perceber que os custos às vezes aumentam e às vezes diminuem, você deve interpretar isso como um sinal claro de que o gradiente descendente não está funcionando corretamente. Isso pode significar que há um bug no código. Ou às vezes isso pode significar que sua taxa de aprendizado é muito grande. Então, aqui está uma ilustração do que pode estar acontecendo. Aqui, o eixo vertical é uma função de custo J, e o eixo horizontal representa um parâmetro como talvez w_1. Se a taxa de aprendizado for muito grande, se você começar aqui, sua etapa de atualização poderá ultrapassar o mínimo e terminar aqui, e na próxima etapa de atualização aqui, seu ganho será superado, então você acaba aqui e assim por diante. É por isso que o custo às vezes pode aumentar em vez de diminuir. Para corrigir isso, você pode usar uma taxa de aprendizado menor. Então, suas atualizações podem começar aqui e diminuir um pouco e diminuir um pouco, e esperamos diminuir de forma consistente até que atinja o mínimo global. Às vezes, você pode ver que o custo aumenta consistentemente após cada iteração, como nesta curva aqui. Provavelmente, isso também se deve a uma taxa de aprendizado muito grande e pode ser resolvido escolhendo uma taxa de aprendizado menor. Mas taxas de aprendizado como essas também podem ser um sinal de um possível código quebrado.
Reproduza o vídeo começando em :1:51 e siga a transcrição1:51
Por exemplo, se eu escrevesse meu código para que w_1 fosse atualizado como w_1 mais Alpha vezes esse termo derivado, isso poderia resultar no aumento consistente do custo a cada iteração. Isso ocorre porque ter o termo derivado afasta seu custo J do mínimo global em vez de aproximá-lo. Portanto, lembre-se de que você deseja usar o sinal de menos, então o código deve ser atualizado w_1 atualizado por w_1 menos Alpha vezes o termo derivado. Uma dica de depuração para uma implementação correta do gradiente descendente é que, com uma taxa de aprendizado pequena o suficiente, a função de custo deve diminuir a cada iteração. Então, se o gradiente descendente não está funcionando, uma coisa que eu costumo fazer e espero que você também ache essa dica útil, uma coisa que eu faço com frequência é definir Alpha como um número muito pequeno e ver se isso faz com que o custo diminua a cada iteração. Se mesmo com o Alpha definido como um número muito pequeno, J não diminui a cada iteração, mas às vezes aumenta , isso geralmente significa que há um bug em algum lugar do código. Observe que definir o Alpha como muito pequeno é uma etapa de depuração e um valor muito pequeno do Alpha não será a opção mais eficiente para realmente treinar seu algoritmo de aprendizado. Uma desvantagem importante é que, se sua taxa de aprendizado for muito pequena, as descidas do gradiente podem levar muitas iterações para convergir. Portanto, quando estou executando a descida de gradiente, geralmente tento uma faixa de valores para a taxa de aprendizado Alpha. Posso começar tentando uma taxa de aprendizado de 0,001 e também posso tentar uma taxa de aprendizado 10 vezes maior, digamos 0,01 e 0,1 e assim por diante. Para cada opção de Alpha, você pode executar a descida de gradiente apenas para algumas iterações e traçar a função de custo J em função do número de iterações e, depois de tentar alguns valores diferentes, você pode escolher o valor de Alpha que parece diminuir a taxa de aprendizado rapidamente, mas também de forma consistente. Na verdade, o que eu realmente faço é tentar uma variedade de valores como essa. Depois de tentar 0,001, aumentarei a taxa de aprendizado em três vezes para 0,003. Depois disso, vou tentar 0,01, que é novamente cerca de três vezes maior que 0,003. Portanto, eles estão aproximadamente testando descidas de gradiente, com cada valor de Alpha sendo aproximadamente três vezes maior do que o valor anterior. O que vou fazer é testar um intervalo de valores até descobrir que o valor é muito pequeno e, em seguida, verificar se encontrei um valor muito grande. Vou lentamente tentar escolher a maior taxa de aprendizado possível, ou apenas algo um pouco menor do que o maior valor razoável que encontrei. Quando eu faço isso, geralmente me dá uma boa taxa de aprendizado para o meu modelo. Espero que essa técnica também seja útil para você escolher uma boa taxa de aprendizado para a implementação do gradiente descendente. No próximo laboratório opcional, você também pode dar uma olhada em como o escalonamento de recursos é feito no código e também ver como diferentes escolhas da taxa de aprendizado Alpha podem levar a um treinamento melhor ou pior do seu modelo. Espero que você se divirta jogando com o valor do Alpha e vendo os resultados das diferentes escolhas do Alpha. Dê uma olhada e execute o código no laboratório opcional para obter uma intuição mais profunda sobre a escalabilidade de recursos, bem como sobre a taxa de aprendizado Alpha. Escolher taxas de aprendizado é uma parte importante do treinamento de muitos algoritmos de aprendizado e espero que este vídeo forneça uma intuição sobre diferentes opções e como escolher um bom valor para o Alpha. Agora, há mais algumas ideias que você pode usar para tornar a regressão linear múltipla muito mais poderosa. Isso é escolher recursos personalizados, que também permitirão que você ajuste curvas, não apenas uma linha reta, aos seus dados. Vamos dar uma olhada nisso no próximo vídeo.
