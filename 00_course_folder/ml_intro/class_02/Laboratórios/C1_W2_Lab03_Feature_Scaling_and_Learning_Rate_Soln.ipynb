{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98375877",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7c9ee",
   "metadata": {},
   "source": [
    "Os dados de moradia foram derivados do [Ames Housing dataset](http://jse.amstat.org/v19n3/decock.pdf) compilado por Dean De Cock para uso no ensino de ciência de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório.\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/ml_intro/class_02/Laborat%C3%B3rios/lab_utils_ml_intro_week_2.zip\n",
    "!unzip -n -q lab_utils_ml_intro_week_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Feature scaling_ e Taxa de Aprendizagem (Multi-Variável)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "Neste laboratório você vai:\n",
    "- Utilizar as rotinas de múltiplas variáveis desenvolvidas no laboratório anterior\n",
    "- Executar o Gradient Descendente em um conjunto de dados com vários recursos\n",
    "- Explorar o impacto da *taxa de aprendizado alfa* na descida de gradiente\n",
    "- Melhorar o desempenho do gradient descent por meio do *feature scaling* usando a normalização com _z-score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ferramentas\n",
    "Você utilizará as funções desenvolvidas no último laboratório, bem como o Matplotlib e o NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_multi import  load_house_data, run_gradient_descent \n",
    "from lab_utils_multi import  norm_plot, plt_equal_scale, plot_cost_i_w\n",
    "from lab_utils_common import dlc\n",
    "np.set_printoptions(precision=2)\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf07937",
   "metadata": {},
   "source": [
    "## Notação\n",
    "\n",
    "|Geral <br />  Notação  | Descrição| Python (se aplicável) |\n",
    "| ------------| ------------------------------------------------------------|-|\n",
    "| $a$ | escalar, não bold                                                      |-|\n",
    "| $\\mathbf{a}$ | vetor, bold                                                 |-|\n",
    "| $\\mathbf{A}$ | matriz, maiúsculo bold                                         |-|\n",
    "| **Regressão** |       -  | -   | -    |\n",
    "|  $\\mathbf{X}$ | matriz de exemplos de treino                  | `X_train` |   \n",
    "|  $\\mathbf{y}$  | alvos dos exemplos de treinamento               | `y_train` \n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{ésimo}$ Exemplo de treinamento | `X[i]`, `y[i]`|\n",
    "| m | quantidade de exemplos de treinamento | `m`|\n",
    "| n | quantidade de recursos em cada exemplo | `n`|\n",
    "|  $\\mathbf{w}$  |  parâmetro: peso                       | `w`    |\n",
    "|  $b$           |  parâmetro: bias                                           | `b`    |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | O resultado da avaliação do modelo em  $\\mathbf{x}^{(i)}$ parametrizado por $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | \n",
    "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$| o gradiente ou a derivada parcial do custo em relação a um parâmetro $w_j$ |`dj_dw[j]`| \n",
    "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$| o gradiente ou a derivada parcial do custo em relação a um parâmetro $b$| `dj_db`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae608f8",
   "metadata": {},
   "source": [
    "#  Definição do Problema\n",
    "\n",
    "Como nos laboratórios anteriores, você usará o exemplo de previsão de preços de imóveis. O conjunto de dados de treinamento contém muitos exemplos com quatro recursos (tamanho, quartos, andares e idade) mostrados na tabela abaixo. Observe que, neste laboratório, o recurso Tamanho é em pés quadrados, enquanto os laboratórios anteriores utilizaram 1000 pés quadrados.  Esse conjunto de dados é maior do que o do laboratório anterior.\n",
    "\n",
    "Gostaríamos de criar um modelo de regressão linear usando esses valores para podermos prever o preço de outras casas - por exemplo, uma casa com 1.200 pés quadrados, 3 quartos, 1 andar e 40 anos de idade. \n",
    "\n",
    "##  Conjunto de Dados: \n",
    "| Tamanho (sqft) | Quantidade de Quartos| Quantidade de Andares | Idade da Casa | Preço (1000s dólares)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|----------------------- |  \n",
    "| 952             | 2                   | 1                | 65           | 271.5                  |  \n",
    "| 1244            | 3                   | 2                | 64           | 232                    |  \n",
    "| 1947            | 3                   | 2                | 17           | 509.8                  |  \n",
    "| ...             | ...                 | ...              | ...          | ...                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe89205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar o conjunto de dados\n",
    "X_train, y_train = load_house_data()\n",
    "X_features = ['tamanho(sqft)','quartos','andares','idade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2509853",
   "metadata": {},
   "source": [
    "Vamos visualizar o conjunto de dados e seus recursos plotando cada recurso em relação ao preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"Preço (1000's)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44618c3",
   "metadata": {},
   "source": [
    "A plotagem de cada recurso em relação à meta, o preço, fornece alguma indicação de quais recursos têm a maior influência sobre o preço. Acima, o aumento do tamanho também aumenta o preço. Quartos e pisos não parecem ter um forte impacto sobre o preço. As casas mais novas têm preços mais altos do que as casas mais antigas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a1478",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "## Gradiente Descendente com Múltiplas Variáveis\n",
    "Aqui estão as equações que você desenvolveu no último laboratório sobre descida de gradiente para várias variáveis:\n",
    "\n",
    "$$\\begin{align*} \\text{repetir}&\\text{ até a convergência:} \\; \\lbrace \\newline\\;\n",
    "& w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "onde n é o número de recursos, os parâmetros $w_j$, $b$ são atualizados simultaneamente e onde  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{2}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "* m é o número de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ é a predição do modelo, enquanto $y^{(i)}$ é o valor alvo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01449813",
   "metadata": {},
   "source": [
    "## Taxa de Aprendizado\n",
    "<figure>\n",
    "    <img src=\"./images/C1_W2_Lab06_learningrate.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "\n",
    "As aulas discutiram alguns dos problemas relacionados à definição da taxa de aprendizado $\\alpha$. A taxa de aprendizado controla o tamanho da atualização dos parâmetros. Veja a equação (1) acima. Ela é compartilhada por todos os parâmetros.  \n",
    "\n",
    "Vamos executar a descida de gradiente e tentar algumas configurações de $\\alpha$ em nosso conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51770689",
   "metadata": {},
   "source": [
    "### $\\alpha$ = 9.9e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b386ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir alpha igual a 9.9e-7\n",
    "_, _, hist = run_gradient_descent(X_train, y_train, 10, alpha = 9.9e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b487383",
   "metadata": {},
   "source": [
    "Parece que a taxa de aprendizado é muito alta.  A solução não converge. O custo está *crescendo* em vez de diminuir. Vamos plotar o resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529f32d",
   "metadata": {},
   "source": [
    "O gráfico à direita mostra o valor de um dos parâmetros, $w_0$. A cada iteração, ele está ultrapassando o valor ideal e, como resultado, o custo acaba *aumentando* em vez de se aproximar do mínimo. Observe que essa não é uma imagem totalmente precisa, pois há 4 parâmetros sendo modificados a cada passagem, em vez de apenas um. Esse gráfico está mostrando apenas $w_0$ com os outros parâmetros fixados em valores benignos. Neste gráfico e em gráficos posteriores, você pode notar que as linhas azul e laranja estão ligeiramente fora do padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e064e",
   "metadata": {},
   "source": [
    "\n",
    "### $\\alpha$ = 9e-7\n",
    "Vamos tentar um valor um pouco menor e ver o que acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfe5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir alpha igual a 9e-7\n",
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 9e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac53001",
   "metadata": {},
   "source": [
    "O custo está diminuindo ao longo da execução, mostrando que o alfa não é muito grande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96578978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81644d",
   "metadata": {},
   "source": [
    "À esquerda, você vê que o custo está diminuindo como deveria. À direita, você pode ver que $w_0$ ainda está oscilando em torno do mínimo, mas o custo está diminuindo a cada iteração em vez de aumentar. Observe acima que `dj_dw[0]` muda de sinal a cada iteração, pois `w[0]` salta sobre o valor ideal.\n",
    "Esse valor alfa convergirá. Você pode variar o número de iterações para ver como ele se comporta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3fac33",
   "metadata": {},
   "source": [
    "### $\\alpha$ = 1e-7\n",
    "Vamos tentar um valor um pouco menor para $\\alpha$ e ver o que acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f73522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir alpha igual a 1e-7\n",
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1803eaa4",
   "metadata": {},
   "source": [
    "O custo está diminuindo ao longo da execução, mostrando que $\\alpha$ não é muito grande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbf1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train,y_train,hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963def7d",
   "metadata": {},
   "source": [
    "À esquerda, você vê que o custo está diminuindo como deveria. À direita, você pode ver que $w_0$ está se aproximando do mínimo sem oscilações. O `dj_w0` é negativo durante toda a execução. Essa solução também convergirá."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb91ec4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## _Feature Scaling_\n",
    "<figure>\n",
    "    <img src=\"./images/C1_W2_Lab06_featurescalingheader.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "As aulas descreveram a importância de redimensionar o conjunto de dados para que os recursos tenham um intervalo semelhante.\n",
    "Se você estiver interessado em saber por que isso acontece, clique no link \"Detalhes\" abaixo. Caso contrário, a seção abaixo apresentará uma implementação de como fazer o _feature scaling_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df826031",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size='3', color='darkgreen'><b>Detalhes</b></font>\n",
    "</summary>\n",
    "\n",
    "Vejamos novamente a situação com $\\alpha$ = 9e-7. Isso está bem próximo do valor máximo que podemos definir para $\\alpha$ sem divergir. Esta é uma execução curta que mostra as primeiras iterações:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"./images/C1_W2_Lab06_ShortRun.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "\n",
    "Acima, enquanto o custo está sendo reduzido, fica claro que $w_0$ está progredindo mais rapidamente do que os outros parâmetros devido ao seu gradiente muito maior.\n",
    "\n",
    "O gráfico abaixo mostra o resultado de uma execução muito longa com $\\alpha$ = 9e-7. Isso leva vaaaaárias horas :-)\n",
    "\n",
    "<figure>\n",
    "    <img src=\"./images/C1_W2_Lab06_LongRun.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "    \n",
    "Acima, você pode ver que o custo diminuiu lentamente após a redução inicial. Observe a diferença entre `w0` e `w1`, `w2`, `w3`, bem como `dj_dw0` e `dj_dw1-3`. O `w0` atinge seu valor quase final muito rapidamente e o `dj_dw0` diminuiu rapidamente para um valor pequeno, mostrando que o `w0` está próximo do valor final. Os outros parâmetros foram reduzidos muito mais lentamente.\n",
    "\n",
    "Por que isso acontece?  Há algo que podemos melhorar? Veja abaixo:\n",
    "<figure>\n",
    "    <center> <img src=\"./images/C1_W2_Lab06_scale.PNG\"   ></center>\n",
    "</figure>   \n",
    "\n",
    "A figura acima mostra por que os $w$ são atualizados de forma desigual. \n",
    "- $\\alpha$ é compartilhado por todas as atualizações de parâmetros ($w$'s e $b$).\n",
    "- o termo de erro comum é multiplicado pelos recursos para os $w$'s. (não $b$).\n",
    "- os recursos variam significativamente em magnitude, fazendo com que alguns recursos sejam atualizados muito mais rapidamente do que outros. Nesse caso, $w_0$ é multiplicado por 'size(sqft)', que geralmente é > 1000, enquanto $w_1$ é multiplicado por 'number of bedrooms', que geralmente é 2-4. \n",
    "    \n",
    "A solução é o _feature scaling_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05d6c7",
   "metadata": {},
   "source": [
    "As aulas discutiram três técnicas diferentes: \n",
    "- _Feature scaling_, essencialmente dividindo cada recurso positivo por seu valor máximo ou, de forma mais geral, redimensionando cada recurso por seus valores mínimo e máximo usando (x-min)/(max-min). Ambas as formas normalizam os recursos para o intervalo de -1 e 1, sendo que o primeiro método funciona para recursos positivos, o que é simples e serve bem para o exemplo da aula, e o segundo método funciona para quaisquer recursos.\n",
    "- Normalização média: $x_i := \\dfrac{x_i - \\mu_i}{max - min} $ \n",
    "- Normalização com _z-score_ que exploraremos a seguir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b010f",
   "metadata": {},
   "source": [
    "\n",
    "### Normalização z-score\n",
    "Após a normalização _z_score_, todos os recursos terão uma média de 0 e um desvio padrão de 1.\n",
    "\n",
    "Para implementar a normalização do escore z, ajuste os valores de entrada conforme mostrado nesta fórmula:\n",
    "\n",
    "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} \\tag{4}$$ \n",
    "em que $j$ seleciona um recurso ou uma coluna na matriz $\\mathbf{X}$. $µ_j$ é a média de todos os valores do recurso (j) e $\\sigma_j$ é o desvio padrão do recurso (j).\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j \\tag{5}\\\\\n",
    "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2  \\tag{6}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    ">**Nota de implementação:** Quando normalizar os recursos é importante\n",
    "armazenar os valores usados para normalização - o valor médio e o desvio padrão usados para os cálculos. Depois de aprender os parâmetros\n",
    "do modelo, geralmente queremos prever os preços de casas que não vimos antes. Dado um novo valor x (área da sala de estar e número de quartos), devemos primeiro normalizar o valor médio e o desvio padrão que havíamos calculado anteriormente com base no conjunto de treinamento.\n",
    "\n",
    "**Implementação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b417547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    calcula  X, zcore normalizado por coluna\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : dados de entrada, m exemplos, n recursos\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): entrada normalizada por coluna\n",
    "      mu (ndarray (n,))     : média de cada recurso\n",
    "      sigma (ndarray (n,))  : desvio padrão de cada recurso\n",
    "    \"\"\"\n",
    "    # Encontre a média de cada coluna/recurso\n",
    "    mu     = np.mean(X, axis=0)   # mu terá a forma (n,)\n",
    "    # Encontre o desvio padrão de cada coluna/recurso\n",
    "    sigma  = np.std(X, axis=0)  # sigma terá a forma (n,)\n",
    "    # subtraia mu elemento-a-elemento dessa coluna para cada exemplo, divida por sigma para cada coluna\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    " \n",
    "#verifique nosso trabalho\n",
    "#from sklearn.preprocessing import scale\n",
    "#scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb6830",
   "metadata": {},
   "source": [
    "Vejamos as etapas envolvidas na normalização do escore Z. O gráfico abaixo mostra a transformação passo a passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8964189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu     = np.mean(X_train,axis=0)   \n",
    "sigma  = np.std(X_train,axis=0) \n",
    "X_mean = (X_train - mu)\n",
    "X_norm = (X_train - mu)/sigma      \n",
    "\n",
    "fig,ax=plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax[0].scatter(X_train[:,0], X_train[:,3])\n",
    "ax[0].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[0].set_title(\"não-normalizado\")\n",
    "ax[0].axis('equal')\n",
    "\n",
    "ax[1].scatter(X_mean[:,0], X_mean[:,3])\n",
    "ax[1].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[1].set_title(r\"X - $\\mu$\")\n",
    "ax[1].axis('equal')\n",
    "\n",
    "ax[2].scatter(X_norm[:,0], X_norm[:,3])\n",
    "ax[2].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[2].set_title(r\"Normalizado com Z-score\")\n",
    "ax[2].axis('equal')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(\"distribuição de recursos antes, durante e depois da normalização\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efe834",
   "metadata": {},
   "source": [
    "O gráfico acima mostra a relação entre dois dos parâmetros do conjunto de treinamento, \"idade\" e \"tamanho (sqft)\". *Esses são plotados em escala igual. \n",
    "- Esquerda: não normalizado: O intervalo de valores ou a variação do recurso \"size(sqft)\" é muito maior do que o da idade\n",
    "- Meio: A primeira etapa remove a média ou o valor médio de cada recurso. Isso deixa os recursos centrados em zero. É difícil ver a diferença para o recurso \"idade\", mas \"size(sqft)\" está claramente em torno de zero.\n",
    "- Certo: A segunda etapa divide pelo desvio padrão. Isso deixa os dois recursos centralizados em zero com uma escala semelhante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516e101",
   "metadata": {},
   "source": [
    "Vamos normalizar os dados e compará-los com os dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aeca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar os recursos originais\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(f\"X_mu = {X_mu}, \\nX_sigma = {X_sigma}\")\n",
    "print(f\"Faixa de pico a pico por coluna com dados originais        X:{np.ptp(X_train,axis=0)}\")   \n",
    "print(f\"Faixa de pico a pico por coluna em X normalizado:{np.ptp(X_norm,axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c2cc9",
   "metadata": {},
   "source": [
    "O intervalo de pico a pico de cada coluna é reduzido de um fator de milhares para um fator de 2 a 3 por meio da normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941592ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_train[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"contagem\");\n",
    "fig.suptitle(\"distribuição dos recursos antes da normalização\")\n",
    "plt.show()\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_norm[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"contagem\"); \n",
    "fig.suptitle(\"distribuição dos recursos após normalização\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88951d",
   "metadata": {},
   "source": [
    "Observe, acima, que o intervalo dos dados normalizados (eixo x) está centrado em zero e aproximadamente +/- 2. O mais importante é que o intervalo é semelhante para cada recurso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ab7c6",
   "metadata": {},
   "source": [
    "Vamos executar novamente nosso algoritmo de descida de gradiente com dados normalizados.\n",
    "Observe o valor **muito maior de alfa**. Isso acelerará a descida do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db14062",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_norm, b_norm, hist = run_gradient_descent(X_norm, y_train, 1000, 1.0e-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd443b55",
   "metadata": {},
   "source": [
    "Os _feature scaling_ obtêm resultados muito precisos **muito, muito mais rápido!** :-). Observe que o gradiente de cada parâmetro é pequeno ao final dessa execução relativamente curta. Uma taxa de aprendizado de 0,1 é um bom começo para a regressão com recursos normalizados.\n",
    "Vamos plotar nossas previsões em relação aos valores-alvo. Observe que a previsão é feita usando o recurso normalizado, enquanto o gráfico é mostrado usando os valores originais do recurso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prever o alvo usando recursos normalizados\n",
    "m = X_norm.shape[0]\n",
    "yp = np.zeros(m)\n",
    "for i in range(m):\n",
    "    yp[i] = np.dot(X_norm[i], w_norm) + b_norm\n",
    "\n",
    "    # Traçar previsões e alvos em relação aos recursos originais    \n",
    "fig,ax=plt.subplots(1,4,figsize=(12, 3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train, label = 'alvo')\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "    ax[i].scatter(X_train[:,i],yp,color=dlc[\"dlorange\"], label = 'predito')\n",
    "ax[0].set_ylabel(\"Preço\"); ax[0].legend();\n",
    "fig.suptitle(\"alvo versus previsão usando o modelo normalizado com z-score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0583e",
   "metadata": {},
   "source": [
    "Os resultados parecem bons. Alguns pontos a serem observados:\n",
    "- com vários recursos, não podemos mais ter um único gráfico mostrando resultados versus recursos.\n",
    "- Ao gerar o gráfico, foram usados os recursos normalizados. Todas as previsões que usam os parâmetros aprendidos em um conjunto de treinamento normalizado também devem ser normalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6ac96",
   "metadata": {},
   "source": [
    "**Previsão**\n",
    "O objetivo de gerar nosso modelo é usá-lo para prever preços de imóveis que não estão no conjunto de dados. Vamos prever o preço de uma casa com 1.200 pés quadrados, 3 quartos, 1 andar, 40 anos de idade. Lembre-se de que você deve normalizar os dados com a média e o desvio padrão calculados quando os dados de treinamento foram normalizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d10b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, normalizar nosso exemplo.\n",
    "x_house = np.array([1200, 3, 1, 40])\n",
    "x_house_norm = (x_house - X_mu) / X_sigma\n",
    "print(x_house_norm)\n",
    "x_house_predict = np.dot(x_house_norm, w_norm) + b_norm\n",
    "print(f\" Preço previsto de uma casa com 1200 pés quadrados, 3 quartos, 1 andar, 40 anos de idade = ${x_house_predict*1000:0.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa12a3b",
   "metadata": {},
   "source": [
    "**Contornos(curvas de nível) de Custo**  \n",
    "<img align=\"left\" src=\"./images/C1_W2_Lab06_contours.PNG\"   style=\"width:240px;\" >Outra maneira de visualizar o _feature scaling_ é em termos de contornos de custo. Quando as escalas dos recursos não coincidem, o gráfico de custo versus parâmetros em um gráfico de contorno é assimétrico. \n",
    "\n",
    "No gráfico abaixo, a escala dos parâmetros é a combinada. O gráfico à esquerda é o gráfico de contorno de custo de w[0], os pés quadrados versus w[1], o número de quartos antes de normalizar os recursos. O gráfico é tão assimétrico que as curvas que completam os contornos não são visíveis. Em contrapartida, quando os recursos são normalizados, o contorno do custo é muito mais simétrico. O resultado é que as atualizações dos parâmetros durante a descida do gradiente podem fazer o mesmo progresso para cada parâmetro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_equal_scale(X_train, X_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parabéns!\n",
    "Neste laboratório, você:\n",
    "- utilizou as rotinas de regressão linear com vários recursos que desenvolveu nos laboratórios anteriores\n",
    "- explorou o impacto da taxa de aprendizado $\\alpha$ na convergência \n",
    "- descobriu o valor do escalonamento de recursos usando a normalização do escore z para acelerar a convergência"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
