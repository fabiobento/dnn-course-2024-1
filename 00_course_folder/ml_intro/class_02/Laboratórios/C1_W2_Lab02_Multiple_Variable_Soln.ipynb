{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3008a7b9",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb06d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório.\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/ml_intro/class_02/Laborat%C3%B3rios/lab_utils_ml_intro_week_2.zip\n",
    "!unzip -n -q lab_utils_ml_intro_week_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear com Múltiplas Variáveis\n",
    "\n",
    "Neste laboratório, você ampliará as estruturas de dados e as rotinas desenvolvidas anteriormente para oferecer suporte a vários recursos. Várias rotinas são atualizadas, o que faz com que o laboratório pareça longo, mas ele faz pequenos ajustes nas rotinas anteriores, o que o torna rápido de revisar.\n",
    "\n",
    "# Tópicos\n",
    "- [&nbsp;&nbsp;1.1 Objetivos](#toc_15456_1.1)\n",
    "- [&nbsp;&nbsp;1.2 Ferramentas](#toc_15456_1.2)\n",
    "- [&nbsp;&nbsp;1.3 Notação](#toc_15456_1.3)\n",
    "- [2 Definição do Problema](#toc_15456_2)\n",
    "- [&nbsp;&nbsp;2.1 Matrix X contendo nossos exemplos](#toc_15456_2.1)\n",
    "- [&nbsp;&nbsp;2.2 Vetor de parâmetros w, b](#toc_15456_2.2)\n",
    "- [3 Modelo de Predição com Múltiplas Variáveis](#toc_15456_3)\n",
    "- [&nbsp;&nbsp;3.1 Previsão Única Elemento por Elemento](#toc_15456_3.1)\n",
    "- [&nbsp;&nbsp;3.2 Previsão Única Elemento: Vetor](#toc_15456_3.2)\n",
    "- [4 Calcular Custo com Múltiplas Variáveis](#toc_15456_4)\n",
    "- [5 Gradiente Descendente com Múltiplas Variáveis](#toc_15456_5)\n",
    "- [&nbsp;&nbsp;5.1 Calcular o Gradiente com Múltiplas Variáveis](#toc_15456_5.1)\n",
    "- [&nbsp;&nbsp;5.2 Gradiente Descendente com Múltiplas Variáveis](#toc_15456_5.2)\n",
    "- [6 Parabéns](#toc_15456_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.1\"></a>\n",
    "## 1.1 Objetivos\n",
    "- Ampliar nossas rotinas de modelo de regressão para oferecer suporte a vários recursos\n",
    "    - Ampliar as estruturas de dados para oferecer suporte a vários recursos\n",
    "    - Reescrever as rotinas de previsão, custo e gradiente para oferecer suporte a vários recursos\n",
    "    - Utilizar o NumPy `np.dot` para vetorizar suas implementações para maior velocidade e simplicidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.2\"></a>\n",
    "## 1.2 Ferramentas\n",
    "Neste laboratório, usaremos: \n",
    "- NumPy, uma biblioteca popular para computação científica\n",
    "- Matplotlib, uma biblioteca popular para plotagem de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2) # precisão de exibição reduzida em matrizes numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529b8ea",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.3\"></a>\n",
    "## 1.3 Notação\n",
    "Aqui está um resumo de algumas das notações que você encontrará, atualizadas para vários recursos.\n",
    "\n",
    "|Geral <img width=70/> <br />  Notação  <img width=70/> | Descrição<img width=350/>| Python (se aplicável) |\n",
    "| ------------| ------------------------------------------------------------|-|\n",
    "| $a$ | escalar, não bold                                                      |-|\n",
    "| $\\mathbf{a}$ | vector, bold                                                 |-|\n",
    "| $\\mathbf{A}$ | matriz, bold maiúsculo                                         |-|\n",
    "| **Regression** |         |  -  |   -  |\n",
    "|  $\\mathbf{X}$ | matriz de exemplos de treino                   | `X_train` |   \n",
    "|  $\\mathbf{y}$  | alvos de exemplos de treino               | `y_train` \n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{th}$Exemplo de treino | `X[i]`, `y[i]`|\n",
    "| m | nḿero de exemplos de treino | `m`|\n",
    "| n | número de recursos em cada exemplo | `n`|\n",
    "|  $\\mathbf{w}$  |  parâmetro: peso,                       | `w`    |\n",
    "|  $b$           |  parâmetro: bias                                           | `b`    |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | O resultado da avaliação do modelo em $\\mathbf{x^{(i)}}$ parametrizado por $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e649f",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "# 2 Definição do Problema\n",
    "\n",
    "Você usará o exemplo motivador de previsão de preços de imóveis. O conjunto de dados de treinamento contém três exemplos com quatro recursos (tamanho, quartos, andares e idade) mostrados na tabela abaixo.  Observe que, diferentemente dos laboratórios anteriores, o tamanho está em pés quadrados em vez de 1000 pés quadrados. Isso causa um problema, que você resolverá no próximo laboratório!\n",
    "\n",
    "| Tamanho (sqft) | Quantidade de Quartos  | Número de andares | Idade da Sasa | Preço (1000s de dólares)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "Você criará um modelo de regressão linear usando esses valores para poder prever o preço de outras casas. Por exemplo, uma casa com 1.200 pés quadrados, 3 quartos, 1 andar, 40 anos de idade.  \n",
    "\n",
    "Execute a seguinte célula de código para criar suas variáveis `X_train` e `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76beca0b",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.1\"></a>\n",
    "## 2.1 Matriz X contendo nossos exemplos\n",
    "De forma semelhante à tabela acima, os exemplos são armazenados em uma matriz NumPy `X_train`. Cada linha da matriz representa um exemplo. Quando você tem $m$ de exemplos de treinamento ($m$ é três no nosso exemplo) e há $n$ de recursos (quatro no nosso exemplo), $\\mathbf{X}$ é uma matriz com dimensões ($m$, $n$) (m linhas, n colunas).\n",
    "\n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "notação:\n",
    "- $\\mathbf{x}^{(i)}$ é um vetor contendo o exemplo $i$. $\\mathbf{x}^{(i)}$ $ = (x^{(i)}_0, x^{(i)}_1, \\cdots,x^{(i)}_{n-1})$\n",
    "- $x^{(i)}_j$ é um recurso $j$ no exemplo $i$.O sobrescrito entre parênteses indica o número do exemplo, enquanto o subscrito representa um elemento.  \n",
    "\n",
    "Exibir os dados de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b839a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os dados são armazenados em uma matriz numérica\n",
    "print(f\"Formato de X: {X_train.shape}, Tipo de X:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"Formato de y: {y_train.shape}, Tipo de y:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a7a70",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.2\"></a>\n",
    "## 2.2 Vetor de parâmetros vector w, b\n",
    "\n",
    "* $\\mathbf{w}$ é um vetor com $n$ elementos.\n",
    "  - Cada elemento contém o parâmetro associado a um recurso.\n",
    "  - Em nosso conjunto de dados, n é 4.\n",
    "  - Desenhamos isso como um vetor coluna\n",
    "\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* $b$ é um parâmetro escalar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82335a",
   "metadata": {},
   "source": [
    "Para fins de demonstração, $\\mathbf{w}$ e $b$ serão carregados com alguns valores iniciais selecionados que estão próximos do ideal. $\\mathbf{w}$ é um vetor NumPy 1-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"Formato de w_init: {w_init.shape}, tipo de b_init: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfe37d",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3\"></a>\n",
    "# 3 Modelo de Predição com Múltiplas Variáveis\n",
    "A previsão do modelo com múltiplas variáveis é dada pelo modelo linear:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "ou, em notação vetorial:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "onde $\\cdot$ é um `dot product` (produto escalar)\n",
    "\n",
    "Para demonstrar o produto escalar, implementaremos a previsão usando (1) e (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bcbf2",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3.1\"></a>\n",
    "## 3.1 Previsão única por elemento\n",
    "Nossa previsão anterior multiplicou o valor de um recurso por um parâmetro e adicionou um parâmetro de polarização. Uma extensão direta de nossa implementação anterior de previsão para vários recursos seria implementar (1) acima usando um loop sobre cada elemento, realizando a multiplicação com seu parâmetro e, em seguida, adicionando o parâmetro de polarização no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48987191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x, w, b): \n",
    "    \"\"\"\n",
    "    Previsão única com regressão linear\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) exemplo com múltiplos recursos\n",
    "      w (ndarray): Shape (n,) parâmetros do modelo    \n",
    "      b (scalar):  parâmetro do modelo     \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  predição\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]  \n",
    "        p = p + p_i         \n",
    "    p = p + b                \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d5c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter uma linha de nossos dados de treinamento\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"Formato de x_vec shape {x_vec.shape}, valor x_vec: {x_vec}\")\n",
    "\n",
    "# fazer uma previsão\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"Formato de f_wb shape {f_wb.shape}, predição: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c6710",
   "metadata": {},
   "source": [
    "Observe o formato de `x_vec`. Ele é um vetor NumPy 1-D com 4 elementos, (4,). O resultado, `f_wb`, é um escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3372bf",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3.2\"></a>\n",
    "## 3.2 Predição única: vetor\n",
    "\n",
    "Observando que a equação (1) acima pode ser implementada usando o produto escalar como em (2) acima. Podemos usar operações vetoriais para acelerar as previsões.\n",
    "\n",
    "Lembre-se de que, no laboratório Python/Numpy, o NumPy `np.dot()`[[link](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)] pode ser usado para executar um produto escalar vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17328b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    previsão única usando regressão linear\n",
    "    Args:\n",
    "      x (ndarray): Formato (n,) exemplo com múltiplas características\n",
    "      w (ndarray): Formato (n,) parâmetros do modelo\n",
    "      b (escalar):             parâmetro do modelo \n",
    "      \n",
    "    Returns:\n",
    "      p (escalar):  predição\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08247ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter uma linha de nossos dados de treinamento\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"Formato de x_vec shape {x_vec.shape}, valor de x_vec: {x_vec}\")\n",
    "\n",
    "# Fazer uma predição\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"Formato de f_wb {f_wb.shape}, predição: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53024df",
   "metadata": {},
   "source": [
    "Os resultados e as formas são os mesmos da versão anterior, que usava looping. A partir de agora, o `np.dot` será usado para essas operações. A previsão agora é uma única instrução. A maioria das rotinas a implementará diretamente em vez de chamar uma rotina de previsão separada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c72cd",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "# 4 Calcular custo com várias variáveis\n",
    "A equação da função de custo com várias variáveis $J(\\mathbf{w},b)$ é:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "onde:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "Em contraste com os laboratórios anteriores, $\\mathbf{w}$ e $\\mathbf{x}^{(i)}$ são vetores em vez de escalares que suportam vários recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb219a",
   "metadata": {},
   "source": [
    "Abaixo está uma implementação das equações (3) e (4). Observe que ela usa um padrão *padrão para este curso* em que é usado um loop for em todos os exemplos `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    calcula o custo\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Dados, m exemplos com n recursos\n",
    "      y (ndarray (m,)) : valores dos alvos\n",
    "      w (ndarray (n,)) : parâmetros do modelo \n",
    "      b (scalar)       : parâmetros do modelo\n",
    "      \n",
    "    Returns:\n",
    "      cost (escalar): custo\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = escalar (veja np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #escalar\n",
    "    cost = cost / (2 * m)                      #escalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule e exiba o custo usando nossos parâmetros ideais pré-escolhidos.\n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'Custo no w ótimo : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18af696",
   "metadata": {},
   "source": [
    "**Resultado Esperado**: Custo no w ótimo : 1.5578904045996674e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d3e06",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "# 5 Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5faae",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.1\"></a>\n",
    "## 5.1 Calcular o Gradiente Descendente com Múltiplas Variáveis\n",
    "Observe abaixo uma implementação para calcular as equações (6) e (7). Há diversas maneiras de implementar. Na versão abaixo versão, há um loop externo sobre todos os m exemplos.\n",
    "- $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ para o exemplo pode ser calculado diretamente e acumulado\n",
    "- em um segundo loop sobre todos os n recursos:\n",
    "    - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$ é calculado para cada $w_j$.        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Calcular o gradiente para a regressão linear\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Dados, m exemplos com n recursos\n",
    "      y (ndarray (m,)) : valores alvo\n",
    "      w (ndarray (n,)) : parâmetros do modelo  \n",
    "      b (scalar)       : parâmetros do modelo\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): O gradiente do custo em relação aos parâmetros w.\n",
    "      dj_db (scalar):       O gradiente do custo em relação aos parâmetros b.\n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(número de exemplos, número de recursos)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb311ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computar e exibir o gradiente\n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db em w,b iniciais: {tmp_dj_db}')\n",
    "print(f'dj_dw em w,b iniciais: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43488d6d",
   "metadata": {},
   "source": [
    "**Resultado Esperado**:   \n",
    "dj_db em w,b iniciais: -1.6739251122999121e-06  \n",
    "dj_dw em w,b iniciais:   \n",
    " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f5cd2",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.2\"></a>\n",
    "## 5.2 Gradiente Descendente com Múltiplas Variáveis\n",
    "A rotina abaixo implementa a equação (5) acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Executa a descida de gradiente em lote para aprender w e b. Atualiza w e b tomando \n",
    "    etapas de gradiente num_iters com taxa de aprendizado alfa    \n",
    "\n",
    "    Args:\n",
    "      X (ndarray (m,n))   : DAdos, me exemplos com n recursos\n",
    "      y (ndarray (m,))    : valores alvo\n",
    "      w_in (ndarray (n,)) : parâmetros iniciais de modelo\n",
    "      b_in (scalar)       : parâmetros iniciais de modelo\n",
    "      cost_function       : função para calcular o custo\n",
    "      gradient_function   : função para calcular o gradiente\n",
    "      alpha (float)       : taxa de aprendizado\n",
    "      num_iters (int)     : número de iterações para executar a descida do gradiente\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Valores atualizados dos parâmetros\n",
    "      b (scalar)       : Valor atualizado do parâmetro \n",
    "      \"\"\"\n",
    "    \n",
    "    # Uma matriz para armazenar os custos J e w em cada iteração,\n",
    "    # principalmente para gráficos posteriores\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in) #evite modificar o w global dentro da função\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calcular o gradiente e atualizar os parâmetros\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Atualizar parâmetros usando w, b, alfa e gradiente\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "      \n",
    "        # Salvar o custo J em cada iteração\n",
    "        if i<100000:# Evitar o esgotamento de recursos\n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Imprimir o custo a cada intervalo de 10 vezes ou tantas iterações se < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteração {i:4d}: Custo {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #retorna o histórico final de w,b e J para gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0f613",
   "metadata": {},
   "source": [
    "Na próxima célula, você testará a implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializar parâmetros\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# algumas configurações de descida de gradiente\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# Executar a descida do gradiente\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w encontrado por gradiente descendente: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"predição: {np.dot(X_train[i], w_final) + b_final:0.2f}, valor alvo: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc6515",
   "metadata": {},
   "source": [
    "**Resultado Esperado**:    \n",
    "b,w encontrado por gradiente descendente: -0.00,[ 0.2   0.   -0.01 -0.07]   \n",
    "predição: 426.19, valor alvo: 460  \n",
    "predição: 286.17, valor alvo: 232  \n",
    "predição: 171.47, valor alvo: 178  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de custo versus iteração\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Custo vs. iteração\")\n",
    "ax2.set_title(\"Custo vs. iteração (tail)\")\n",
    "ax1.set_ylabel(\"Custo\")\n",
    "ax2.set_ylabel(\"Custo\") \n",
    "ax1.set_xlabel(\"passo de iteração\")\n",
    "ax2.set_xlabel(\"passo de iteração\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Esses resultados não são inspiradores! O custo ainda está diminuindo e nossas previsões não são muito precisas. O próximo laboratório explorará como melhorar isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"toc_15456_6\"></a>\n",
    "# 6 Parabéns!\n",
    "Neste laboratório, você:\n",
    "- Reestruturou as rotinas de regressão linear, agora com várias variáveis.\n",
    "- Utilizou o NumPy `np.dot` para vetorizar as implementações"
   ]
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "15456"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
