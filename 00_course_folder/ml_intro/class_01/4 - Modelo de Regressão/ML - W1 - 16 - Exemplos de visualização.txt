Vamos ver mais algumas visualizações de w e b. Aqui está um exemplo. Aqui, você tem um ponto específico no gráfico j. Nesse ponto, w é igual a menos 0,15 e b é igual a cerca de 800. Esse ponto corresponde a um par de valores para w e b que usam um custo específico j. Na verdade, esse par de valores do livreto para w e b corresponde a essa função f de x, que é essa linha que você pode ver à esquerda.
Reproduza o vídeo começando em ::45 e siga a transcrição0:45
Essa linha cruza o eixo vertical em 800 porque b é igual a 800 e a inclinação da linha é menos 0,15, porque w é igual a menos 0,15. Agora, se você observar os pontos de dados no conjunto de treinamento, poderá perceber que essa linha não se ajusta bem aos dados. Para essa função f de x, com esses valores de w e b, muitas das previsões para o valor de y estão bem distantes do valor-alvo real de y que está nos dados de treinamento. Como essa linha não é um bom ajuste, se você observar o gráfico de j, o custo dessa linha está aqui, o que está bem longe do mínimo. O custo é bastante alto porque essa escolha de w e b simplesmente não é muito boa para o conjunto de treinamento. Agora, vamos ver outro exemplo com uma escolha diferente de w e b. Agora, aqui está outra função que ainda não é adequada para os dados, mas talvez um pouco menos ruim. Esses pontos aqui representam o custo desse par de livretos de w e b que cria essa linha. O valor de w é igual a 0 e o valor b é cerca de 360. Esse par de parâmetros corresponde a essa função, que é uma linha plana, porque f de x é igual a 0 vezes x mais 360. Espero que isso faça sentido. Vejamos mais um exemplo. Aqui está mais uma opção para w e b, e com esses valores, você acaba com essa linha f de x. Novamente, não é um bom ajuste para os dados, na verdade está mais distante do mínimo em comparação com o exemplo anterior. Lembre-se de que o mínimo está no centro da menor elipse. Por último exemplo, se você observar f de x à esquerda, isso parece um ajuste muito bom para o conjunto de treinamento. Você pode ver à direita que esse ponto representando o custo está bem próximo do centro da elipse menor, não é exatamente o mínimo, mas está bem próximo. Para esse valor de w e b, você chega a essa linha, f de x. Você pode ver que, se medir as distâncias verticais entre os pontos de dados e os valores previstos na linha reta, obterá o erro para cada ponto de dados. A soma dos erros quadrados de todos esses pontos de dados é bem próxima da soma mínima possível dos erros quadrados entre todos os ajustes de linha reta possíveis. Espero que, ao analisar esses números, você possa ter uma ideia melhor de como as diferentes escolhas dos parâmetros afetam a linha f de x e como isso corresponde a valores diferentes para o custo j, e espero que você possa ver como as linhas de melhor ajuste correspondem aos pontos no gráfico de j que estão mais próximos do custo mínimo possível para essa função de custo j de w e b. No laboratório opcional que segue este vídeo, você poderá executar alguns códigos e lembrar todo o código é fornecido, então você só precisa pressionar Shift Enter para executá-lo e dê uma olhada e o laboratório mostrará como a função de custo é implementada no código. Com um pequeno conjunto de treinamento e diferentes opções para os parâmetros, você poderá ver como o custo varia dependendo de quão bem o modelo se ajusta aos dados. No laboratório opcional, você também pode jogar com um gráfico de console interativo. Confira isso. Você pode usar o cursor do mouse para clicar em qualquer lugar no gráfico de contorno e você verá a linha reta definida pelos valores escolhidos para os parâmetros w e b. Você verá um ponto aqui também no gráfico de superfície 3D mostrando o custo. Finalmente, o laboratório opcional também tem um gráfico de superfície 3D que você pode girar e girar manualmente usando o cursor do mouse para ver melhor a aparência da função de custo. Espero que você goste de brincar com o laboratório opcional. Agora, em regressão linear, em vez de ter que tentar ler manualmente um gráfico de contorno para obter o melhor valor para w e b, o que não é realmente um bom procedimento e também não funcionará quando chegarmos a modelos de aprendizado de máquina mais complexos. O que você realmente quer é um algoritmo eficiente que você possa escrever em código para encontrar automaticamente os valores dos parâmetros w e b; eles fornecem a linha de melhor ajuste. Isso minimiza a função de custo j. Existe um algoritmo para fazer isso chamado gradiente descendente. Esse algoritmo é um dos algoritmos mais importantes no aprendizado de máquina. A descida de gradiente e as variações na descida de gradiente são usadas para treinar não apenas a regressão linear, mas alguns dos maiores e mais complexos modelos de toda a IA. Vamos ao próximo vídeo para mergulhar nesse algoritmo realmente importante chamado gradiente descendente.
