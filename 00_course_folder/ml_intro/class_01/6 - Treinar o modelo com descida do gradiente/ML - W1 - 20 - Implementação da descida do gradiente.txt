Vamos dar uma olhada em como você pode realmente implementar o algoritmo de descida de gradiente. Deixe-me anotar o algoritmo de gradiente descendente. Aqui está. Em cada etapa, w, o parâmetro, é atualizado para o valor antigo de w menos Alpha vezes esse termo d/dw da função cos J de wb. O que essa expressão está dizendo é, após seu parâmetro w, pegando o valor atual de w e ajustando-o em uma pequena quantidade, que é essa expressão à direita, menos Alfa vezes esse termo aqui.
Reproduza o vídeo começando em ::48 e siga a transcrição0:48
Se você acha que há muita coisa acontecendo nessa equação, tudo bem, não se preocupe. Vamos desempacotá-lo juntos. Primeiro, essa notação igual aqui. Agora, como eu disse, estamos atribuindo a w um valor usando esse sinal de igual, nesse contexto, esse sinal de igual é o operador de atribuição. Especificamente, nesse contexto, se você escrever um código que diz que a é igual a c, significa pegar o valor c e armazená-lo em seu computador, na variável a. Ou se você escrever a igual a mais 1, significa definir o valor de a como igual a mais 1, ou incrementar o valor de a em um. A codificação do operador de atribuição é diferente das afirmações de verdade em matemática. Onde se eu escrever a igual a c, estou afirmando, ou seja, estou afirmando que os valores de a e c são iguais entre si. Espero que eu nunca escreva uma afirmação verdadeira igual a mais 1, porque isso simplesmente não pode ser verdade.
Reproduza o vídeo começando em :2:5 e siga a transcrição2:05
Em Python e em outras linguagens de programação, as afirmações de verdade às vezes são escritas como iguais, então você pode ver oh, que diz que a é igual a c se você estiver testando se a é igual a c. Mas na notação matemática, como a usamos convencionalmente, como nesses vídeos, o sinal de igual pode ser usado para tarefas ou para afirmação de verdade. Tento ter certeza de que fui claro ao escrever um sinal de igualdade, se estamos atribuindo um valor a uma variável ou se estamos afirmando a verdade da igualdade de dois valores. Agora, vamos mergulhar mais profundamente no que significam os símbolos dessa equação. O símbolo aqui é o alfabeto grego Alpha. Nessa equação, Alpha também é chamado de taxa de aprendizado. A taxa de aprendizado geralmente é um pequeno número positivo entre 0 e 1 e pode ser, digamos, 0,01. O que o Alpha faz é basicamente controlar o tamanho do passo que você dá ladeira abaixo. Se o Alpha for muito grande, isso corresponde a um procedimento de descida de gradiente muito agressivo, no qual você está tentando dar grandes passos ladeira abaixo. Se Alpha for muito pequeno, você estaria dando pequenos passos ladeira abaixo. Voltaremos mais tarde para nos aprofundar mais em como escolher uma boa taxa de aprendizado Alpha. Finalmente, esse termo aqui é o termo derivado da função de custo J. Não vamos nos preocupar com os detalhes dessa derivada agora. Mas, mais tarde, você verá mais sobre o termo derivado. Mas, por enquanto, você pode pensar nesse termo derivado em torno do qual desenhei uma caixa magenta dizendo em que direção você quer dar o passo do bebê. Em combinação com a taxa de aprendizado Alpha, ela também determina o tamanho das etapas que você deseja seguir ladeira abaixo. Agora, eu quero mencionar que as derivadas vêm do cálculo. Mesmo que você não esteja familiarizado com o cálculo, não se preocupe com isso. Mesmo sem conhecer nenhum cálculo, você poderá descobrir tudo o que precisa saber sobre esse termo derivado neste vídeo e no próximo. Mais uma coisa. Lembre-se de que seu modelo tem dois parâmetros, não apenas w, mas também b. Você também tem uma operação de atribuição que atualiza o parâmetro b que parece muito semelhante. b recebe o valor antigo de b menos a taxa de aprendizado Alpha vezes esse termo derivado ligeiramente diferente, d/db de J de wb. Lembre-se de que, no gráfico do gráfico de superfície, você está dando pequenos passos até chegar ao final do valor. Bem, para o algoritmo de gradiente descendente, você repetirá essas duas etapas de atualização até que o algoritmo converja. Por convergências, quero dizer que você atinge um ponto no mínimo local em que os parâmetros w e b não mudam mais muito a cada etapa adicional que você dá. Agora, há mais um detalhe sutil sobre como corrigir a descida do gradiente semântico, você atualizará dois parâmetros, w e b. Essa atualização ocorre para ambos os parâmetros, w e b. Um detalhe importante é que, para o gradiente descendente, você deseja atualizar simultaneamente w e b, o que significa que você deseja atualizar os dois parâmetros ao mesmo tempo. O que quero dizer com isso é que, nessa expressão, você atualizará w do antigo w para um novo w e também atualizará b do valor mais antigo para um novo valor de b. A maneira de implementar isso é computar o lado direito, computando essa coisa para w e b e, simultaneamente, atualizar w e b para os novos valores. Vamos dar uma olhada no que isso significa. Aqui está a maneira correta de implementar o gradiente descendente que faz uma atualização simultânea. Isso define uma variável temp_w igual a essa expressão, que é w menos esse termo aqui. Também há um conjunto em outra variável temp_b para isso, que é b menos esse termo.
Reproduza o vídeo começando em :6:36 e siga a transcrição6:36
Você calcula os dois lados, ambas as atualizações, e as armazena nas variáveis temp_w e temp_b. Em seguida, você copia o valor de temp_w em w e também copia o valor de temp_b em b. Agora, uma coisa que você pode notar é que esse valor de w é do for w é atualizado. Aqui, notei que a pré-atualização w é onde entra no termo derivado aqui. Em contraste, aqui está uma implementação incorreta do gradiente descendente que não faz uma atualização simultânea. Nessa implementação incorreta, calculamos temp_w, da mesma forma que antes, até agora está tudo bem. Agora é aqui que as coisas começam a diferir. Em seguida, atualizamos w com o valor em temp_w antes de calcular o novo valor para o outro parâmetro. Em seguida, calculamos temp_b como b menos esse termo aqui e, finalmente, atualizamos b com o valor em temp_b. A diferença entre as implementações do lado direito e do lado esquerdo é que, se você olhar aqui, esse w já foi atualizado para esse novo valor, e isso é o w atualizado que realmente entra na função de custo j de w, b. Isso significa que esse termo aqui à direita não é o mesmo que este termo aqui que você vê à esquerda. Isso também significa que esse termo temp_b à direita não é exatamente o mesmo que o termo temp b à esquerda e, portanto, esse valor atualizado para b à direita não é o mesmo que esse valor atualizado para a variável b à esquerda. Da forma como o gradiente descendente é implementado no código, na verdade, é mais natural implementá-lo da maneira correta com atualizações simultâneas. Quando você ouve alguém falar sobre descida de gradiente, essa pessoa sempre se refere às descidas de gradiente em que você executa uma atualização simultânea dos parâmetros. Se, no entanto, você implementasse uma atualização não simultânea, provavelmente funcionará mais ou menos de qualquer maneira. Mas fazer isso dessa maneira não é realmente a maneira correta de implementá-lo, é na verdade algum outro algoritmo com propriedades diferentes. Eu aconselho você a manter a atualização simultânea correta e não usar essa versão incorreta à direita. Isso é gradiente descendente. No próximo vídeo, entraremos em detalhes sobre o termo derivado que você viu neste vídeo, mas sobre o qual realmente não falamos em detalhes. As derivadas fazem parte do cálculo e, novamente, se você não estiver familiarizado com o cálculo, não se preocupe com isso. Você não precisa saber nada sobre cálculo para concluir este curso ou essa especialização e tem todas as informações necessárias para implementar o gradiente descendente. No próximo vídeo, analisaremos os derivados juntos e você terá a intuição e o conhecimento necessários para poder implementar e aplicar o gradiente descendente sozinho. Acho que será interessante para você saber como implementar. Vamos ao próximo vídeo para ver como fazer isso.
(Obrigatória)
pt-BR
​

