No último vídeo, vimos que a regularização tenta reduzir os valores parentais de W1 a WN para reduzir o sobreajuste. Neste vídeo, desenvolveremos essa intuição e desenvolveremos uma função de custo modificada para seu algoritmo de aprendizado que pode ser usada para realmente aplicar a regularização. Vamos começar, relembre este exemplo do vídeo anterior, no qual vimos que, se você ajusta uma função quadrática a esses dados, ela dá um ajuste muito bom. Mas se você ajustar um polinômio de ordem muito alta, acabará com uma curva que se ajusta demais aos dados. Mas agora considere o seguinte, suponha que você tenha uma maneira de tornar os parâmetros W3 e W4 muito, muito pequenos. Diga perto de 0. Aqui está o que eu quero dizer. Digamos que, em vez de minimizar essa função objetivo, essa seja uma função de custo para regressão linear. Digamos que você modifique a função de custo e adicione-a 1000 vezes W3 ao quadrado mais 1000 vezes W4 ao quadrado. E aqui estou escolhendo 1000 porque é um número grande, mas qualquer outro número realmente grande estaria bem. Portanto, com essa função de custo modificada, você pode de fato penalizar o modelo se W3 e W4 forem grandes. Porque se você quiser minimizar essa função, a única maneira de tornar essa nova função de custo pequena é se W3 e W4 forem pequenos, certo? Porque, caso contrário, esses termos 1000 vezes W3 ao quadrado e 1000 vezes W4 quadrados serão muito, muito grandes. Então, quando você minimiza essa função, você vai acabar com W3 perto de 0 e W4 perto de 0. Portanto, estamos efetivamente quase cancelando os efeitos da execução dos recursos e da potência extra de 4 e nos livrando desses dois termos aqui. E se fizermos isso, acabaremos com um ajuste nos dados que está muito mais próximo da função quadrática, incluindo talvez apenas pequenas contribuições das características x ao cubo e 4 extras. E isso é bom porque se ajusta muito melhor aos dados do que se todos os parâmetros pudessem ser grandes e você acabasse com essa função quadrática semanal de forma mais geral, aqui está a ideia por trás da regularização. A ideia é que, se houver valores menores para os parâmetros, isso é um pouco como ter um modelo mais simples. Talvez um com menos recursos, o que, portanto, é menos propenso ao sobreajuste. No último slide, penalizamos ou dizemos que regularizamos apenas W3 e W4. Mas, de forma mais geral, a forma como a regularização tende a ser implementada é que, se você tiver muitos recursos, digamos, 100 recursos, talvez não saiba quais são os recursos mais importantes e quais devem ser penalizados. Portanto, a forma como a regularização é normalmente implementada é penalizar todos os recursos ou, mais precisamente, você penaliza todos os parâmetros do WJ e é possível mostrar que isso geralmente resulta no ajuste de uma função semanal mais suave, simples e menos propensa a ajustes excessivos. Portanto, neste exemplo, se você tiver dados com 100 recursos para cada casa, pode ser difícil escolher antecipadamente quais recursos incluir e quais excluir. Então, vamos criar um modelo que use todos os 100 recursos. Então você tem esses 100 parâmetros W1 a W100, bem como 100 e o primeiro parâmetro B. Porque não sabemos quais desses parâmetros serão os mais importantes. Vamos penalizar um pouco todos eles e reduzi-los adicionando esse novo termo lambda vezes a soma de J igual a 1 a n, onde n é 100. O número de características de wj squared. Esse valor lambda aqui é o alfabeto grego lambda e também é chamado de parâmetro de regularização. Assim como escolher uma taxa de aprendizado alfa, agora você também precisa escolher um número para lambda. Algumas coisas que eu gostaria de destacar por convenção, em vez de usar lambda vezes a soma de wj ao quadrado. Também dividimos lambda por 2m para que o 1º e o 2º termos aqui sejam escalados em 1 sobre 2m. Acontece que, ao escalar os dois termos da mesma forma , fica um pouco mais fácil escolher um bom valor para lambda. E, em particular, você descobre que, mesmo que o tamanho do seu conjunto de treinamento aumente, digamos que você encontre mais exemplos de treinamento. Então m, o tamanho do conjunto de treinamento agora é maior. O mesmo valor de lambda que você escolheu anteriormente agora também tem mais chances de continuar funcionando se você tiver essa escala extra em 2m. Além disso, por convenção, não vamos penalizar o parâmetro b por ser grande. Na prática, faz pouca diferença se você faz ou não. E alguns engenheiros de aprendizado de máquina e, na verdade, algumas implementações de algoritmos de aprendizado também incluirão lambda mais de 2 milhões de vezes o termo b quadrado. Mas isso faz pouca diferença na prática e a convenção mais comum que foi usada neste curso é regularizar somente os parâmetros w em vez do parâmetro b. Então, para resumir nesta função de custo modificada, queremos minimizar o custo original, que é o custo médio quadrático do erro mais, adicionalmente, o segundo termo que é chamado de termo de regularização. Portanto, essa nova função de custo compensa duas metas que você possa ter. Tentar minimizar esse primeiro termo incentiva o algoritmo a ajustar bem os dados de treinamento, minimizando as diferenças quadradas das previsões e dos valores reais. E tente minimizar o segundo mandato. O algoritmo também tenta manter os parâmetros wj pequenos, o que tende a reduzir o sobreajuste. O valor de lambda que você escolhe especifica a importância relativa ou a compensação relativa ou como você se equilibra entre essas duas metas. Vamos dar uma olhada em quais valores diferentes de lambda farão com que você esteja aprendendo o algoritmo a fazer. Vamos usar o exemplo de previsão do preço da habitação usando regressão linear. Então F de X é o modelo de regressão linear. Se lambda foi definido como 0, você não está usando o termo de regularização porque o termo de regularização é multiplicado por 0. Então, se lambda fosse 0, você acabaria ajustando essa curva excessivamente ondulada e excessivamente complexa e ela se ajusta demais. Então esse era um extremo de se lambda fosse 0. Vamos agora ver o outro extremo. Se você disse que lambda é um número muito, muito, muito grande, digamos que lambda seja igual a 10 elevado a 10, então você está colocando um peso muito grande nesse termo de regularização à direita. E a única maneira de minimizar isso é ter certeza de que todos os valores de w estão praticamente muito próximos de 0. Portanto, se lambda for muito, muito grande, o algoritmo de aprendizado escolherá W1, W2, W3 e W4 para serem extremamente próximos de 0 e, portanto, F de X é basicamente igual a b e, portanto, o algoritmo de aprendizado se ajusta a uma linha reta horizontal e a um ajuste inferior. Para recapitular, se lambda é 0, esse modelo se ajustará demais. Se lambda for enorme, como 10 elevado a 10. Este modelo será inadequado. Então, o que você quer é algum valor de lambda intermediário que equilibre mais adequadamente esses primeiro e segundo termos de negociação, minimizando o erro quadrático médio e mantendo os parâmetros pequenos. E quando o valor de lambda não é muito pequeno nem muito grande, mas está certo, espero que você consiga ajustar um polinômio de 4ª ordem, mantendo todas essas características, mas com uma função parecida com essa. Então é assim que a regularização funciona. Quando falamos sobre seleção de modelos, mais tarde na especialização também veremos uma variedade de maneiras de escolher bons valores para lambda. Nos próximos dois vídeos, explicaremos como aplicar a regularização à regressão linear e à regressão logística, e como treinar esses modelos com grande discordância com isso, você poderá evitar o sobreajuste com esses dois algoritmos.
