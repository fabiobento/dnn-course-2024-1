Posteriormente nesta especialização, falaremos sobre como depurar e diagnosticar coisas que podem dar errado com algoritmos de aprendizado. Você também aprenderá sobre ferramentas específicas para reconhecer quando o ajuste excessivo ou insuficiente pode estar ocorrendo. Mas, por enquanto, quando você acha que ocorreu um ajuste excessivo, vamos falar sobre o que você pode fazer para resolvê-lo. Digamos que você se encaixe em um modelo e ele tenha alta variância, seja sobreajustado. Aqui está nosso modelo de previsão de preços de casas sobreajustadas. Uma maneira de resolver esse problema é coletar mais dados de treinamento, essa é uma opção. Se você conseguir obter mais dados, ou seja, mais exemplos de treinamento sobre tamanhos e preços de casas , com o conjunto de treinamento maior, o algoritmo de aprendizado aprenderá a ajustar uma função menos instável. Você pode continuar ajustando um polinômio de alta ordem ou alguma função com muitos recursos e, se tiver exemplos de treinamento suficientes, ele ainda funcionará bem. Resumindo, a ferramenta número um que você pode usar contra o sobreajuste é obter mais dados de treinamento. Agora, obter mais dados nem sempre é uma opção. Talvez apenas algumas casas tenham sido vendidas neste local, então talvez não haja mais dados a serem adicionados. Mas quando os dados estão disponíveis, isso pode funcionar muito bem. Uma segunda opção para lidar com o sobreajuste é verificar se você pode usar menos recursos. No vídeo anterior, os recursos de nossos modelos incluíam o tamanho x, bem como o tamanho quadrado, e esse x ao quadrado e x ao cubo e x^4 e assim por diante. Essas eram muitas características polinomiais. Nesse caso, uma forma de reduzir o sobreajuste é simplesmente não usar tantos desses recursos polinomiais. Mas agora vamos ver um exemplo diferente. Talvez você tenha muitas características diferentes de uma casa para tentar prever seu preço, variando do tamanho, número de quartos, número de andares, idade, renda média do bairro e assim por diante, até a distância total até a cafeteria mais próxima. Acontece que, se você tem muitos recursos como esses, mas não tem dados de treinamento suficientes , seu algoritmo de aprendizado também pode se adequar ao seu conjunto de treinamento. Agora, em vez de usar todos os 100 recursos, escolheríamos apenas um subconjunto dos mais úteis, talvez o tamanho, os quartos e a idade da casa. Se você acha que esses são os recursos mais relevantes , usando apenas esse menor subconjunto de recursos, você pode descobrir que seu modelo não se encaixa mais tão mal. A escolha do conjunto mais apropriado de recursos a ser usada às vezes também é chamada de seleção de recursos. Uma maneira de fazer isso é usar sua intuição para escolher o que você acha que é o melhor conjunto de recursos, o que é mais relevante para prever o preço. Agora, uma desvantagem da seleção de recursos é que, ao usar apenas um subconjunto dos recursos, o algoritmo está descartando algumas das informações que você tem sobre as casas. Por exemplo, talvez todos esses recursos, todos os 100 deles, sejam realmente úteis para prever o preço de uma casa. Talvez você não queira jogar fora algumas das informações jogando fora alguns dos recursos. Posteriormente, no Curso 2, você também verá alguns algoritmos para escolher automaticamente o conjunto de recursos mais apropriado para usar em nossa tarefa de previsão. Agora, isso nos leva à terceira opção para reduzir o sobreajuste. Essa técnica, que veremos com ainda mais profundidade no próximo vídeo, é chamada de regularização. Se você observar um modelo sobreajustado, aqui está um modelo usando características polinomiais: x, x ao quadrado, x ao cubo e assim por diante. Você descobre que os parâmetros geralmente são relativamente grandes. Agora, se você eliminasse alguns desses recursos, digamos, se eliminasse o recurso x4, isso corresponderia à configuração desse parâmetro como 0. Portanto, definir um parâmetro como 0 equivale a eliminar um recurso, que foi o que vimos no slide anterior. Acontece que a regularização é uma forma de reduzir mais suavemente os impactos de alguns dos recursos sem fazer algo tão severo quanto eliminá-los de imediato. O que a regularização faz é incentivar o algoritmo de aprendizado a reduzir os valores dos parâmetros sem necessariamente exigir que o parâmetro seja definido como exatamente 0. Acontece que mesmo que você ajuste um polinômio de ordem superior como esse, contanto que você consiga que o algoritmo use valores de parâmetros menores: w1, w2, w3, w4. Você acaba com uma curva que acaba se ajustando muito melhor aos dados de treinamento. Então, o que a regularização faz é permitir que você mantenha todos os seus recursos, mas apenas evita que os recursos tenham um efeito muito grande, o que às vezes pode causar sobreajuste. A propósito, por convenção, normalmente reduzimos o tamanho dos parâmetros wj, ou seja, w1 a wn. Não faz grande diferença se você regulariza o parâmetro b também; você pode fazer isso se quiser ou não, se não quiser. Normalmente não faço isso e não há problema em regularizar w1, w2, até ganhar, mas não encorajar b a ficar menor. Na prática, deve fazer pouca diferença se você também regulariza b ou não. Para recapitular, essas são as três maneiras que você viu neste vídeo para lidar com o sobreajuste. Primeiro, colete mais dados. Se você puder obter mais dados, isso pode realmente ajudar a reduzir o sobreajuste. Às vezes, isso não é possível. Nesse caso, algumas das opções são: duas, tente selecionar e usar apenas um subconjunto dos recursos. Você aprenderá mais sobre a seleção de recursos no Curso 2. A terceira seria reduzir o tamanho dos parâmetros usando a regularização. Esse também será o assunto do próximo vídeo. Só para mim, eu uso a regularização o tempo todo. Portanto, essa é uma técnica muito útil para treinar algoritmos de aprendizado, incluindo redes neurais especificamente, que você também verá mais tarde nesta especialização. Espero que você também confira o laboratório opcional sobre sobremontagem. No laboratório, você poderá ver diferentes exemplos de sobreajuste e ajustar esses exemplos clicando nas opções nos gráficos. Você também poderá adicionar seus próprios pontos de dados clicando no gráfico e ver como isso altera a curva ajustada. Você também pode tentar exemplos de regressão e classificação e alterar o grau do polinômio para x, x ao quadrado, x ao cubo e assim por diante. O laboratório também permite que você use duas opções diferentes para lidar com o sobreajuste. Você pode adicionar dados de treinamento adicionais para reduzir o sobreajuste e também pode selecionar quais recursos incluir ou excluir como outra forma de tentar reduzir o sobreajuste. Por favor, dê uma olhada em um laboratório, que espero que ajude você a desenvolver sua intuição sobre o sobreajuste, bem como alguns métodos para lidar com isso. Neste vídeo, você também viu a ideia de regularização em um nível relativamente alto. Sei que todos esses detalhes sobre regularização podem não fazer todo o sentido para você ainda. Mas no próximo vídeo, começaremos a formular exatamente como aplicar a regularização e exatamente o que significa regularização. Em seguida, começaremos a descobrir como fazer isso funcionar com nossos algoritmos de aprendizado para fazer regressão linear e regressão logística e, no futuro, outros algoritmos também evitarão ajustes excessivos. Vamos dar uma olhada nisso no próximo vídeo.
