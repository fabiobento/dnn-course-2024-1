{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec2783",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório.\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/ml_intro/class_03/Laborat%C3%B3rios/lab_utils_ml_intro_week_3.zip\n",
    "!unzip -n -q lab_utils_ml_intro_week_3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão, Perda Logística\n",
    "\n",
    "Neste laboratório, você irá:\n",
    "- explorar a razão pela qual a perda de erro quadrático não é apropriada para regressão logística\n",
    "- explorar a função de perda logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8607414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from plt_logistic_loss import  plt_logistic_cost, plt_two_logistic_loss_curves, plt_simple_example\n",
    "from plt_logistic_loss import soup_bowl, plt_logistic_squared_error\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6579e",
   "metadata": {},
   "source": [
    "## Erro quadrático para regressão logística?\n",
    "<img align=\"left\" src=\"./images/C1_W3_SqErrorVsLogistic.png\"     style=\" width:400px; padding: 10px; \" >Lembre-se de que para a regressão **Linear** usamos a **função de custo do erro quadrático**:\n",
    "A equação para o custo do erro quadrático com uma variável é:\n",
    "  $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{1}$$ \n",
    " \n",
    "onde \n",
    "  $$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c8fc2",
   "metadata": {},
   "source": [
    "Lembre-se de que o custo do erro quadrático tinha a ela propriedade de que seguir a derivada do custo leva ao mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_bowl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eae79e",
   "metadata": {},
   "source": [
    "Esta função de custo funcionou bem para regressão linear, é natural considerá-la também para regressão logística. No entanto, como mostra o slide acima, $f_{wb}(x)$ agora tem um componente não linear, a função sigmóide: $f_{w,b}(x^{(i)}) = sigmoid(wx ^{(i)} + b)$. Vamos tentar um custo de erro quadrático no exemplo de um laboratório anterior, agora incluindo o sigmóide.\n",
    "\n",
    "Aqui estão nossos dados de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a569dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0., 1, 2, 3, 4, 5],dtype=np.longdouble)\n",
    "y_train = np.array([0,  0, 0, 1, 1, 1],dtype=np.longdouble)\n",
    "plt_simple_example(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15887fb",
   "metadata": {},
   "source": [
    "Agora, vamos obter um gráfico de superfície do custo usando um *custo de erro quadrático*:\n",
    "   $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y ^{(i)})^2 $$\n",
    " \n",
    "onde\n",
    "   $$f_{w,b}(x^{(i)}) = sigmoide(wx^{(i)} + b )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e45164",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt_logistic_squared_error(x_train,y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bcaff",
   "metadata": {},
   "source": [
    "Embora isso produza um gráfico bastante interessante, a superfície acima não é tão lisa quanto a 'tigela de sopa' da regressão linear!\n",
    "\n",
    "A regressão logística requer uma função de custo mais adequada à sua natureza não linear. Isso começa com uma função Loss. Isso é descrito abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b207388",
   "metadata": {},
   "source": [
    "## Função de Perda Logística\n",
    "<img align=\"left\" src=\"./images/C1_W3_LogisticLoss_a.png\"     style=\" width:250px; padding: 2px; \" >\n",
    "<img align=\"left\" src=\"./images/C1_W3_LogisticLoss_b.png\"     style=\" width:250px; padding: 2px; \" >\n",
    "<img align=\"left\" src=\"./images/C1_W3_LogisticLoss_c.png\"     style=\" width:250px; padding: 2px; \" > "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211b600",
   "metadata": {},
   "source": [
    "A regressão logística usa uma função de perda mais adequada para a tarefa de categorização onde o alvo é 0 ou 1 em vez de qualquer número.\n",
    "\n",
    ">**Nota de definição:** Neste curso, estas definições são usadas:\n",
    "**Perda** é uma medida da diferença de um único exemplo em relação ao seu valor alvo, enquanto o\n",
    "**Custo** é uma medida das perdas no conjunto de treinamento\n",
    "\n",
    "\n",
    "Segue definição de perda(_loss_): \n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ é o custo de um único ponto de dados, que é:\n",
    "\n",
    "\\begin{equation}\n",
    "  loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = \\begin{cases}\n",
    "    - \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) & \\text{if $y^{(i)}=1$}\\\\\n",
    "    - \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) & \\text{if $y^{(i)}=0$}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$é a previsão do modelo, enquanto $y^{(i)}$ é o valor alvo.\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot\\mathbf{x}^{(i)}+b)$ onde a função $g$ é a função sigmóide.\n",
    "\n",
    "A característica definidora desta função de perda é o fato de ela usar duas curvas separadas. Um para o caso em que o alvo é zero ou ($y=0$) e outro para quando o alvo é um ($y=1$). Combinadas, essas curvas fornecem o comportamento útil para uma função de perda, ou seja, sendo zero quando a previsão corresponde ao alvo e aumentando rapidamente em valor à medida que a previsão difere do alvo. Considere as curvas abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_two_logistic_loss_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7ce37",
   "metadata": {},
   "source": [
    "Combinadas, as curvas são semelhantes à curva quadrática da perda de erro quadrática. Observe que o eixo x é $f_{\\mathbf{w},b}$ que é a saída de um sigmóide. A saída sigmóide está estritamente entre 0 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c45e2c",
   "metadata": {},
   "source": [
    "A função de perda acima pode ser reescrita para ser mais fácil de implementar.\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)$$\n",
    "  \n",
    "Esta é uma equação de aparência um pouco \"intimidadora\" :-). É menos assustador quando você considera que $y^{(i)}$ pode ter apenas dois valores, 0 e 1. Pode-se então considerar a equação em duas partes:\n",
    "quando $ y^{(i)} = 0$, o termo da esquerda é eliminado:\n",
    "$$\n",
    "\\begin{align}\n",
    "loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), 0) &= (-(0) \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - 0\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\\\\n",
    "&= -\\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "e quando $ y^{(i)} = 1$, o termo da direita é eliminado:\n",
    "$$\n",
    "\\begin{align}\n",
    "  loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), 1) &=  (-(1) \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - 1\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\\\\\n",
    "  &=  -\\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "OK, com esta nova função de perda logística, pode ser produzida uma função de custo que incorpore a perda de todos os exemplos. Este será o tema do próximo laboratório. Por enquanto, vamos dar uma olhada na curva de custo versus parâmetros do exemplo simples que consideramos acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850399b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "cst = plt_logistic_cost(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta curva é adequada para descida gradiente! Não possui platôs, mínimos locais ou descontinuidades. Observe que não é uma tigela como no caso do erro quadrático. Tanto o custo quanto o logaritmo do custo são traçados para esclarecer o fato de que a curva, quando o custo é pequeno, tem uma inclinação e continua a diminuir. Lembrete: você pode girar os gráficos acima usando o mouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parabéns!\n",
    "Você tem:\n",
    "  - determinou que uma função de perda de erro quadrática não é adequada para tarefas de classificação\n",
    "  - desenvolveu e examinou a função de perda logística que **é** adequada para tarefas de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
