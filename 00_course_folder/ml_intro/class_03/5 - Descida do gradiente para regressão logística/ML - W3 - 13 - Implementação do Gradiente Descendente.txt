Para ajustar os parâmetros de um modelo de regressão logística, vamos tentar encontrar os valores dos parâmetros w e b que minimizem a função de custo J de w e b, e aplicaremos novamente o gradiente descendente para fazer isso. Vamos dar uma olhada em como. Neste vídeo, vamos nos concentrar em como encontrar uma boa escolha dos parâmetros w e b. Depois de fazer isso, se você der ao modelo uma nova entrada, x, digamos, um novo paciente no hospital com um determinado tamanho e idade do tumor, então esses são diagnósticos. O modelo pode então fazer uma previsão ou tentar estimar a probabilidade de que o rótulo y seja um. A média que você pode usar para minimizar a função de custo é o gradiente descendente. Aqui está novamente a função de custo. Se você quiser minimizar o custo j em função de w e b, bem, aqui está o algoritmo usual de gradiente descendente, em que você atualiza repetidamente cada parâmetro como o valor 0 menos Alpha, a taxa de aprendizado multiplicada por esse termo derivado. Vamos dar uma olhada na derivada de j em relação a w_j. Esse termo aqui em cima, onde, como de costume, j vai de um a n, onde n é o número de características. Se alguém aplicasse as regras do cálculo, você pode mostrar que a derivada em relação a w_j da função de custo capital J é igual a essa expressão aqui, é 1 sobre m vezes a soma de 1 a m desse termo de erro. Isso é f menos o rótulo y vezes x_j. Aqui estão apenas x I j é a característica j do exemplo de treinamento i. Agora, vamos ver também a derivada de j em relação ao parâmetro b. Acontece que é essa expressão aqui. É muito semelhante à expressão acima, exceto pelo fato de não ser multiplicada por esse símbolo x sobrescrito i j no final. Apenas como um lembrete, semelhante ao que você viu para a regressão linear, a maneira de realizar essas atualizações é usar atualizações simultâneas, o que significa que você primeiro calcula o lado direito de todas essas atualizações e, em seguida, substitui simultaneamente todos os valores à esquerda ao mesmo tempo. Deixe-me pegar essas expressões derivadas aqui e inseri-las nesses termos aqui. Isso fornece gradiente descendente para regressão logística. Agora, uma coisa engraçada que você pode estar se perguntando é: isso é estranho. Essas duas equações se parecem exatamente com a média que criamos anteriormente para regressão linear, então você pode estar se perguntando: a regressão linear é, na verdade, secretamente a mesma coisa que a regressão logística? Bem, mesmo que essas equações pareçam as mesmas, a razão pela qual isso não é uma regressão linear é porque a definição da função f de x mudou. Na regressão linear, f de x é, isso é wx mais b. Mas na regressão logística, f de x é definido como a função sigmóide aplicada a wx mais b. Embora o algoritmo escrito tenha a mesma aparência tanto para regressão linear quanto para regressão logística, na verdade eles são dois algoritmos muito diferentes porque a definição de f de x não é a mesma. Quando falamos sobre gradiente descendente para regressão linear anteriormente, você viu como monitorar uma descida de gradiente para garantir que ela converja. Você pode simplesmente aplicar o mesmo método para regressão logística para garantir que ela também converja. Eu escrevi essas atualizações como se você estivesse atualizando os parâmetros w_j, um parâmetro por vez. Semelhante à discussão sobre implementações vetorizadas de regressão linear, você também pode usar a vetorização para fazer com que a descida de gradiente funcione mais rapidamente na regressão logística. Não vou me aprofundar nos detalhes da implementação vetorizada neste vídeo. Mas você também pode aprender mais sobre isso e ver o código nos laboratórios opcionais. Agora você sabe como implementar o gradiente descendente para regressão logística. Você também deve se lembrar do dimensionamento de recursos quando estávamos usando regressão linear. Onde você viu como escalar recursos, ou seja, escalar todos os recursos para assumir faixas de valores semelhantes, digamos, entre menos 1 e mais 1, como eles podem ajudar a descida do gradiente a convergir mais rapidamente. A
Reproduza o vídeo começando em :5:8 e siga a transcrição5:08
escala de recursos aplicada da mesma forma para escalar as diferentes características para assumir faixas de valores semelhantes também pode acelerar a descida do gradiente para regressão logística. No próximo laboratório opcional, você também verá como o gradiente da regressão logística pode ser calculado em código. Será útil analisar isso porque você também implementará isso no laboratório prático no final desta semana. Depois de executar a descida de gradiente neste laboratório, haverá um bom conjunto de gráficos animados que mostram a descida de gradiente em ação. Você vê a função sigmóide, o gráfico de contorno do custo, o gráfico de superfície 3D do custo e a curva de aprendizado ou evolui à medida que a descida do gradiente ocorre. Depois disso, haverá outro laboratório opcional, que é curto e agradável, mas também muito útil porque eles estão mostrando como usar a popular biblioteca scikit-learn para treinar o modelo de regressão logística para classificação.
Reproduza o vídeo começando em :6:7 e siga a transcrição6:07
Atualmente, muitos profissionais de aprendizado de máquina em muitas empresas usam o scikit-learn regularmente como parte de seu trabalho. Espero que você também confira a função scikit-learn e veja como ela é usada. É isso mesmo. Agora você deve saber como implementar a regressão logística. Este é um algoritmo de aprendizado muito poderoso e amplamente usado e agora você sabe como fazê-lo funcionar sozinho. Parabéns.
