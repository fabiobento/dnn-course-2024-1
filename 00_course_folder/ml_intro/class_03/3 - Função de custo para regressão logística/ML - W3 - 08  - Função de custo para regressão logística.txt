Lembre-se de que a função de custo oferece uma maneira de medir o quão bem um conjunto específico de parâmetros se ajusta aos dados de treinamento. Assim, você pode tentar escolher parâmetros melhores. Neste vídeo, veremos como a função de custo de erro quadrático não é uma função de custo ideal para regressão logística. Analisaremos uma função de custo diferente que pode nos ajudar a escolher melhores parâmetros para regressão logística. Veja como pode ser o conjunto de treinamento para nosso modelo de regressão logística. Onde aqui cada fila pode corresponder a pacientes que estavam visitando o médico e um deles recebeu algum diagnóstico. Como antes, usaremos m para indicar o número de exemplos de treinamento. Cada exemplo de treinamento tem uma ou mais características, como o tamanho do tumor, a idade do paciente e assim por diante, totalizando n características. Vamos chamar os recursos de X_1 a X_n. Como essa é uma tarefa de classificação binária, o rótulo de destino y assume apenas dois valores, 0 ou 1. Finalmente, o modelo de regressão logística é definido por essa equação. A pergunta que você quer responder é, dado esse conjunto de treinamento, como você pode escolher os parâmetros w e b? Lembre-se de que, para a regressão linear, essa é a função de custo do erro quadrado. A única coisa que mudei foi colocar a metade dentro da soma em vez de fora da soma. Você deve se lembrar que, no caso da regressão linear, em que f de x é a função linear, w dot x mais b. A função de custo tem essa aparência, é uma função convexa ou em forma de tigela ou martelo. A descida do gradiente ficará assim, onde você dá um passo, um passo e assim por diante para convergir no mínimo global. Agora você pode tentar usar a mesma função de custo para regressão logística. Mas acontece que se eu escrevesse f de x igual a 1 sobre 1 mais e para menos wx mais b e representasse graficamente a função de custo usando esse valor de f de x, o custo ficaria assim. Isso faz com que o que chamamos de função de custo não convexa não seja convexa. O que isso significa é que se você tentasse usar o gradiente descendente. Existem muitos mínimos locais que você pode chupar. Acontece que, para regressão logística, essa função de custo de erro quadrático não é uma boa escolha. Em vez disso, haverá uma função de custo diferente que pode tornar a função de custo convexa novamente. É possível garantir que a descida do gradiente converja para o mínimo global. A única coisa que mudei foi colocar a metade dentro da soma em vez de fora da soma. Isso tornará a matemática que você verá mais adiante neste slide um pouco mais simples. Para criar uma nova função de custo, uma que usaremos para regressão logística. Vou mudar um pouco a definição da função de custo J de w e b. Em particular, se você examinar esse somatório, vamos chamar esse termo de “dentro da perda” em um único exemplo de treinamento. Vou denotar a perda por meio desse L maiúsculo e, em função da previsão do algoritmo de aprendizagem, f de x, bem como do rótulo verdadeiro y. A perda dada pelo preditor f de x e pelo rótulo verdadeiro y é igual, neste caso, a 1,5 da diferença quadrada. Veremos em breve que, ao escolher uma forma diferente para essa função de perda, poderemos manter a função de custo geral, que é 1 sobre n vezes a soma dessas funções de perda, como uma função convexa. Agora, a função de perda insere f de x e o rótulo verdadeiro y e nos diz o quão bem estamos nesse exemplo. Vou apenas escrever aqui a definição da função de perda que usaremos para regressão logística. Se o rótulo y for igual a 1, então a perda é log negativo de f de x e se o rótulo y for igual a 0, então a perda é log negativo de 1 menos f de x. Vamos ver por que essa função de perda talvez faça sentido. Vamos primeiro considerar o caso de y igual a 1 e traçar a aparência dessa função para obter uma intuição sobre o que essa função de perda está fazendo. Lembre-se de que a função de perda mede seu desempenho em um exemplo de treinamento e, ao somar as perdas em todos os exemplos de treinamento que você obtém, a função de custo, que mede o desempenho de todo o conjunto de treinamento. Se você traçar o log de f, parece essa curva aqui, onde f aqui está no eixo horizontal. Um gráfico de um negativo do logaritmo de f é assim, onde simplesmente invertemos a curva ao longo do eixo horizontal. Observe que ele cruza o eixo horizontal em f igual a 1 e continua descendo a partir daí. Agora, f é o resultado da regressão logística. Assim, f está sempre entre zero e um porque a saída da regressão logística está sempre entre zero e um. A única parte da função que é relevante é , portanto, essa parte aqui, correspondente a f entre 0 e 1. Vamos ampliar e examinar mais de perto essa parte do gráfico. Se o algoritmo prediz uma probabilidade próxima de 1 e o rótulo verdadeiro é 1 , a perda é muito pequena. É praticamente 0 porque você está muito perto da resposta certa. Agora continue com o exemplo do verdadeiro rótulo y sendo 1, digamos que tudo é um tumor maligno. Se o algoritmo prevê 0,5, então a perda ocorre neste ponto aqui, que é um pouco maior, mas não tão alta. Por outro lado, se o algoritmo tivesse resultados de 0,1, pensaria que há apenas 10% de chance de o tumor ser maligno, mas y realmente é 1. Se realmente é maligno, então a perda é um valor muito maior por aqui. Quando y é igual a 1, a função de perda incentiva, estimula ou ajuda a impulsionar o algoritmo a fazer previsões mais precisas porque a perda é menor, quando prediz valores próximos a 1. Agora, neste slide, veremos qual é a perda quando y é igual a 1. Neste slide, vamos ver a segunda parte da função de perda correspondente a quando y é igual a 0. Nesse caso, a perda é log negativo de 1 menos f de x. Quando essa função é plotada, ela realmente fica assim. O intervalo de f é limitado a 0 a 1 porque a regressão logística só gera valores entre 0 e 1. Se aumentarmos o zoom, é assim que parece. Neste gráfico, correspondendo a y igual a 0, o eixo vertical mostra o valor da perda para diferentes valores de f de x. Quando f é 0 ou muito próximo de 0, a perda também será muito pequena, o que significa que se o rótulo verdadeiro for 0 e a previsão do modelo estiver muito próxima de 0, bem, você quase acertou, então a perda é apropriadamente muito próxima de 0. Quanto maior for o valor de f de x, maior será a perda porque a previsão está mais distante do verdadeiro rótulo 0. Na verdade, quando essa previsão se aproxima de 1, a perda na verdade se aproxima do infinito. Voltando ao exemplo de previsão de tumor, apenas diz que se o modelo prevê que o tumor do paciente é quase certo de ser maligno, digamos, 99,9% de chance de malignidade, que na verdade não é maligno, então y é igual a 0, então penalizamos o modelo com uma perda muito alta. Nesse caso de y igual a 0, portanto, no caso de y igual a 1 no slide anterior, quanto mais a previsão f de x estiver longe do valor real de y, maior será a perda. Na verdade, se f de x se aproxima de 0, a perda aqui realmente é muito grande e, de fato, se aproxima do infinito. Quando o rótulo verdadeiro é 1, o algoritmo é fortemente incentivado a não prever algo muito próximo de 0. Neste vídeo, você viu por que a função de custo de erro quadrático não funciona bem para regressão logística. Também definimos a perda para um único exemplo de treinamento e criamos uma nova definição para a função de perda para regressão logística. Acontece que, com essa opção de função de perda, a função de custo geral será convexa e, portanto, você pode usar a descida de gradiente de forma confiável para levá-lo ao mínimo global. Provar que essa função é convexa está além do escopo desse custo. Você deve se lembrar que a função de custo é uma função de todo o conjunto de treinamento e, portanto, é a média ou 1 sobre m vezes a soma da função de perda nos exemplos de treinamento individuais. O custo de um determinado conjunto de parâmetros, w e b, é igual a 1 sobre m vezes a soma de todos os exemplos de treinamento da perda nos exemplos de treinamento. Se você puder encontrar o valor dos parâmetros, w e b, que minimiza isso, então você teria um bom conjunto de valores para os parâmetros w e b para regressão logística. No próximo laboratório opcional, você verá como a função de custo do erro quadrado não funciona muito bem para classificação, porque você verá que o gráfico de superfície resulta em uma superfície de custos muito altos com muitos mínimos locais. Em seguida, você examinará a nova função de perda logística. Como você pode ver aqui, isso produz um gráfico de superfície convexo agradável e suave que não tem todos esses mínimos locais. Por favor, dê uma olhada no custo e nos gráficos após este vídeo. Vimos muita coisa neste vídeo. No próximo vídeo, vamos voltar
Reproduza o vídeo começando em :11:40 e siga a transcrição11:40
e usar a função de perda para um único exemplo de trem para definir a função de custo geral de todo o conjunto de treinamento. Também descobriremos uma maneira mais simples de escrever a função de custo, que posteriormente nos permitirá executar a descida de gradiente para encontrar bons parâmetros para regressão logística. Vamos para o próximo vídeo.
