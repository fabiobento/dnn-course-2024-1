{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/hp_tuning/02%20-%20hp_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adaptado de [Getting started with KerasTuner](https://keras.io/guides/keras_tuner/getting_started/) de Luca Invernizzi, James Long, Francois Chollet e Tom O'Malley, Haifeng Jin em  [Keras Developer Guides](https://keras.io/guides/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Primeiros passos com o KerasTuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8tok2fEeosT9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introdução\n",
        "\n",
        "O KerasTuner é uma biblioteca de ajuste de hiperparâmetros.\n",
        "\n",
        "Ela tem uma forte integração com os fluxos de trabalho do Keras, mas não se limita a eles: você pode usá-la para você pode usá-la para ajustar modelos do scikit-learn ou qualquer outro _framework_.\n",
        "\n",
        "Neste tutorial, você verá como ajustar a arquitetura do modelo, o processo de treinamento e as etapas de preprocessamento de dados com o KerasTuner. Vamos começar com um exemplo simples.\n",
        "\n",
        "## Ajustar a arquitetura do modelo\n",
        "\n",
        "A primeira coisa que precisamos fazer é escrever uma função que retorne um modelo compilado do\n",
        "modelo do Keras.\n",
        "\n",
        "Ela recebe um argumento `hp` para definir os hiperparâmetros durante a construção do modelo.\n",
        "\n",
        "### Definir o espaço de pesquisa\n",
        "\n",
        "No exemplo de código a seguir, definimos um modelo do Keras com duas camadas `Dense`.\n",
        "\n",
        "Queremos ajustar o número de unidades na primeira camada `Dense`.\n",
        "\n",
        "Para isso, apenas definimos um hiperparâmetro inteiro com `hp.Int('units', min_value=32, max_value=512, step=32)`, cujo intervalo é de 32 a 512, inclusive.\n",
        "\n",
        "Ao fazer a amostragem a partir dele, a etapa mínima para percorrer o intervalo é 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wBqIzcBQosT_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            # Definir o hiperparâmetro.\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBbc5EHiosT_"
      },
      "source": [
        "Você pode testar rapidamente se o modelo foi criado com sucesso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RXBuA-euosUA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_5, built=False>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import keras_tuner\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBKkvAD7osUA"
      },
      "source": [
        "Há também muitos outros tipos de hiperparâmetros.\n",
        "\n",
        "Podemos definir vários hiperparâmetros na função.\n",
        "\n",
        "No código a seguir, ajustamos se devemos:\n",
        "* usar uma camada `Dropout` com `hp.Boolean()`\n",
        "* ajustamos a função de ativação a ser usar com `hp.Choice()`\n",
        "* ajustamos a taxa de aprendizado do otimizador com `hp.Float()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gwQiMFZZosUA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_6, built=False>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            # Ajuste o número de unidades.\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            # Ajuste a função de ativação a ser usada.\n",
        "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "        )\n",
        "    )\n",
        "    # Ajuste de dropout\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    # Defina a taxa de aprendizado do otimizador como um hiperparâmetro.\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70d2EeHBosUB"
      },
      "source": [
        "Conforme mostrado abaixo, os hiperparâmetros são valores reais.\n",
        "\n",
        "De fato, eles são apenas funções que retornam valores reais.\n",
        "\n",
        "Por exemplo, `hp.Int()` retorna um valor `int`.\n",
        "\n",
        "Portanto, você pode colocá-los em variáveis, loops for ou condições if."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "I5wcun_SosUB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n"
          ]
        }
      ],
      "source": [
        "hp = keras_tuner.HyperParameters()\n",
        "print(hp.Int(\"units\", min_value=32, max_value=512, step=32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UZspydKosUB"
      },
      "source": [
        "Você também pode definir os hiperparâmetros antecipadamente e manter o código do Keras em\n",
        "em uma função separada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Xt0ezMdHosUB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_7, built=False>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def call_existing_code(units, activation, dropout, lr):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=units, activation=activation))\n",
        "    if dropout:\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
        "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "    dropout = hp.Boolean(\"dropout\")\n",
        "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    # Chame o código de construção de modelo existente com os valores de hiperparâmetro.\n",
        "    model = call_existing_code(\n",
        "        units=units, activation=activation, dropout=dropout, lr=lr\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcBgFu_mosUB"
      },
      "source": [
        "Cada um dos hiperparâmetros é identificado exclusivamente por seu nome (o primeiro argumento).\n",
        "\n",
        "Para ajustar o número de unidades em diferentes camadas `Dense` separadamente como hiperparâmetros diferentes, damos a eles nomes diferentes como `f \"units_{i}\"`.\n",
        "\n",
        "Notavelmente, esse também é um exemplo de criação de hiperparâmetros condicionais.\n",
        "\n",
        "Há muitos hiperparâmetros que especificam o número de unidades nas camadas `Dense` densas.\n",
        "> O número de tais hiperparâmetros é decidido pelo número de camadas, que também é um hiperparâmetro.\n",
        "\n",
        "Portanto, o número total de hiperparâmetros usado pode ser diferente de uma tentativa para outra.\n",
        "\n",
        "Alguns hiperparâmetros são usados somente quando uma determinada condição é satisfeita.\n",
        "> Por exemplo, `units_3` só é usado quando `num_layers` for maior que 3.\n",
        "\n",
        "Com o KerasTuner, você pode definir facilmente esses hiperparâmetros dinamicamente durante a criação do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7pkg7QXlosUB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_8, built=False>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "   # Ajuste o número de camadas.\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                # Ajuste o número de unidades separadamente.\n",
        "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "            )\n",
        "        )\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Iniciar a busca\n",
        "\n",
        "Depois de definir o espaço de busca, precisamos selecionar uma classe de sintonizador para executar a pesquisa.\n",
        "\n",
        "Você pode escolher entre `RandomSearch`, `BayesianOptimization` e `Hyperband`, que correspondem a diferentes algoritmos de ajuste.\n",
        "> Aqui usamos o `RandomSearch` como exemplo.\n",
        "\n",
        "Para inicializar o ajustador, precisamos especificar vários argumentos no inicializador.\n",
        "\n",
        "* `hypermodel`. A função de construção de modelo, que é `build_model` em nosso caso.\n",
        "* `objective`. O nome do objetivo a ser otimizado (onde minimizar ou maximizar é automaticamente inferido para métricas incorporadas). Apresentaremos como como usar métricas personalizadas mais adiante neste tutorial.\n",
        "* `max_trials`. O número total de tentativas a serem executadas durante a pesquisa.\n",
        "* `executions_per_trial`. O número de modelos que devem ser criados e ajustados para cada tentativa. Diferentes tentativas têm diferentes valores de hiperparâmetro. As execuções dentro da mesma tentativa têm os mesmos valores de hiperparâmetro. O objetivo de ter várias execuções por tentativa é reduzir a variação dos resultados e, portanto, ser capaz de avaliar com mais precisão o desempenho de um modelo. Se quiser obter resultados mais rapidamente, você poderá definir `executions_per_trial=1` (rodada única de treinamento para cada configuração de modelo).\n",
        "* `overwrite`. Controla se os resultados anteriores devem ser substituídos no mesmo diretório ou, em vez disso, retomar a pesquisa anterior. Aqui, definimos `overwrite=True` para iniciar uma nova pesquisa e ignorar os resultados anteriores.\n",
        "* `directory`. Um caminho para um diretório para armazenar os resultados da pesquisa.\n",
        "* `project_name`. O nome do subdiretório no `directory`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vC1VAF4gosUC"
      },
      "outputs": [],
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=2,\n",
        "    executions_per_trial=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hvgd3j1osUC"
      },
      "source": [
        "Você pode imprimir um resumo do espaço de pesquisa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "eIzltlVNosUC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLc5SJPosUC"
      },
      "source": [
        "Antes de iniciar a pesquisa, vamos preparar o conjunto de dados MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1ILD-ItyosUC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "(x, y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x[:-10000]\n",
        "x_val = x[-10000:]\n",
        "y_train = y[:-10000]\n",
        "y_val = y[-10000:]\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwQJJChjosUC"
      },
      "source": [
        "Em seguida, inicie a busca pela melhor configuração de hiperparâmetros.\n",
        "\n",
        "Todos os argumentos passados para `search` são passados para `model.fit()` em cada execução. Lembre-se de passar `validation_data` para avaliar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lrJDu9EVosUC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [00h 00m 13s]\n",
            "val_accuracy: 0.9688666661580404\n",
            "\n",
            "Best val_accuracy So Far: 0.9688666661580404\n",
            "Total elapsed time: 00h 00m 30s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axPy5vF-osUC"
      },
      "source": [
        "Durante a `busca`, a função de criação de modelos é chamada com diferentes valores de hiperparâmetro em diferentes tentativas.\n",
        "\n",
        "Em cada tentativa:\n",
        "* o sintonizador gera um novo conjunto de valores de hiperparâmetros para construir o modelo.\n",
        "* O modelo é então treinado e avaliado.\n",
        "* As métricas são registradas.\n",
        "\n",
        "Assim o tuner progressivamente explora progressivamente o espaço e finalmente encontra um bom conjunto de valores de hiperparâmetros.\n",
        "\n",
        "### Consultar os resultados\n",
        "\n",
        "Quando a pesquisa terminar, você poderá recuperar o(s) melhor(es) modelo(s).\n",
        "> O modelo é salvo em sua época de melhor desempenho avaliada em `validation_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WbVY5Z1RosUC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">970</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m75,360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m970\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,330</span> (298.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,330\u001b[0m (298.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,330</span> (298.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,330\u001b[0m (298.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Obtenha os 2 principais modelos.\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "\n",
        "best_model.build(input_shape=(None, 28, 28, 1))\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy27JlOosUC"
      },
      "source": [
        "Você também pode imprimir um resumo dos resultados da pesquisa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "CYQ9ZZ7mosUC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 96\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.002752738682669076\n",
            "units_1: 384\n",
            "units_2: 32\n",
            "Score: 0.9688666661580404\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 352\n",
            "activation: relu\n",
            "dropout: False\n",
            "lr: 0.00036999076091727033\n",
            "units_1: 32\n",
            "units_2: 32\n",
            "Score: 0.9679666757583618\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54VHiWiuosUC"
      },
      "source": [
        "Você encontrará logs detalhados, pontos de verificação, etc., na pasta `my_dir/helloworld`, ou seja, `directory/project_name`.\n",
        "\n",
        "Você também pode visualizar os resultados de ajuste usando o TensorBoard e o plug-in HParams.\n",
        "Para obter mais informações, acesse [_Visualize the hyperparameter tuning process_](https://keras.io/guides/keras_tuner/visualize_tuning/).\n",
        "\n",
        "### Treinar novamente o modelo\n",
        "\n",
        "Se quiser treinar o modelo com todo o conjunto de dados, você poderá recuperar os\n",
        "melhores hiperparâmetros e treinar novamente o modelo por conta própria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "U8juNB2-osUD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 931us/step - accuracy: 0.8693 - loss: 0.4294\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x77a5dc286e10>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtenha os 2 principais hiperparâmetros.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Crie o modelo com o melhor hp.\n",
        "model = build_model(best_hps[0])\n",
        "# Treinamento com todo o conjunto de dados.\n",
        "x_all = np.concatenate((x_train, x_val))\n",
        "y_all = np.concatenate((y_train, y_val))\n",
        "model.fit(x=x_all, y=y_all, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eu5e8-2osUD"
      },
      "source": [
        "## Ajuste o treinamento do modelo\n",
        "\n",
        "Para ajustar o processo de construção do modelo, precisamos criar uma subclasse da classe `HyperModel`, que também facilita o compartilhamento e a reutilização de hipermodelos.\n",
        "\n",
        "Precisamos substituir `HyperModel.build()` e `HyperModel.fit()` para ajustar o processo de construção e treinamento do modelo, respectivamente.\n",
        "> O método `HyperModel.build()` é o mesmo que a função de construção de modelo, que cria um modelo do Keras usando os hiperparâmetros e o retorna.\n",
        "\n",
        "Em `HyperModel.fit()`, você pode acessar o modelo retornado por `HyperModel.build()`, `hp` e todos os argumentos passados para `search()`. Você precisa treinar o modelo e retornar o histórico de treinamento.\n",
        "\n",
        "No código a seguir, ajustaremos o argumento `shuffle` em `model.fit()`.\n",
        "\n",
        "Geralmente, não é necessário ajustar o número de épocas porque um _callback_ é passado para `model.fit()` para salvar o modelo em sua melhor época avaliada por `validation_data`.\n",
        "\n",
        "> **Nota**: Os `**kwargs` devem sempre ser passados para `model.fit()` porque ele contém os retornos de chamada para salvar o modelo e os plug-ins do tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hszNhXVLosUD"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            # Ajuste se os dados devem ser embaralhados em cada época.\n",
        "            shuffle=hp.Boolean(\"shuffle\"),\n",
        "            **kwargs,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_yweoT-osUD"
      },
      "source": [
        "Novamente, podemos fazer uma verificação rápida para ver se o código funciona corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RrRvjz6aosUD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1211 - loss: 13.0318  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x77a65c5d8290>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hp = keras_tuner.HyperParameters()\n",
        "hypermodel = MyHyperModel()\n",
        "model = hypermodel.build(hp)\n",
        "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc-UoKQGosUD"
      },
      "source": [
        "## Ajuste o pré-processamento de dados\n",
        "\n",
        "Para ajustar o pré-processamento de dados, basta adicionar uma etapa adicional em `HyperModel.fit()`, em que podemos acessar o conjunto de dados a partir dos argumentos.\n",
        "\n",
        "No código a seguir, ajustamos se devemos normalizar os dados antes de treinar o modelo.\n",
        "\n",
        "Desta vez, colocamos explicitamente `x` e `y` na assinatura da função porque precisamos usá-los."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "x_71vrRDosUD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0983 - loss: 11.5941  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x77a65c467610>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, x, y, **kwargs):\n",
        "        if hp.Boolean(\"normalize\"):\n",
        "            x = layers.Normalization()(x)\n",
        "        return model.fit(\n",
        "            x,\n",
        "            y,\n",
        "            # Tune whether to shuffle the data in each epoch.\n",
        "            shuffle=hp.Boolean(\"shuffle\"),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "hp = keras_tuner.HyperParameters()\n",
        "hypermodel = MyHyperModel()\n",
        "model = hypermodel.build(hp)\n",
        "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPHFO55IosUD"
      },
      "source": [
        "Se um hiperparâmetro for usado tanto em `build()` quanto em `fit()`, você poderá defini-lo em `build()` e usar `hp.get(hp_name)` para recuperá-lo em `fit()`.\n",
        "\n",
        "Usamos o tamanho da imagem como exemplo.\n",
        "> Ele é usado como a forma de entrada em `build()` e usado pela etapa de pré-processamento de dados para cortar as imagens em `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zr_Qc7fZosUD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.9606000185012817\n",
            "\n",
            "Best val_accuracy So Far: 0.9606000185012817\n",
            "Total elapsed time: 00h 00m 11s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        image_size = hp.Int(\"image_size\", 10, 28)\n",
        "        inputs = tf.keras.Input(shape=(image_size, image_size))\n",
        "        outputs = layers.Flatten()(inputs)\n",
        "        outputs = layers.Dense(\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            activation=\"relu\",\n",
        "        )(outputs)\n",
        "        outputs = layers.Dense(10, activation=\"softmax\")(outputs)\n",
        "        model = tf.keras.Model(inputs, outputs)\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, x, y, validation_data=None, **kwargs):\n",
        "        if hp.Boolean(\"normalize\"):\n",
        "            x = layers.Normalization()(x)\n",
        "        image_size = hp.get(\"image_size\")\n",
        "        cropped_x = x[:, :image_size, :image_size, :]\n",
        "        if validation_data:\n",
        "            x_val, y_val = validation_data\n",
        "            cropped_x_val = x_val[:, :image_size, :image_size, :]\n",
        "            validation_data = (cropped_x_val, y_val)\n",
        "        return model.fit(\n",
        "            cropped_x,\n",
        "            y,\n",
        "            # Tune whether to shuffle the data in each epoch.\n",
        "            shuffle=hp.Boolean(\"shuffle\"),\n",
        "            validation_data=validation_data,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvIkhgZFosUE"
      },
      "source": [
        "### Treinar novamente o modelo\n",
        "\n",
        "O uso do `HyperModel` também permite que você treine novamente o melhor modelo por conta própria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0Bs8P_cHosUE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.8523 - loss: 0.5241\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x77a65c416190>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hypermodel = MyHyperModel()\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "model = hypermodel.build(best_hp)\n",
        "hypermodel.fit(best_hp, model, x_all, y_all, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U41GEzRxosUE"
      },
      "source": [
        "## Especifique o objetivo de ajuste\n",
        "\n",
        "Em todos os exemplos anteriores, usamos apenas a acurácia de validação (`\"val_accuracy\"`) como o objetivo de ajuste para selecionar o melhor modelo. Na verdade, você pode usar qualquer métrica como objetivo. A métrica mais comumente usada é `\"val_loss\"`, que é a perda de validação.\n",
        "\n",
        "### Métrica integrada como objetivo\n",
        "\n",
        "Há muitas outras métricas incorporadas no Keras que você pode usar como objetivo. Aqui está [uma lista das métricas incorporadas](https://keras.io/api/metrics/).\n",
        "\n",
        "Para usar uma métrica integrada como objetivo, você precisa seguir estas etapas:\n",
        "\n",
        "* Compilar o modelo com a métrica incorporada. Por exemplo, você deseja usar `MeanAbsoluteError()`. Você precisa compilar o modelo com `metrics=[MeanAbsoluteError()]`. Em vez disso, você também pode usar sua _string_: `metrics=[\"mean_absolute_error\"]`.\n",
        "\n",
        "* Identificar a _string_ do nome do objetivo. A _string_ do nome do objetivo está sempre no formato de `f \"val_{metric_name_string}\"`. Por exemplo, a string do erro quadrático médio avaliado nos dados de validação deve ser `\"val_mean_absolute_error\"`.\n",
        "\n",
        "* Envolva-a em `keras_tuner.Objective`. Normalmente, é necessário envolver o objetivo em um objeto `keras_tuner.Objective` para especificar a direção em que otimizar o objetivo. Por exemplo, se quisermos minimizar o erro quadrático médio, podemos usar `keras_tuner.Objective(\"val_mean_absolute_error\", \"min\")`. A direção deve ser `\"min\"` ou `\"max\"`.\n",
        "\n",
        "* Passe o agrupado para o sintonizador.\n",
        "\n",
        "Você pode ver o seguinte exemplo de código básico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "OqrbVnPKosUH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 01s]\n",
            "val_mean_absolute_error: 0.8806929588317871\n",
            "\n",
            "Best val_mean_absolute_error So Far: 0.21110916137695312\n",
            "Total elapsed time: 00h 00m 02s\n",
            "Results summary\n",
            "Results in my_dir/built_in_metrics\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_mean_absolute_error\", direction=\"min\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: 0.21110916137695312\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "Score: 0.43424248695373535\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.8806929588317871\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_regressor(hp):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
        "            layers.Dense(units=1),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"mean_squared_error\",\n",
        "        # O objetivo é uma das métricas.\n",
        "        metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_regressor,\n",
        "    # O nome e a direção do objetivo.\n",
        "    objective=keras_tuner.Objective(\"val_mean_absolute_error\", direction=\"min\"),\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"built_in_metrics\",\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x=np.random.rand(100, 10),\n",
        "    y=np.random.rand(100, 1),\n",
        "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métrica personalizada como objetivo\n",
        "\n",
        "Você pode implementar sua própria métrica e usá-la como objetivo de pesquisa de hiperparâmetro. Aqui, usamos o erro quadrático médio (MSE) como exemplo.\n",
        "\n",
        "Primeiro, nós implementamos a métrica MSE por meio de uma subclasse de `keras.metrics.Metric`. Lembre-se de dar um nome à sua métrica usando o argumento `name` de `super().__init__()`, que será usado posteriormente.\n",
        "> *Observação*: o MSE é, na verdade, uma métrica incorporada, que pode ser importado com `keras.metrics.MeanSquaredError`. Este é apenas um exemplo para mostrar como usar uma métrica personalizada como objetivo de pesquisa de hiperparâmetro.\n",
        "\n",
        "Para obter mais informações sobre a implementação de métricas personalizadas, consulte [este tutorial](https://keras.io/api/metrics/#creating-custom-metrics). Se você quiser desejar uma métrica com uma assinatura de função diferente de `update_state(y_true, y_pred, sample_weight)`, você poderá substituir o método `train_step()` do seu modelo modelo seguindo [este tutorial](https://keras.io/guides/customizing_what_happens_in_fit/#going-lowerlevel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ru4lg_K9osUH"
      },
      "outputs": [],
      "source": [
        "class CustomMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, **kwargs):\n",
        "        # Especifique o nome da métrica como \"custom_metric\".\n",
        "        super().__init__(name=\"custom_metric\", **kwargs)\n",
        "        self.sum = self.add_weight(name=\"sum\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", dtype=\"int32\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        values = tf.keras.ops.square(y_true - y_pred)\n",
        "        count = tf.keras.ops.shape(y_true)[0]\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.keras.ops.cast(sample_weight, self.dtype)\n",
        "            values *= sample_weight\n",
        "            count *= sample_weight\n",
        "        self.sum.assign_add(tf.keras.ops.sum(values))\n",
        "        self.count.assign_add(count)\n",
        "\n",
        "    def result(self):\n",
        "        return self.sum / tf.keras.ops.cast(self.count, \"float32\")\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.sum.assign(0)\n",
        "        self.count.assign(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8rmTca0osUI"
      },
      "source": [
        "Execute a pesquisa com o objetivo personalizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Z43YTpZkosUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 01s]\n",
            "val_custom_metric: 0.11389829963445663\n",
            "\n",
            "Best val_custom_metric So Far: 0.06787848472595215\n",
            "Total elapsed time: 00h 00m 02s\n",
            "Results summary\n",
            "Results in my_dir/custom_metrics\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_custom_metric\", direction=\"min\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: 0.06787848472595215\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.11389829963445663\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "Score: 0.19134631752967834\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_regressor(hp):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
        "            layers.Dense(units=1),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"mean_squared_error\",\n",
        "        # Coloque a métrica personalizada nas métricas.\n",
        "        metrics=[CustomMetric()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_regressor,\n",
        "    # Especifique o nome e a direção do objetivo.\n",
        "    objective=keras_tuner.Objective(\"val_custom_metric\", direction=\"min\"),\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"custom_metrics\",\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x=np.random.rand(100, 10),\n",
        "    y=np.random.rand(100, 1),\n",
        "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzqUfV-josUJ"
      },
      "source": [
        "Se o seu objetivo personalizado for difícil de ser colocado em uma métrica personalizada, você também pode avaliar o modelo por conta própria em `HyperModel.fit()` e retornar o valor do objetivo.\n",
        "\n",
        "O valor do objetivo seria minimizado por padrão. Nesse caso, não é necessário especificar o `objetivo` ao inicializar o sintonizador.\n",
        "\n",
        "No entanto, nesse caso, o valor da métrica não será rastreado nos logs do Keras, apenas nos logs do KerasTuner.\n",
        "> Portanto, esses valores não seriam exibidos por nenhuma exibição do TensorBoard usando as métricas do Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yNMJcnR-osUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 01s]\n",
            "default_objective: 0.4981072251778859\n",
            "\n",
            "Best default_objective So Far: 0.4981072251778859\n",
            "Total elapsed time: 00h 00m 02s\n",
            "Results summary\n",
            "Results in my_dir/custom_eval\n",
            "Showing 10 best trials\n",
            "Objective(name=\"default_objective\", direction=\"min\")\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: 0.4981072251778859\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.5630087179285445\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "Score: 0.61802369301215\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class HyperRegressor(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
        "                layers.Dense(units=1),\n",
        "            ]\n",
        "        )\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"mean_squared_error\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
        "        model.fit(x, y, **kwargs)\n",
        "        x_val, y_val = validation_data\n",
        "        y_pred = model.predict(x_val)\n",
        "        # Retorna um único float para minimizar.\n",
        "        return np.mean(np.abs(y_pred - y_val))\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=HyperRegressor(),\n",
        "    # Não há objetivo a ser especificado.\n",
        "    # O objetivo é o valor de retorno de `HyperModel.fit()`.\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"custom_eval\",\n",
        ")\n",
        "tuner.search(\n",
        "    x=np.random.rand(100, 10),\n",
        "    y=np.random.rand(100, 1),\n",
        "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XrYil7fosUJ"
      },
      "source": [
        "Se você tiver várias métricas para rastrear no KerasTuner, mas usar apenas uma delas como objetivo, poderá retornar um dicionário, cujas chaves são os nomes das métricas e os valores são os valores das métricas, por exemplo, retornar `{“metric_a”: 1.0, “metric_b”, 2.0}`.\n",
        "\n",
        "Use uma das chaves como o nome do objetivo, por exemplo, `keras_tuner.Objective(“metric_a”, “min”)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "h6U7tA_sosUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 01s]\n",
            "metric_a: -0.3460912875026351\n",
            "\n",
            "Best metric_a So Far: -0.2837509138006842\n",
            "Total elapsed time: 00h 00m 02s\n",
            "Results summary\n",
            "Results in my_dir/custom_eval_dict\n",
            "Showing 10 best trials\n",
            "Objective(name=\"metric_a\", direction=\"max\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: -0.2837509138006842\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: -0.3460912875026351\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "Score: -0.36974070530610603\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class HyperRegressor(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
        "                layers.Dense(units=1),\n",
        "            ]\n",
        "        )\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"mean_squared_error\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
        "        model.fit(x, y, **kwargs)\n",
        "        x_val, y_val = validation_data\n",
        "        y_pred = model.predict(x_val)\n",
        "        # Retorna um dicionário de métricas para o KerasTuner rastrear.\n",
        "        return {\n",
        "            \"metric_a\": -np.mean(np.abs(y_pred - y_val)),\n",
        "            \"metric_b\": np.mean(np.square(y_pred - y_val)),\n",
        "        }\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=HyperRegressor(),\n",
        "    # O objetivo é uma das chaves.\n",
        "    # Maximizar o MAE negativo, equivalente a minimizar o MAE.\n",
        "    objective=keras_tuner.Objective(\"metric_a\", \"max\"),\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"custom_eval_dict\",\n",
        ")\n",
        "tuner.search(\n",
        "    x=np.random.rand(100, 10),\n",
        "    y=np.random.rand(100, 1),\n",
        "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B_9M9oHosUJ"
      },
      "source": [
        "## Ajuste os fluxos de trabalho de ponta a ponta\n",
        "\n",
        "Em alguns casos, é difícil alinhar seu código em funções de compilação e treino. Você também pode manter o fluxo de trabalho de ponta a ponta em um único lugar substituindo `Tuner.run_trial()`, que lhe dá controle total de uma avaliação. Você pode vê-lo como um otimizador de caixa preta para qualquer coisa.\n",
        "\n",
        "### Ajuste qualquer função\n",
        "\n",
        "Por exemplo, você pode encontrar um valor de `x` que minimize `f(x)=x*x+1`. No código a seguir, apenas definimos `x` como um hiperparâmetro e retornamos `f(x)` como o valor objetivo. Os argumentos `hypermodel` e `objective` para inicializar o sintonizador podem ser omitidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "X7Rh8LYMosUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 00s]\n",
            "default_objective: 1.65720670166111\n",
            "\n",
            "Best default_objective So Far: 1.0036180512809396\n",
            "Total elapsed time: 00h 00m 00s\n",
            "0.060150239242579895\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class MyTuner(keras_tuner.RandomSearch):\n",
        "    def run_trial(self, trial, *args, **kwargs):\n",
        "        # Obter o hp do teste.\n",
        "        hp = trial.hyperparameters\n",
        "        # Defina “x” como um hiperparâmetro.\n",
        "        x = hp.Float(\"x\", min_value=-1.0, max_value=1.0)\n",
        "        # Retorna o valor objetivo a ser minimizado.\n",
        "        return x * x + 1\n",
        "\n",
        "\n",
        "tuner = MyTuner(\n",
        "    # Nenhum hipermodelo ou objetivo especificado.\n",
        "    max_trials=20,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_anything\",\n",
        ")\n",
        "\n",
        "# Não há necessidade de passar nada para search()\n",
        "# a menos que você os use em run_trial().\n",
        "tuner.search()\n",
        "print(tuner.get_best_hyperparameters()[0].get(\"x\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie0yZmHVosUJ"
      },
      "source": [
        "### Mantenha o código do Keras separado\n",
        "\n",
        "Você pode manter todo o seu código do Keras inalterado e usar o KerasTuner para ajustá-lo. Isso é útil se você não puder modificar o código do Keras por algum motivo.\n",
        "\n",
        "Isso também lhe dá mais flexibilidade. Você não precisa separar a construção do modelo e o código de treinamento. No entanto, esse fluxo de trabalho não ajudaria você a salvar o modelo ou conectar-se aos plug-ins do TensorBoard.\n",
        "\n",
        "Para salvar o modelo, você pode usar `trial.trial_id`, que é uma cadeia de caracteres para identificar uma tentativa, para construir caminhos diferentes para salvar os modelos de diferentes tentativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_3EgYuUfosUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 00s]\n",
            "default_objective: 0.3756241505326371\n",
            "\n",
            "Best default_objective So Far: 0.3756241505326371\n",
            "Total elapsed time: 00h 00m 01s\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5641  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4610180642441408"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def keras_code(units, optimizer, saving_path):\n",
        "    # Construir modelo\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(units=units, activation=\"relu\"),\n",
        "            layers.Dense(units=1),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"mean_squared_error\",\n",
        "    )\n",
        "\n",
        "    # Preparar dados\n",
        "    x_train = np.random.rand(100, 10)\n",
        "    y_train = np.random.rand(100, 1)\n",
        "    x_val = np.random.rand(20, 10)\n",
        "    y_val = np.random.rand(20, 1)\n",
        "\n",
        "    # Treinar e avaliar o modelo\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Salvar o modelo\n",
        "    model.save(saving_path)\n",
        "\n",
        "    # Retorna um único float como o valor objetivo.\n",
        "    # Você também pode retornar um dicionário\n",
        "    # de {metric_name: metric_value}.\n",
        "    y_pred = model.predict(x_val)\n",
        "    return np.mean(np.abs(y_pred - y_val))\n",
        "\n",
        "\n",
        "class MyTuner(keras_tuner.RandomSearch):\n",
        "    def run_trial(self, trial, **kwargs):\n",
        "        hp = trial.hyperparameters\n",
        "        return keras_code(\n",
        "            units=hp.Int(\"units\", 32, 128, 32),\n",
        "            optimizer=hp.Choice(\"optimizer\", [\"adam\", \"adadelta\"]),\n",
        "            saving_path=os.path.join(\"/tmp\", f\"{trial.trial_id}.keras\"),\n",
        "        )\n",
        "\n",
        "\n",
        "tuner = MyTuner(\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"keep_code_separate\",\n",
        ")\n",
        "tuner.search()\n",
        "# Retreinando o modelo\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "keras_code(**best_hp.values, saving_path=\"/tmp/best_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9rpTdE4osUJ"
      },
      "source": [
        "## O KerasTuner inclui aplicativos ajustáveis pré-fabricados: HyperResNet e HyperXception\n",
        "\n",
        "Esses são hipermodelos prontos para uso para visão computacional.\n",
        "\n",
        "Eles vêm pré-compilados com `loss=“categorical_crossentropy”` e\n",
        "`metrics=[“accuracy”]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NDCb3jnCosUJ"
      },
      "outputs": [],
      "source": [
        "from keras_tuner.applications import HyperResNet\n",
        "\n",
        "hypermodel = HyperResNet(input_shape=(28, 28, 1), classes=10)\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=2,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"built_in_hypermodel\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "getting_started",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
