{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f2b7e4",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_convnets/class_03/12%20-%20Atividade%20Avaliativa/C2W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07645c91",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed17edc",
   "metadata": {
    "id": "f8cj-HBNoEZy"
   },
   "source": [
    "# Aprendizagem por transferência(_Transfer Learning_)\n",
    "\n",
    " Nesta atividade, você usará uma técnica chamada \"Aprendizagem por transferência\", na qual você utiliza uma rede já treinada para ajudá-lo a resolver um problema semelhante àquele para o qual ela foi originalmente treinada.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affe0eb",
   "metadata": {
    "id": "lbFmQdsZs5eW",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2aafe",
   "metadata": {
    "id": "RPvtLK1GyUWr"
   },
   "source": [
    "## Conjunto de dados\n",
    "\n",
    "Para esta tarefa, você usará o conjunto de dados `Horse or Human`, que contém imagens de cavalos e humanos. \n",
    "\n",
    "Faça download dos conjuntos de `treinamento` e `validação` executando a célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873beec7",
   "metadata": {
    "id": "dIeTNcPEo79J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obter o conjunto de dados de treinamento Horse ou Human\n",
    "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
    "\n",
    "# Obter o conjunto de dados de validação Horse ou Human\n",
    "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
    "\n",
    "test_local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(test_local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "\n",
    "val_local_zip = './validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(val_local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bd77c",
   "metadata": {
    "id": "x4OMDxYS6tmv"
   },
   "source": [
    "Esse conjunto de dados já tem uma estrutura compatível com o `flow_from_directory` do Keras, portanto, você não precisa mover as imagens para subdiretórios como fez em uma atividade avaliativa anterior.\n",
    "\n",
    "No entanto, ainda é uma boa ideia salvar os caminhos das imagens para que você possa usá-los mais tarde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f3dc8",
   "metadata": {
    "id": "lHRrmo5CpEw_",
    "lines_to_next_cell": 2,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Definir os diretórios de base de treinamento e validação\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "# Diretório com fotos de cavalos de treinamento\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')\n",
    "# Diretório com fotos de humanos de treinamento\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')\n",
    "# Diretório com imagens de cavalos de validação\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "# Diretório com imagens humanas de validação\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "# Verificar o número de imagens para cada classe e definir\n",
    "print(f\"Há {len(os.listdir(train_horses_dir))} imagens de cavalos para treinamento.\\n\")\n",
    "print(f\"Há {len(os.listdir(train_humans_dir))} imagens de humanos para treinamento.\\n\")\n",
    "print(f\"Há {len(os.listdir(validation_horses_dir))} imagens de cavalos para validação.\\n\")\n",
    "print(f\"Há {len(os.listdir(validation_humans_dir))} imagens de humanos para validação.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fcda2",
   "metadata": {
    "id": "1G5hXBB57c78"
   },
   "source": [
    "Agora, dê uma olhada em uma imagem de amostra de cada uma das classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020115d",
   "metadata": {
    "id": "HgbMs7p0qSKr",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Exemplo de imagem de cavalo:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(train_horses_dir, os.listdir(train_horses_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nExemplo de imagem humana:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(train_humans_dir, os.listdir(train_humans_dir)[0])}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a09fe",
   "metadata": {
    "id": "LBnbnY0c8Zd0"
   },
   "source": [
    "O `matplotlib` facilita a visualização de que essas imagens têm uma resolução de 300x300 e são coloridas, mas você pode verificar isso usando o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332e53e",
   "metadata": {
    "id": "4lIGjHC5pxua",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Carregue o primeiro exemplo de um cavalo\n",
    "sample_image  = load_img(f\"{os.path.join(train_horses_dir, os.listdir(train_horses_dir)[0])}\")\n",
    "\n",
    "# Converta a imagem em sua representação de matriz numérica\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Cada imagem tem uma forma: {sample_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d742827",
   "metadata": {
    "id": "4fYwAYyd8zEm"
   },
   "source": [
    "Como esperado, a imagem de amostra tem uma resolução de 300x300 e a última dimensão é usada para cada um dos canais RGB para representar a cor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cd4cb",
   "metadata": {
    "id": "6HcE1TSqNRY2"
   },
   "source": [
    "## Geradores de treinamento e validação\n",
    "\n",
    "Agora que você conhece as imagens com as quais está lidando, é hora de codificar os geradores que alimentarão essas imagens na sua rede. Para isso, complete a função `train_val_generators` abaixo:\n",
    "\n",
    "**Observação importante:** As imagens têm uma resolução de 300x300, mas o método `flow_from_directory` que você usará permite que você defina uma resolução de destino. Nesse caso, **configure um `target_size` de (150, 150)**. Isso reduzirá bastante o número de parâmetros treináveis em sua rede final, proporcionando tempos de treinamento muito mais rápidos sem comprometer a acurácia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f6f72",
   "metadata": {
    "cellView": "code",
    "id": "AX5Q3NL_FXMT",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  Cria os geradores de dados de treinamento e validação\n",
    "  \n",
    "  Args:\n",
    "    TRAINING_DIR (string): caminho do diretório que contém as imagens de treinamento\n",
    "    VALIDATION_DIR (string): caminho do diretório que contém as imagens de teste/validação\n",
    "    \n",
    "  Retorna:\n",
    "    train_generator, validation_generator: tupla contendo os geradores\n",
    "  \"\"\"\n",
    "  ### COMECE SEU CÓDIGO AQUI\n",
    "\n",
    "  # Instanciar a classe ImageDataGenerator \n",
    "  # Não se esqueça de normalizar os valores de pixel e definir argumentos para aumentar as imagens \n",
    "\n",
    "  train_datagen = None\n",
    "\n",
    "  # Passe os argumentos apropriados para o método flow_from_directory\n",
    "  train_generator = train_datagen.flow_from_directory(directory=None,\n",
    "                                                      batch_size=32, \n",
    "                                                      class_mode=None,\n",
    "                                                      target_size=(None, None))\n",
    "\n",
    "  # Instanciar a classe ImageDataGenerator (não se esqueça de definir o argumento rescale)\n",
    "  # Lembre-se de que os dados de validação não devem ser aumentados\n",
    "  validation_datagen = None\n",
    "\n",
    "  # Passe os argumentos apropriados para o método flow_from_directory\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=None,\n",
    "                                                                batch_size=32, \n",
    "                                                                class_mode=None,\n",
    "                                                                target_size=(None, None))\n",
    "  ### TERMINE SEU CÓDIGO AQUI\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4482a",
   "metadata": {
    "id": "8FLUUqMKFwVR",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Teste seus geradores\n",
    "train_generator, validation_generator = train_val_generators(train_dir, validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031442fe",
   "metadata": {
    "id": "TszKWhunQaj4"
   },
   "source": [
    "**Saída Esperada:**\n",
    "```\n",
    "Found 1027 images belonging to 2 classes.\n",
    "Found 256 images belonging to 2 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4f0ce",
   "metadata": {
    "id": "Izx51Ju1rXwd"
   },
   "source": [
    "## Aprendizagem por transferência - Crie o modelo pré-treinado\n",
    "\n",
    "Faça o download dos pesos do `inception V3` para o diretório `/tmp/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199be3d8",
   "metadata": {
    "id": "-lEzPAqxrPcU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Faça o download dos pesos v3 iniciais\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087a94d",
   "metadata": {
    "id": "_zlXNulm9USZ"
   },
   "source": [
    "Agora, carregue o modelo `InceptionV3` e salve o caminho para os pesos que você acabou de baixar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39291c18",
   "metadata": {
    "id": "zfmRpsMf7E3-",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Importar o modelo inicial  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Criar uma instância do modelo inicial a partir dos pesos locais pré-treinados\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cc8e5",
   "metadata": {
    "id": "ZPQb0PkT9_3w"
   },
   "source": [
    "Complete a função `create_pre_trained_model` abaixo.\n",
    "\n",
    "Você deve especificar a `input_shape` correta para o modelo (lembre-se de que você definiu uma nova resolução para as imagens em vez da nativa 300x300) e tornar todas as camadas não treináveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2afb2",
   "metadata": {
    "cellView": "code",
    "id": "x2JnQ6m8r5oe",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def create_pre_trained_model(local_weights_file):\n",
    "  \"\"\"\n",
    "  Inicializa um modelo InceptionV3.\n",
    "  \n",
    "  Args:\n",
    "    local_weights_file (string): caminho que aponta para um arquivo H5 de pesos pré-treinados\n",
    "    \n",
    "  Retorna:\n",
    "    pre_trained_model: o modelo InceptionV3 inicializado\n",
    "  \"\"\"\n",
    "  ### COMECE SEU CÓDIGO AQUI\n",
    "  pre_trained_model = InceptionV3(input_shape = (None, None, None),\n",
    "                                  include_top = False, \n",
    "                                  weights = None) \n",
    "\n",
    "  pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "  # Tornar todas as camadas do modelo pré-treinado não treináveis\n",
    "  for None in None:\n",
    "    None = None\n",
    "\n",
    "  ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "  return pre_trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf219f23",
   "metadata": {
    "id": "phE00SCr-RCT"
   },
   "source": [
    "Verifique se tudo correu bem, comparando as últimas linhas do resumo do modelo com o resultado esperado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12229ac",
   "metadata": {
    "id": "ve7eh9iztT4q",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "pre_trained_model = create_pre_trained_model(local_weights_file)\n",
    "\n",
    "# Imprimir o resumo do modelo\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17567e0",
   "metadata": {
    "id": "4cAY2gQytr0-"
   },
   "source": [
    "**Saída Esperada:**\n",
    "```\n",
    "batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "__________________________________________________________________________________________________\n",
    "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "__________________________________________________________________________________________________\n",
    "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "                                                                activation_276[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "                                                                activation_280[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "__________________________________________________________________________________________________\n",
    "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "                                                                mixed9_1[0][0]                   \n",
    "                                                                concatenate_5[0][0]              \n",
    "                                                                activation_281[0][0]             \n",
    "==================================================================================================\n",
    "Total params: 21,802,784\n",
    "Trainable params: 0\n",
    "Non-trainable params: 21,802,784\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d245b8",
   "metadata": {
    "id": "MRHkV9jo-hkh"
   },
   "source": [
    "Para verificar se todas as camadas do modelo foram definidas como não treináveis, você também pode executar a célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2378063",
   "metadata": {
    "id": "VASOaB8xDbhU",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "total_params = pre_trained_model.count_params()\n",
    "num_trainable_params = sum([w.shape.num_elements() for w in pre_trained_model.trainable_weights])\n",
    "\n",
    "print(f\"Há um total de {total_params:,} parâmetros nesse modelo.\")\n",
    "print(f\"Há {num_trainable_params:,} parâmetros treináveis nesse modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7504cd80",
   "metadata": {
    "id": "mRioO7FH5a8I"
   },
   "source": [
    "**Saída Esperada:**\n",
    "```\n",
    "Há um total de 21,802,784 parâmetros nesse modelo.\n",
    "Há 0 parâmetros treináveis nesse modelo.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e281fb",
   "metadata": {
    "id": "dFtwDyKj-4GR"
   },
   "source": [
    "## Criando callbacks para depois\n",
    "\n",
    "Você já trabalhou com _callbacks_ antes, portanto, o _callbacks_ para interromper o treinamento quando for atingida uma precisão de 99,9% é fornecido para você:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125b3fa",
   "metadata": {
    "id": "SeVjZD2o7gWS",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Defina uma classe de retorno de chamada que interrompa o treinamento quando a precisão atingir 99,9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.999):\n",
    "      print(\"\\nAtingi 99,9% de precisão, portanto, estou cancelando o treinamento!!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb7e20",
   "metadata": {
    "id": "lHZnFl-5_p3a"
   },
   "source": [
    "## _Pipelining_ do modelo pré-treinado com o seu próprio modelo\n",
    "\n",
    "Agora que o modelo pré-treinado está pronto, você precisa \"colá-lo\" ao seu próprio modelo para resolver a tarefa em questão.\n",
    "\n",
    "Para isso, você precisará da última saída do modelo pré-treinado, pois ela será a entrada do seu modelo. Complete a função `output_of_last_layer` abaixo.\n",
    "\n",
    "**Nota:** Para fins de avaliação nessa atividade, use a camada `mixed7` como a última camada do modelo pré-treinado. No entanto, após o envio, sinta-se à vontade para voltar aqui e usar camadas para ver os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5b99d",
   "metadata": {
    "id": "CFsUlwdfs_wg",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def output_of_last_layer(pre_trained_model):\n",
    "  \"\"\"\n",
    "  Obtém a saída da última camada de um modelo\n",
    "  \n",
    "  Args:\n",
    "    pre_trained_model (tf.keras Model): modelo para obter a saída da última camada\n",
    "    \n",
    "  Retorna:\n",
    "    last_output: saída da última camada do modelo \n",
    "  \"\"\"\n",
    "  ### COMECE SEU CÓDIGO AQUI\n",
    "  last_desired_layer = None\n",
    "  print('formato da última camada: ', last_desired_layer.output_shape)\n",
    "  last_output = None\n",
    "  print('saída da última camada: ', last_output)\n",
    "  ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "  return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f7763",
   "metadata": {
    "id": "13AEzKG2A6_J"
   },
   "source": [
    "Verifique se tudo está funcionando como esperado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ec1d3",
   "metadata": {
    "id": "zOJPUtMN6PHo",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "last_output = output_of_last_layer(pre_trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30744c5f",
   "metadata": {
    "id": "XqIWKZ_h7CuY"
   },
   "source": [
    "**Saída Esperada (se a camada `mixed7` foi usada):**\n",
    "```\n",
    "formato da última camada:  (None, 7, 7, 768)\n",
    "saída da última camada:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 768), dtype=tf.float32, name=None), name='mixed7/concat:0', description=\"created by layer 'mixed7'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb30bb",
   "metadata": {
    "id": "0Rp-J6JuwJTq"
   },
   "source": [
    "Agora você criará o modelo final adicionando algumas camadas adicionais sobre o modelo pré-treinado.\n",
    "\n",
    "Complete a função `create_final_model` abaixo. Você precisará usar a [Functional API](https://www.tensorflow.org/guide/keras/functional) do Tensorflow para isso, pois o modelo pré-treinado foi criado com ela. \n",
    "\n",
    "Vamos verificar isso primeiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277ef8b",
   "metadata": {
    "id": "cKQknB4j7K9y",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Imprimir o tipo do modelo pré-treinado\n",
    "print(f\"O modelo pré-treinado tem o tipo: {type(pre_trained_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29dd28d",
   "metadata": {
    "id": "Kt7AU7jP7LW9"
   },
   "source": [
    "Para criar o modelo final, você usará a classe Model do Keras, definindo as entradas e saídas apropriadas, conforme descrito na primeira maneira de instanciar um modelo na [documentação](https://www.tensorflow.org/api_docs/python/tf/keras/Model).\n",
    "\n",
    "Observe que você pode obter a entrada de qualquer modelo existente usando seu atributo `input` e, usando a API Funcional, pode usar a última camada diretamente como saída ao criar o modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b8b89",
   "metadata": {
    "cellView": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [],
   "source": [
    "def create_final_model(pre_trained_model, last_output):\n",
    "  \"\"\"\n",
    "  Anexa um modelo personalizado a um modelo pré-treinado\n",
    "  \n",
    "  Args:\n",
    "    pre_trained_model (tf.keras Model): modelo que aceitará as entradas de treinamento/teste\n",
    "    last_output (tensor): saída da última camada do modelo pré-treinado\n",
    "    \n",
    "  Retorna:\n",
    "    model: o modelo combinado\n",
    "  \"\"\"\n",
    "  # Achatar a camada de saída para uma dimensão\n",
    "  x = layers.Flatten()(last_output)\n",
    "\n",
    "  ### COMECE SEU CÓDIGO AQUI\n",
    "\n",
    "  # Adicione uma camada totalmente conectada com 1024 unidades ocultas e ativação ReLU\n",
    "  x = None\n",
    "  # Adicionar uma taxa de dropout de 0,2\n",
    "  x = None  \n",
    "  # Adicionar uma camada sigmoide final para classificação\n",
    "  x = None        \n",
    "\n",
    "  # Criar o modelo completo usando a classe Model\n",
    "  model = Model(inputs=None, outputs=None)\n",
    "\n",
    "  # Compilar o modelo\n",
    "  model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "                loss = None,\n",
    "                metrics = [None])\n",
    "\n",
    "  ### TERMINE SEU CÓDIGO AQUI\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00a764",
   "metadata": {
    "id": "cL6ga5Z1783H",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Salve seu modelo em uma variável\n",
    "model = create_final_model(pre_trained_model, last_output)\n",
    "\n",
    "# Inspecionar parâmetros\n",
    "total_params = model.count_params()\n",
    "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
    "\n",
    "print(f\"Há um total de {total_params:,} parâmetros nesse modelo.\")\n",
    "print(f\"Há {num_trainable_params:,} parâmetros treináveis nesse modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670c61e",
   "metadata": {
    "id": "J4d3zlcQDrvm"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Há um total de 47,512,481 parâmetros nesse modelo.\n",
    "Há 38,537,217 parâmetros treináveis nesse modelo.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0e2b1",
   "metadata": {
    "id": "_eqwHj5xEBZ7"
   },
   "source": [
    "É muito parâmetros, né?!\n",
    "\n",
    "Depois de enviar seu trabalho mais tarde, tente executar novamente esse notebook, mas use a resolução original de 300x300; você ficará surpreso ao ver quantos parâmetros a mais existem nesse caso.\n",
    "\n",
    "Agora treine o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868a36d",
   "metadata": {
    "id": "Blhq2MAUeyGA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute isso e veja quantas épocas devem ser necessárias antes que a chamada de retorno inicie\n",
    "#  e interrompa o treinamento com 99,9% de precisão\n",
    "# (Deve levar algumas épocas)\n",
    "callbacks = myCallback()\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs = 100,\n",
    "                    verbose = 2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9186f7",
   "metadata": {
    "id": "Y94djl4t0sK5"
   },
   "source": [
    "O treinamento deveria ter sido interrompido após menos de 10 épocas e deveria ter atingido uma precisão superior a 99,9% (disparando a chamada de retorno).\n",
    "\n",
    "Isso aconteceu tão rapidamente devido ao modelo pré-treinado que você usou, que já continha informações para classificar humanos e cavalos. Lega, não acha! :-)\n",
    "\n",
    "Agora, dê uma olhada rápida nas acurácias de treinamento e validação para cada época de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94026844",
   "metadata": {
    "id": "C2Fp6Se9rKuL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plote as precisões de treinamento e validação para cada época\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Acurácia de Treino')\n",
    "plt.plot(epochs, val_acc, 'b', label='Acurácia de Validação')\n",
    "plt.title('Acurácia de Treino e Validação')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff50893",
   "metadata": {
    "id": "7w54-pbB1W9r"
   },
   "source": [
    "**Parabéns por terminar a tarefa!**\n",
    "\n",
    "Você implementou com sucesso uma rede neural convolucional que utiliza uma rede pré-treinada para ajudá-lo a resolver o problema de classificação de humanos e cavalos."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
