{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_convnets/class_02/7%20-%20C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGxCD4mGHHjG"
   },
   "source": [
    "# Aumento de dados\n",
    "\n",
    "Nas lições anteriores, você viu que ter uma alta acurácia de treinamento não significa automaticamente ter um bom modelo preditivo.\n",
    "\n",
    "Ele ainda pode ter um desempenho ruim em novos dados porque se ajustou demais ao conjunto de treinamento.\n",
    "\n",
    "Neste laboratório, você verá como evitar isso usando _data augmentation_.\n",
    "\n",
    "Isso aumenta a quantidade de dados de treinamento modificando as propriedades dos dados de treinamento existentes. \n",
    "\n",
    "Por exemplo, em dados de imagem, você pode aplicar diferentes técnicas de pré-processamento, como: girar, inverter, cortar ou aplicar zoom nas imagens existentes para simular outros dados com os quais o modelo também deve aprender. \n",
    "\n",
    "Dessa forma, o modelo veria mais variedade nas imagens durante o treinamento e, assim, inferiria melhor sobre dados novos e não vistos anteriormente.\n",
    "\n",
    "Vamos ver como isso pode ser feito nas seções a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJJqX4DxcQs8"
   },
   "source": [
    "## Desempenho da linha de base\n",
    "\n",
    "Você começará com um modelo que é muito eficaz no aprendizado de `Cats vs Dogs` sem aumento de dados.\n",
    "\n",
    "Ele é semelhante aos modelos anteriores que você usou.\n",
    "\n",
    "Observe que há quatro camadas convolucionais com 32, 64, 128 e 128 convoluções, respectivamente.\n",
    "\n",
    "O código é basicamente o mesmo do laboratório anterior, portanto, não analisaremos os detalhes passo a passo, pois você já o viu antes.\n",
    "\n",
    "Você treinará apenas 20 épocas para economizar tempo, mas fique à vontade para aumentar esse número se quiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJZIF29-dIRv"
   },
   "outputs": [],
   "source": [
    "# Baixar o conjunto de dados\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DyUfCTgdwa8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Descompactar o arquivo\n",
    "zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "zip_ref.extractall(\"tmp/\")\n",
    "zip_ref.close()\n",
    "\n",
    "# Atribuir diretórios de conjuntos de treinamento e validação\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Diretório com fotos de treinamento de gatos\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Diretório com fotos de treinamento de cães\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Diretório com imagens de gatos para validação\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Diretório com fotos de cães para validação\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub_BdOJIfZ_Q"
   },
   "source": [
    "Você colocará a criação do modelo dentro de uma função para poder inicializar facilmente um novo modelo quando usar a aumento de dados mais adiante neste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWllK_Wad-Mx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def create_model():\n",
    "  '''Cria uma CNN com 4 camadas convolucionais'''\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "                optimizer=RMSprop(learning_rate=1e-4),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJPyDEzOqrKB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Todas as imagens serão redimensionadas em 1,/255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Fluxo de imagens de treinamento em lotes de 20 usando o gerador train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # Esse é o diretório de origem das imagens de treinamento\n",
    "        target_size=(150, 150),  # Todas as imagens serão redimensionadas para 150x150\n",
    "        batch_size=20,\n",
    "        # Como usamos a perda binary_crossentropy, precisamos de rótulos binários\n",
    "        class_mode='binary')\n",
    "\n",
    "# Imagens de validação de fluxo em lotes de 20 usando o gerador test_datagen\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdqUoF44esR3"
   },
   "outputs": [],
   "source": [
    "# Constante para épocas\n",
    "EPOCHS = 20\n",
    "\n",
    "# Criar um novo modelo\n",
    "model = create_model()\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 imagens = batch_size * steps\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 imagens = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-G0Am4cguNt"
   },
   "source": [
    "Em seguida, você visualizará a perda e a acurácia em relação ao conjunto de treinamento e validação.\n",
    "\n",
    "Você usará novamente uma função auxiliar para que ela possa ser reutilizada posteriormente.\n",
    "\n",
    "Essa função aceita um objeto [History](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History) que contém os resultados do método `fit()` que você executou acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZWPcmKWO303"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "  '''Plota a perda e a Acurácia do treinamento e da validação de um objeto de histórico'''\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'bo', label='Acurácia do treinamento')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Acurácia da validação')\n",
    "  plt.title('Acurácia do treinamento e da validação')\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'bo', label='Perda de Treino')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Perda de Validação')\n",
    "  plt.title('Perda de treinamento e validação')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vojz4NYXiT_f"
   },
   "outputs": [],
   "source": [
    "# Plotar os resultados do treinamento\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb81GvNov-Tg"
   },
   "source": [
    "Nos resultados acima, você verá que a acurácia do treinamento é superior a 90% e a acurácia da validação está na faixa de 70% a 80%.\n",
    "\n",
    "Esse é um ótimo exemplo de _overfitting_, o que, em resumo, significa que ele pode se sair muito bem com imagens que já viu antes, mas não tão bem com imagens que não viu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KBz-vFbjLZX"
   },
   "source": [
    "## Aumento de dados\n",
    "\n",
    "Um método simples para evitar o _overfitting_ é alterar um pouco as imagens.\n",
    "\n",
    "Se você pensar bem, a maioria das imagens de um gato é muito semelhante: as orelhas estão no topo, depois os olhos, depois a boca etc.\n",
    "\n",
    "Coisas como a distância entre os olhos e as orelhas também serão sempre muito semelhantes. \n",
    "\n",
    "E se você ajustar um pouco as imagens: girar a imagem, comprimi-la, etc.?  É disso que se trata o aumento de imagens. E há uma API que facilita isso!\n",
    "\n",
    "Dê uma olhada no [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) que você tem usado para redimensionar a imagem. Há outras propriedades nele que você pode usar para aumentar a imagem. \n",
    "\n",
    "```\n",
    "# Atualizado para fazer o aumento da imagem\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "```\n",
    "\n",
    "Essas são apenas algumas das opções disponíveis. Vamos examiná-las rapidamente:\n",
    "\n",
    "* `rotation_range` é um valor em graus (0-180) dentro do qual as imagens serão giradas aleatoriamente.\n",
    "* `width_shift` e `height_shift` são intervalos (como uma fração da largura ou altura total) dentro dos quais as imagens podem ser convertidas aleatoriamente na vertical ou na horizontal.\n",
    "* O `shear_range` serve para aplicar transformações de cisalhamento aleatoriamente.\n",
    "* O `zoom_range` serve para aplicar zoom aleatoriamente nas imagens.\n",
    "* `horizontal_flip` serve para inverter metade das imagens horizontalmente de forma aleatória. Isso é relevante quando não há suposições de assimetria horizontal (por exemplo, imagens do mundo real).\n",
    "* O `fill_mode` é a estratégia usada para preencher os pixels recém-criados, que podem aparecer após uma rotação ou uma mudança de largura/altura.\n",
    "\n",
    "\n",
    "Execute as próximas células para ver o impacto nos resultados. O código é semelhante ao da linha de base, mas a definição de `train_datagen` foi atualizada para usar os parâmetros descritos acima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK7_Fflgv8YC"
   },
   "outputs": [],
   "source": [
    "# Criar um novo modelo\n",
    "model_for_aug = create_model()\n",
    "\n",
    "# Esse código foi alterado. Agora, em vez de o ImageGenerator apenas redimensionar\n",
    "# a imagem, também giramos e fazemos outras operações\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Fluxo de imagens de treinamento em lotes de 20 usando o gerador train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # Esse é o diretório de origem das imagens de treinamento\n",
    "        target_size=(150, 150),  # Todas as imagens serão redimensionadas para 150x150\n",
    "        batch_size=20,\n",
    "        # Como usamos a perda binary_crossentropy, precisamos de rótulos binários\n",
    "        class_mode='binary')\n",
    "\n",
    "# Fluxo de Imagens de validação em lotes de 20 usando o gerador test_datagen\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Treinar o novo modelo\n",
    "history_with_aug = model_for_aug.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 imagens = batch_size * steps\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 imagens = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnyRnwopT5aW"
   },
   "outputs": [],
   "source": [
    "# Plote os resultados do treinamento com aumento de dados\n",
    "plot_loss_acc(history_with_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D1hd5fqmJUx"
   },
   "source": [
    "Como você pode ver, a acurácia do treinamento diminuiu em comparação com a linha de base.\n",
    "\n",
    "Isso é esperado porque (como resultado do aumento de dados) há mais variedade nas imagens e, portanto, o modelo precisará de mais execuções para aprender com elas.\n",
    "\n",
    "O ponto positivo é que a acurácia da validação não está mais estagnada e está mais alinhada com os resultados do treinamento.\n",
    "\n",
    "Isso significa que o modelo agora está apresentando melhor desempenho em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4B9b6GPnKg1"
   },
   "source": [
    "## Encerramento\n",
    "\n",
    "Este exercício mostrou um truque simples para evitar o _overfitting_.\n",
    "\n",
    "Você pode melhorar seus resultados de linha de base simplesmente ajustando as mesmas imagens que já possui.\n",
    "\n",
    "A classe `ImageDataGenerator` tem parâmetros incorporados para fazer exatamente isso.\n",
    "\n",
    "Tente modificar um pouco mais os valores no `train_datagen` e veja os resultados que você obtém.\n",
    "\n",
    "Observe que isso não funcionará em todos os casos.\n",
    "\n",
    "Na próxima atividade, você verá um cenário em que o aumento de dados não ajudará a melhorar a acurácia da validação."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W2/ungraded_labs/C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
     "timestamp": 1639637705486
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
