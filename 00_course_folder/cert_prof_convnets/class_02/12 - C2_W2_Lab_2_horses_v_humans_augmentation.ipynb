{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_convnets/class_02/12%20-%20C2_W2_Lab_2_horses_v_humans_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37v_yExZppEp"
   },
   "source": [
    "# Aumento de dados no conjunto de dados Horses or Humans\n",
    "\n",
    "No laboratório anterior, você viu como o aumento de dados ajudou a melhorar o desempenho do modelo em dados não vistos.\n",
    "\n",
    "Ao ajustar as imagens de treinamento de cães e gatos, o modelo conseguiu aprender recursos que também são representativos dos dados de validação.\n",
    "\n",
    "No entanto, a aplicação do aumento de dados exige um bom entendimento do conjunto de dados.\n",
    "\n",
    "A simples transformação aleatória nem sempre produzirá bons resultados. \n",
    "\n",
    "Nas próximas células, você aplicará as mesmas técnicas ao conjunto de dados `Horses or Humans` e analisará os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lslf0vB3rQlU"
   },
   "outputs": [],
   "source": [
    "# Faça o download do conjunto de treinamento\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar o conjunto de validação\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXZT2UsyIVe_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Extrair o arquivo\n",
    "zip_ref = zipfile.ZipFile('./horse-or-human.zip', 'r')\n",
    "zip_ref.extractall('tmp/horse-or-human')\n",
    "\n",
    "zip_ref = zipfile.ZipFile('./validation-horse-or-human.zip', 'r')\n",
    "zip_ref.extractall('tmp/validation-horse-or-human')\n",
    "\n",
    "zip_ref.close()\n",
    "\n",
    "# Diretório com fotos de cavalos de treinamento\n",
    "train_horse_dir = os.path.join('tmp/horse-or-human/horses')\n",
    "\n",
    "# Diretório com imagens humanas de treinamento\n",
    "train_human_dir = os.path.join('tmp/horse-or-human/humans')\n",
    "\n",
    "# Diretório com imagens de cavalos de validação\n",
    "validation_horse_dir = os.path.join('tmp/validation-horse-or-human/horses')\n",
    "\n",
    "# Diretório com imagens humanas de validação\n",
    "validation_human_dir = os.path.join('tmp/validation-horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PixZ2s5QbYQ3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Construir o modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Observe que a forma de entrada é o tamanho desejado da imagem 300x300 com 3 bytes de cor\n",
    "    # Essa é a primeira convolução\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # A segunda convolução\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # A terceira convolução\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # A quarta convolução\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # A quinta convolução\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Achatar os resultados para alimentar um DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Camada oculta de 512 neurônios\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "# Apenas 1 neurônio de saída. Ele conterá um valor de 0 a 1, sendo 0 para uma classe (\"cavalos\") e 1 para a outra (\"humanos\")\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DHWhFP_uhq3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Definir parâmetros de treinamento\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClebU9NJg99G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Aplicar data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Fluco de imagens de treinamento em lotes de 128 usando o gerador train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'tmp/horse-or-human/',  # Esse é o diretório de origem das imagens de treinamento\n",
    "        target_size=(300, 300),   # Todas as imagens serão redimensionadas para 300x300\n",
    "        batch_size=128,\n",
    "        # Como usamos a perda binary_crossentropy, precisamos de rótulos binários\n",
    "        class_mode='binary')\n",
    "\n",
    "# Fluco de imagens de treinamento em lotes de 128 usando o gerador train_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'tmp/validation-horse-or-human/',  # Esse é o diretório de origem das imagens de validação\n",
    "        target_size=(300, 300),  # Todas as imagens serão redimensionadas para 300x300\n",
    "        batch_size=32,\n",
    "        # Como usamos a perda binary_crossentropy, precisamos de rótulos binários\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fb1_lgobv81m"
   },
   "outputs": [],
   "source": [
    "# Constante para épocas\n",
    "EPOCHS = 20\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zNPRWOVJdOH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotar os resultados do modelo\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Acurácia de Treino')\n",
    "plt.plot(epochs, val_acc, 'b', label='Acurácia de Validação')\n",
    "plt.title('Acurácia de Treino e Validação')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Perda de Treino')\n",
    "plt.plot(epochs, val_loss, 'b', label='Perda de Validação')\n",
    "plt.title('Perda de Treino e Validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwyabYvCsvtn"
   },
   "source": [
    "Como você pode ver nos resultados, as técnicas de pré-processamento usadas para aumentar os dados não ajudaram muito nos resultados.\n",
    "\n",
    "A acurácia da validação está flutuando e não está tendendo a aumentar como a acurácia do treinamento.\n",
    "\n",
    "Isso pode ocorrer porque os dados de treinamento adicionais gerados ainda não representam os recursos nos dados de validação.\n",
    "\n",
    "Por exemplo, algumas poses humanas ou de cavalos no conjunto de validação não podem ser imitadas pelas técnicas de processamento de imagens fornecidas pelo `ImageDataGenerator`.\n",
    "\n",
    "Pode ser também que o plano de fundo das imagens de treinamento também seja aprendido, de modo que o plano de fundo branco do conjunto de validação esteja confundindo o modelo, mesmo com o corte.\n",
    "\n",
    "Tente examinar as imagens de validação no diretório `tmp/validation-horse-or-human` (observação: se estiver usando o Colab, você poderá usar o explorador de arquivos à esquerda para explorar as imagens) e veja se é possível aumentar as imagens de treinamento para que correspondam às suas características.\n",
    "\n",
    "Se isso não for possível, neste ponto você pode considerar outras técnicas, o que verá nas próximas lições."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W2_Lab_2_horses_v_humans_augmentation.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W2/ungraded_labs/C2_W2_Lab_2_horses_v_humans_augmentation.ipynb",
     "timestamp": 1639648217641
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
