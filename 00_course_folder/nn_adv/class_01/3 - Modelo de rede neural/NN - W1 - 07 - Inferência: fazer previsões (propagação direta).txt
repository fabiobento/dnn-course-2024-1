Vamos pegar o que aprendemos e agrupá-lo em um algoritmo para permitir que sua rede neural faça inferências ou predições. Esse será um algoritmo chamado propagação direta. Vamos dar uma olhada. Vou usar como exemplo motivador o reconhecimento de dígitos manuscritos. E para simplificar, vamos apenas distinguir entre os dígitos manuscritos zero e um. Então, é apenas um problema de classificação binária em que vamos inserir uma imagem e classificar, esse é o dígito zero ou o dígito um? E você mesmo poderá brincar com isso no final desta semana no laboratório prático Para o exemplo do slide, vou usar uma imagem de oito por oito. Portanto, essa imagem de um é essa grade ou matriz de valores de intensidade de oito por oito ou 64 pixels, onde 255 denota um pixel branco brilhante e zero denotaria um pixel preto. E números diferentes são diferentes tons de cinza entre os tons de preto e branco. Dados esses 64 recursos de entrada, usaremos a rede neural com duas camadas ocultas. Onde a primeira camada oculta tem 25 neurônios ou 25 unidades. A segunda camada oculta tem 15 neurônios ou 15 unidades. E então, finalmente, a camada de saída ou unidade de saída, qual é a chance de isso ser 1 versus 0?. Então, vamos percorrer a sequência de cálculos que em sua rede neural precisará fazer para ir da entrada X, esses oito por oito ou 64 números até a probabilidade prevista a3. O primeiro cálculo é ir de X para a1, e é isso que a primeira camada da primeira camada oculta faz. Ele realiza o cálculo de uma superfaixa. 1 colchete igual a essa fórmula à direita. Observe que um tem 25 números porque essa camada oculta tem 25 unidades. É por isso que os parâmetros vão de w1 a w25 e de b1 a b25. E eu escrevi x aqui, mas eu também poderia ter escrito a0 aqui porque, por convenção, a ativação da camada zero, que é a0, é igual ao valor do recurso de entrada x. Então, vamos calcular a1. A próxima etapa é calcular a2. Olhando para a segunda camada oculta, ele então realiza esse cálculo em que a2 é uma função de a1 e é computado como a função de ativação de ponto seguro aplicada ao produto w dot a1 mais o valor correspondente de b. Observe que a camada dois tem 15 neurônios ou 15 unidades, e é por isso que os parâmetros aqui vão de w1 a w15 e b1 a b15. Agora calculamos a2. A etapa final é então calcular a3 e fazemos isso usando um cálculo muito semelhante. Só que agora, essa terceira camada, a camada de saída tem apenas uma unidade, e é por isso que há apenas uma saída aqui. Então a3 é apenas um escalar. E, finalmente, você pode, opcionalmente, pegar um subscrito de 3 e limitá-lo em 4,5 para criar um rótulo de classificação binária. Esse é o dígito 1? Sim ou não? Portanto, a sequência de cálculos primeiro pega x e depois calcula a1, depois calcula a2 e depois calcula a3, que também é a saída das redes neurais. Você também pode escrever isso como f (x). Portanto, lembre-se de que quando aprendemos sobre regressão linear e regressão logística, usamos f (x) para denotar a saída da regressão linear ou regressão logística.
Reproduza o vídeo começando em :4:2 e siga a transcrição4:02
Portanto, também podemos usar f (x) para denotar a função computada pela rede neural como uma função de x. Como esse cálculo vai da esquerda para a direita, você começa com x e calcula a1, depois a2 e depois a3. Esse álbum também é chamado de propagação direta porque você está propagando as ativações dos neurônios. Então você está fazendo esses cálculos na direção para frente, da esquerda para a direita. E isso contrasta com um algoritmo diferente chamado retropropagação ou retropropagação, que é usado para aprender. E isso é algo sobre o qual você aprenderá na próxima semana. E, a propósito, esse tipo de arquitetura de rede neural em que você tem mais unidades ocultas inicialmente e , em seguida, o número de unidades ocultas diminui à medida que você se aproxima da camada de saída. Também há uma escolha bastante comum ao escolher arquiteturas de redes neurais. E você também vê mais exemplos disso no laboratório prático. Então, isso é inferência de rede neural usando o algoritmo de propagação direta. E com isso, você seria capaz de baixar os parâmetros de uma rede neural que outra pessoa treinou e publicou na Internet. E você seria capaz de realizar inferências sobre seus novos dados usando a rede neural deles. Agora que você viu a matemática e o algoritmo, vamos dar uma olhada em como você pode realmente implementar isso no tensorflow. Especificamente, vamos dar uma olhada nisso no próximo vídeo.
