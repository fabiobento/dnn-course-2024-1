{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório Prático: Redes Neurais para Reconhecimento de Dígitos Manuscritos, Binário\n",
    "\n",
    "Neste exercício, você usará uma rede neural para reconhecer os dígitos zero e um escritos à mão.\n",
    "\n",
    "\n",
    "# Tópicos\n",
    "- [ 1 - Pacotes ](#1)\n",
    "- [ 2 - Redes Neurais](#2)\n",
    "  - [ 2.1 Definição do Problema](#2.1)\n",
    "  - [ 2.2 Conjunto de Dados](#2.2)\n",
    "  - [ 2.3 Representação de Modelo](#2.3)\n",
    "  - [ 2.4 Implementação do Modelo no Tensorflow](#2.4)\n",
    "    - [ Exercício 1](#ex01)\n",
    "  - [ 2.5 Implementação do Modelo no NumPy(Propagação Direta no NumPy)](#2.5)\n",
    "    - [ Exercício 2](#ex02)\n",
    "  - [ 2.6 Implementação do Modelo NumPy - Vetorizado](#2.6)\n",
    "    - [ Exercício 3](#ex03)\n",
    "  - [ 2.7 Parabéns!](#2.7)\n",
    "  - [ 2.8 Tutorial de Broadcasting no NumPy](#2.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_01/11%20-%20Atividade%20avaliativa%20-%20Redes%20Neurais/lab_utils_ml_adv_assig_week_1.zip\n",
    "!unzip -n -q lab_utils_ml_adv_assig_week_1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Pacotes \n",
    "\n",
    "Primeiro, vamos executar a célula abaixo para importar todos os pacotes de que você precisará durante esta tarefa.\n",
    "- [numpy](https://numpy.org/) é o pacote fundamental para a computação científica com Python.\n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca popular para plotar gráficos em Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) uma plataforma popular para aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from autils import *\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow e Keras**  \n",
    "O Tensorflow é um pacote de aprendizado de máquina desenvolvido pelo Google. Em 2019, o Google integrou o Keras ao Tensorflow e lançou o Tensorflow 2.0. O Keras é uma estrutura(_framework_) desenvolvida de forma independente por François Chollet que cria uma interface simples e centrada em camadas para o Tensorflow. Este curso usará a interface do Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Redes Neurais\n",
    "\n",
    "Uma regressão logística pode ser estendida para lidar com limites não lineares usando a regressão polinomial. No entanto, para cenários ainda mais complexos, como o reconhecimento de imagens, é preferível usar redes neurais.\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Definição do Problema\n",
    "\n",
    "Neste exercício, você usará uma rede neural para reconhecer dois dígitos escritos à mão, zero e um. Essa é uma tarefa de classificação binária. O reconhecimento automatizado de dígitos manuscritos tem muitas amplamente utilizado atualmente, desde o reconhecimento de códigos postais em envelopes de correio até o reconhecimento de valores escritos em documentos bancários. Você ampliará essa rede para reconhecer todos os 10 dígitos (0-9) em uma tarefa futura. \n",
    "\n",
    "Este exercício mostrará como os métodos que você aprendeu podem ser usados para essa tarefa de classificação.\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Conjunto de Dados\n",
    "\n",
    "Você começará carregando o conjunto de dados para essa tarefa.\n",
    "- A função `load_data()` mostrada abaixo carrega dados nas variáveis `X` e `y`\n",
    "\n",
    "\n",
    "- O conjunto de dados contém 1.000 exemplos de treinamento de dígitos manuscritos $^1$, aqui limitados a zero e um.\n",
    "\n",
    "    - Cada exemplo de treinamento é uma imagem em escala de cinza de 20 pixels x 20 pixels do dígito. \n",
    "        - Cada pixel é representado por um número de ponto flutuante que indica a intensidade da escala de cinza naquele local. \n",
    "        - A grade de 20 por 20 pixels é \"desenrolada\"(_unrolled_) em um vetor de 400 dimensões. \n",
    "        - Cada exemplo de treinamento torna-se uma única linha em nossa matriz de dados `X`. \n",
    "        - Isso nos dá uma matriz 1000 x 400 `X` em que cada linha é um exemplo de treinamento de uma imagem de dígito manuscrito.\n",
    "\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- A segunda parte do conjunto de treinamento é um vetor uni-dimensional de 1000 x 1 `y` que contém rótulos para o conjunto de treinamento\n",
    "    - `y = 0` se a imagem tiver o dígito `0`, `y = 1` se a imagem tiver o dígito `1`.\n",
    "\n",
    "$^1$<sub> Esse é um subconjunto do conjunto de dados de dígitos manuscritos MNIST de Yann Lecun</sub>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Carregar conjunto de dados\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.1\"></a>\n",
    "#### 2.2.1 Visualizar as Variáveis\n",
    "Vamos nos familiarizar mais com seu conjunto de dados.  \n",
    "- Um bom ponto de partida é imprimir cada variável e ver o que ela contém.\n",
    "\n",
    "O código abaixo imprime os elementos das variáveis `X` e `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('O primeiro elemento de X é: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O primeiro elemento de y é: ', y[0,0])\n",
    "print ('O último elemento de y é: ', y[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.2\"></a>\n",
    "#### 2.2.2 Verificar as Dimensões de suas Variáveis\n",
    "\n",
    "Outra maneira de se familiarizar com seus dados é visualizar suas dimensões. Imprima a forma de `X` e `y` e veja quantos exemplos de treinamento você tem em seu conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O formato de  X é: ' + str(X.shape))\n",
    "print ('O formato de y é: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.3\"></a>\n",
    "#### 2.2.3 Visualizando os Dados\n",
    "\n",
    "Você começará visualizando um subconjunto do conjunto de treinamento. \n",
    "- Na célula abaixo, o código seleciona aleatoriamente 64 linhas de `X`, mapeia cada linha de volta para uma imagem em escala de cinza de 20 pixels por 20 pixels e exibe as imagens juntas. \n",
    "- O rótulo de cada imagem é exibido acima da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Selecionar índices randômicos\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecione as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Exibir o rótulo da imagem acima\n",
    "    ax.set_title(y[random_index,0])\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Representação do Modelo\n",
    "\n",
    "A rede neural que você usará neste trabalho é mostrada na figura abaixo. \n",
    "- Ela tem três camadas densas com ativações sigmoides.\n",
    "    - Lembre-se de que nossas entradas são valores de pixel de imagens de dígitos.\n",
    "    - Como as imagens são de tamanho $20\\times20$, isso nos dá $400$ de entradas\n",
    "    \n",
    "<img src=\"images/C2_W1_Assign1.PNG\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          \n",
    "- Os parâmetros têm dimensões que são dimensionadas para uma rede neural com $25$ unidades na camada 1, $15$ unidades na camada 2 e $1$ unidade de saída na camada 3. \n",
    "\n",
    "    - Lembre-se de que as dimensões desses parâmetros são determinadas da seguinte forma:\n",
    "        - Se a rede tiver $s_{in}$ unidades em uma camada e $s_{out}$ unidades na camada seguinte, então \n",
    "            - $W$ terá a dimensão de $s_{in} \\times s_{out}$.\n",
    "            - $b$ será um vetor com $s_{out}$ elementos\n",
    "  \n",
    "    - Portanto, as formas de `W` e `b` são \n",
    "        - camada1: A forma de `W1` é (400, 25) e a forma de `b1` é (25,)\n",
    "        - camada2: A forma de `W2` é (25, 15) e a forma de `b2` é: (15,)\n",
    "        - camada3: A forma de `W3` é (15, 1) e a forma de `b3` é: (1,)\n",
    ">**Observação:** O vetor de bias `b` pode ser representado como uma matriz 1-D (n,) ou 2-D (1,n). O Tensorflow utiliza uma representação 1-D e este laboratório manterá essa convenção.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Implementação do Modelo no Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos do Tensorflow são criados camada por camada. As dimensões de entrada de uma camada ($s_{in}$ acima) são calculadas para você. Você especifica as *dimensões de saída* de uma camada e isso determina a dimensão de entrada da próxima camada. A dimensão de entrada da primeira camada é derivada do tamanho dos dados de entrada especificados na instrução `model.fit` abaixo. \n",
    ">**Nota:** Também é possível adicionar uma camada de entrada que especifique a dimensão de entrada da primeira camada. Por exemplo:  \n",
    "`tf.keras.Input(shape=(400,)), #especifica a forma de entrada`  \n",
    "Incluiremos isso aqui para esclarecer o dimensionamento de alguns modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercício 1\n",
    "\n",
    "Abaixo, usando Keras [Sequential model](https://keras.io/guides/sequential_model/) e [Dense Layer](https://keras.io/api/layers/core_layers/dense/) com uma ativação sigmoide para construa a rede descrita acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(400,)),    #especifique a dimensão da entrada\n",
    "        ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "        ### TERMINE SEU CÓDIGO AQUI ###\n",
    "    ], name = \"my_model\" \n",
    ")                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Saída Esperada (Click para expandir) </b></font></summary>\n",
    "A função `model.summary()` exibe um resumo útil do modelo. Como especificamos um tamanho de camada de entrada, a forma das matrizes de peso e bias é determinada e o número total de parâmetros por camada pode ser mostrado. Observe que os nomes das camadas podem variar, pois são gerados automaticamente.\n",
    "    \n",
    "```\n",
    "Model: \"my_model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 25)                10025     \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 15)                390       \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 16        \n",
    "=================================================================\n",
    "Total params: 10,431\n",
    "Trainable params: 10,431\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para Dicas</b></font></summary>\n",
    "Conforme descrito na aula:\n",
    "    \n",
    "```python\n",
    "model = Sequential(                      \n",
    "    [                                   \n",
    "        tf.keras.Input(shape=(400,)),    # especifique a dimensão da entrada (opcional)\n",
    "        Dense(25, activation='sigmoid'), \n",
    "        Dense(15, activation='sigmoid'), \n",
    "        Dense(1,  activation='sigmoid')  \n",
    "    ], name = \"my_model\"                                    \n",
    ")                                       \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Teste da unidade\n",
    "\n",
    "from public_tests import *\n",
    "\n",
    "test_c1(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As contagens de parâmetros mostradas no resumo correspondem ao número de elementos nas matrizes de peso e polarização, conforme mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "L1_num_params = 400 * 25 + 25  # W1 parameters  + b1 parameters\n",
    "L2_num_params = 25 * 15 + 15   # W2 parameters  + b2 parameters\n",
    "L3_num_params = 15 * 1 + 1     # W3 parameters  + b3 parameters\n",
    "print(\"Parâmetros da camada 1 = \", L1_num_params, \", Parâmetros da camada 2 = \", L2_num_params, \",  Parâmetros da camada 3 = \", L3_num_params )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos examinar os detalhes do modelo extraindo primeiro as camadas com `model.layers` e, em seguida, extraindo os pesos com `layerx.get_weights()`, conforme mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#### Examine o formato dos pesos\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"Formato de shape = {W1.shape}, Formato de b1 = {b1.shape}\")\n",
    "print(f\"Formato de shape = {W2.shape}, Formato de b2 = {b2.shape}\")\n",
    "print(f\"Formato de shape = {W3.shape}, Formato de b3 = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**\n",
    "```\n",
    "W1 shape = (400, 25), b1 shape = (25,)  \n",
    "W2 shape = (25, 15), b2 shape = (15,)  \n",
    "W3 shape = (15, 1), b3 shape = (1,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xx.get_weights` retorna uma matriz NumPy. Também é possível acessar os pesos diretamente em sua forma de tensor. Observe a forma dos tensores na camada final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(model.layers[2].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir definirá uma função de perda e executará a descida de gradiente para ajustar os pesos do modelo aos dados de treinamento. Isso será explicado em mais detalhes na próxima aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X,y,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para executar o modelo em um exemplo para fazer uma previsão, use [Keras `predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model). A entrada para `predict` é uma matriz, portanto, o exemplo único é remodelado para ser bidimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X[0].reshape(1,400))  # 0\n",
    "print(f\" predição de um zero: {prediction}\")\n",
    "prediction = model.predict(X[500].reshape(1,400))  # 1\n",
    "print(f\" predição de um 1:  {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado do modelo é interpretado como uma probabilidade. No primeiro exemplo acima, a entrada é um zero. O modelo prevê que a probabilidade de a entrada ser um é quase zero. \n",
    "No segundo exemplo, a entrada é um. O modelo prevê que a probabilidade de o input ser um é quase um.\n",
    "Como no caso da regressão logística, a probabilidade é comparada a um limite para fazer uma previsão final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(f\"predição após limiar: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar as previsões com os rótulos de uma amostra aleatória de 64 dígitos. Isso demora um pouco para ser executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92])#[esquerda, inferior, direita, superior]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Selecionar índices randômicos\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecionar as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Predizer utilizando a rede neural\n",
    "    prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    if prediction >= 0.5:\n",
    "        yhat = 1\n",
    "    else:\n",
    "        yhat = 0\n",
    "    \n",
    "    # Exibir o rótulo abaixo da imagem\n",
    "    ax.set_title(f\"{y[random_index,0]},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Rótulo, yhat\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 Implementação do Modelo no NumPy(Propagação Direta no NumPy)\n",
    "Conforme descrito na aula, é possível criar sua própria camada densa usando o NumPy. Isso pode ser utilizado para criar uma rede neural de várias camadas.\n",
    "\n",
    "<img src=\"images/C2_W1_dense2.PNG\" width=\"600\" height=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercício 2\n",
    "\n",
    "Abaixo, crie uma sub-rotina de camada densa. O exemplo da aula utilizou um loop for para visitar cada unidade (`j`) na camada e executar o produto escalar dos pesos dessa unidade (`W[:,j]`) e somar a polarização da unidade (`b[j]`) para formar `z`. Uma função de ativação `g(z)` é então aplicada a esse resultado. Esta seção não utilizará algumas das operações de matriz descritas nas aulas opcionais. Elas serão exploradas em uma seção posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "\n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "    return(a_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verificação rápida\n",
    "x_tst = 0.1*np.arange(1,3,1).reshape(2,)  # (1 exemplo, 2 recursos)\n",
    "W_tst = 0.1*np.arange(1,7,1).reshape(2,3) # (2 recursos de entrada, 3 recursos de saída)\n",
    "b_tst = 0.1*np.arange(1,4,1).reshape(3,)  # (3 recursos)\n",
    "A_tst = my_dense(x_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**\n",
    "```\n",
    "[0.54735762 0.57932425 0.61063923]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para Dicas</b></font></summary>\n",
    "Conforme descrito na aula:\n",
    "    \n",
    "```python\n",
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Calcula a camada densa\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Dados, 1 exemplo\n",
    "      W    (ndarray (n,j)) : Matriz de pesos, n recursos por unidade, j unidides\n",
    "      b    (ndarray (j, )) : Vetor de bias vector, j unidades  \n",
    "      g    função de ativação (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j unidades\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):             \n",
    "        w =                            # Selecione os pesos para a unidade j. Eles estão na coluna j de W\n",
    "        z =                            # produto escalar de w e a_in + b\n",
    "        a_out[j] =                     # aplicar a ativação a z\n",
    "    return(a_out)\n",
    "```\n",
    "   \n",
    "    \n",
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para mais dicas</b></font></summary>\n",
    "\n",
    "    \n",
    "```python\n",
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Calcula a camada densa\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Dados, 1 exemplo\n",
    "      W    (ndarray (n,j)) : Matriz de pesos, n recursos por unidade, j unidides\n",
    "      b    (ndarray (j, )) : Vetor de bias vector, j unidades  \n",
    "      g    função de ativação (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j unidades\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):             \n",
    "        w = W[:,j]                     \n",
    "        z = np.dot(w, a_in) + b[j]     \n",
    "        a_out[j] = g(z)                \n",
    "    return(a_out)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Teste da unidade\n",
    "\n",
    "test_c2(my_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula a seguir cria uma rede neural de três camadas utilizando a sub-rotina `my_dense` acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2, W3, b3):\n",
    "    a1 = my_dense(x,  W1, b1, sigmoid)\n",
    "    a2 = my_dense(a1, W2, b2, sigmoid)\n",
    "    a3 = my_dense(a2, W3, b3, sigmoid)\n",
    "    return(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos copiar os pesos e as tendências treinados do Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "W1_tmp,b1_tmp = layer1.get_weights()\n",
    "W2_tmp,b2_tmp = layer2.get_weights()\n",
    "W3_tmp,b3_tmp = layer3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# realizar predições\n",
    "prediction = my_sequential(X[0], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[0,0])\n",
    "prediction = my_sequential(X[500], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[500,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula a seguir para ver as previsões do modelo Numpy e do modelo Tensorflow. Isso leva um momento para ser executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92])#[esquerda, inferior, direita, superior]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Selecione índices aleatórios\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecione as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    # Prever usando a rede neural implementada no Numpy\n",
    "    my_prediction = my_sequential(X[random_index], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "    my_yhat = int(my_prediction >= 0.5)\n",
    "\n",
    "    # Prever usando a rede neural implementada no Tensorflow\n",
    "    tf_prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    tf_yhat = int(tf_prediction >= 0.5)\n",
    "    \n",
    "    # Exibir o rótulo acima da imagem\n",
    "    ax.set_title(f\"{y[random_index,0]},{tf_yhat},{my_yhat}\")\n",
    "    ax.set_axis_off() \n",
    "fig.suptitle(\"Rótulo, yhat Tensorflow, yhat Numpy\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Implementação do Modelo NumPy - Vetorizado\n",
    "Lembre-se das aulas que descrevem operações de vetores e matrizes que podem ser usadas para acelerar os cálculos.\n",
    "A seguir, descrevemos uma operação de camada que calcula a saída de todas as unidades em uma camada em um determinado exemplo de entrada:\n",
    "<img src=\"images/C2_W1_VectorMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "Podemos demonstrar isso usando os exemplos `X` e os parâmetros `W1`, `b1` acima. Usamos o `np.matmul` para realizar a multiplicação de matrizes. Observe que as dimensões de x e W devem ser compatíveis, conforme mostrado no diagrama acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "x = X[0].reshape(-1,1)         # vetor coluna (400,1)\n",
    "z1 = np.matmul(x.T,W1) + b1    # (1,400)(400,25) = (1,25)\n",
    "a1 = sigmoid(z1)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode dar um passo adiante e calcular todas as unidades de todos os exemplos em uma operação Matrix-Matrix.\n",
    "\n",
    "<img src=\"images/C2_W1_MatrixMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "A operação completa é $\\mathbf{Z}=\\mathbf{XW}+\\mathbf{b}$. Isso utilizará a transmissão do NumPy para expandir $\\mathbf{b}$ para $m$ linhas. Se não estiver familiarizado com isso, há um breve tutorial no final do notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex03\"></a>\n",
    "### Exercício 3\n",
    "\n",
    "Abaixo, componha uma nova sub-rotina `my_dense_v` que execute os cálculos de camada para uma matriz de exemplos. Isso utilizará `np.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def my_dense_v(A_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Calcula a camada densa\n",
    "    Args:\n",
    "      A_in (ndarray (m,n)) : Dados, m exemplos, cada um com n recursos  \n",
    "      W    (ndarray (n,j)) : Weight matrix, n recursos por unidade, j unidades\n",
    "      b    (ndarray (1,j)) : vetor de bias, j unidades  \n",
    "      g    função de ativação (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      A_out (tf.Tensor or ndarray (m,j)) : m exemplos, j unidades\n",
    "    \"\"\"\n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "\n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "    return(A_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_tst = 0.1*np.arange(1,9,1).reshape(4,2) # (4 exemplos, 2 recursos)\n",
    "W_tst = 0.1*np.arange(1,7,1).reshape(2,3) # (2 recursos de entrada, 3 recursos de saída)\n",
    "b_tst = 0.1*np.arange(1,4,1).reshape(1,3) # (1,3 recursos)\n",
    "A_tst = my_dense_v(X_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**\n",
    "\n",
    "```\n",
    "[[0.54735762 0.57932425 0.61063923]\n",
    " [0.57199613 0.61301418 0.65248946]\n",
    " [0.5962827  0.64565631 0.6921095 ]\n",
    " [0.62010643 0.67699586 0.72908792]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para Dicas</b></font></summary>\n",
    "    Na forma de matriz, isso pode ser escrito em uma ou duas linhas. \n",
    "    \n",
    "       Z = np.matmul de A_in e W mais b    \n",
    "       A_out é g(Z)\n",
    "\n",
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para código</b></font></summary>\n",
    "\n",
    "```python\n",
    "def my_dense_v(A_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Calcula a camada densa\n",
    "    Args:\n",
    "      A_in (ndarray (m,n)) : Dados, m exemplos, cada um com n recursos  \n",
    "      W    (ndarray (n,j)) : Weight matrix, n recursos por unidade, j unidades\n",
    "      b    (ndarray (1,j)) : vetor de bias, j unidades  \n",
    "      g    função de ativação (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      A_out (tf.Tensor or ndarray (m,j)) : m exemplos, j unidades\n",
    "    \"\"\"\n",
    "    Z = np.matmul(A_in,W) + b    \n",
    "    A_out = g(Z)                 \n",
    "    return(A_out)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Teste da unidade\n",
    "\n",
    "test_c3(my_dense_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula a seguir cria uma rede neural de três camadas utilizando a sub-rotina `my_dense_v` acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
    "    A1 = my_dense_v(X,  W1, b1, sigmoid)\n",
    "    A2 = my_dense_v(A1, W2, b2, sigmoid)\n",
    "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
    "    return(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos copiar novamente os pesos e os vieses treinadas do Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "W1_tmp,b1_tmp = layer1.get_weights()\n",
    "W2_tmp,b2_tmp = layer2.get_weights()\n",
    "W3_tmp,b3_tmp = layer3.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer uma previsão com o novo modelo. Isso fará uma previsão de *todos os exemplos de uma vez*. Observe a forma do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaremos um limite de 0,5 como antes, mas a todas as previsões de uma só vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "Yhat = (Prediction >= 0.5).astype(int)\n",
    "print(\"predict a zero: \",Yhat[0], \"predict a one: \", Yhat[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula a seguir para ver as previsões. Isso usará as previsões que acabamos de calcular acima. A execução demora um pouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Selecione índices aleatórios\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecione as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "   \n",
    "    # Exibir o rótulo acima da imagem\n",
    "    ax.set_title(f\"{y[random_index,0]}, {Yhat[random_index, 0]}\")\n",
    "    ax.set_axis_off() \n",
    "fig.suptitle(\"Label, Yhat\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver a aparência de uma das imagens classificadas incorretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1, 1))\n",
    "errors = np.where(y != Yhat)\n",
    "random_index = errors[0][0]\n",
    "X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "plt.imshow(X_random_reshaped, cmap='gray')\n",
    "plt.title(f\"{y[random_index,0]}, {Yhat[random_index, 0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.7\"></a>\n",
    "### 2.7 Parabéns!\n",
    "Você construiu e utilizou uma rede neural com sucesso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.8\"></a>\n",
    "### 2.8 2.8 Tutorial de Broadcasting no NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "No último exemplo, $\\mathbf{Z}=\\mathbf{XW} + \\mathbf{b}$ utilizou o broadcasting  do NumPy para expandir o vetor $\\mathbf{b}$. Se não estiver familiarizado com o _NumPy Broadcasting_, este breve tutorial é pra você!\n",
    "\n",
    "$\\mathbf{XW}$ é uma operação de matriz-matriz com dimensões $(m,j_1)(j_1,j_2)$ que resulta em uma matriz com dimensão $(m,j_2)$. A isso, adicionamos um vetor $\\mathbf{b}$ com dimensão $(1,j_2)$. $\\mathbf{b}$ deve ser expandido para ser uma matriz $(m,j_2)$ para que essa operação de elementos faça sentido. Essa expansão é realizada para você pelo _NumPy Broadcasting_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _broadcasting_ se aplica a operações que envolvem operações elemento-a-elemento.  \n",
    "Sua operação básica é \"esticar\" uma dimensão menor replicando elementos para corresponder a uma dimensão maior.\n",
    "\n",
    "Mais [especificamente](https://NumPy.org/doc/stable/user/basics.broadcasting.html): \n",
    "Ao operar em duas matrizes, o NumPy compara suas formas em termos de elementos. Ele começa com as dimensões mais à direita e segue para a esquerda. Duas dimensões são compatíveis quando\n",
    "- são iguais, ou\n",
    "- uma delas é 1   \n",
    "\n",
    "Se essas condições não forem atendidas, será lançada uma exceção _ValueError: operands could not be broadcast together_, indicando que as matrizes têm formas incompatíveis. O tamanho da matriz resultante é o tamanho que não é 1 ao longo de cada eixo das entradas.\n",
    "\n",
    "Aqui estão alguns exemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center> <img src=\"./images/C2_W1_Assign1_BroadcastIndexes.PNG\"  alt='missing' width=\"400\"  ><center/>\n",
    "    <figcaption>Calculando o formato resultante do Broadcast</figcaption>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico abaixo descreve as dimensões de expansão. Observe o texto em vermelho abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center> <img src=\"./images/C2_W1_Assign1_Broadcasting.gif\"  alt='missing' width=\"600\"  ><center/>\n",
    "    <figcaption>O Broadcast expande os argumentos para que correspondam a operações com elementos</figcaption>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico acima mostra o NumPy expandindo os argumentos para que combinem antes da operação final. Observe que essa é uma descrição fictícia. A mecânica real da operação do NumPy escolhe a implementação mais eficiente.\n",
    "\n",
    "Para cada um dos exemplos a seguir, tente adivinhar o tamanho do resultado antes de executar o exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que isso se aplica a todas as operações com elemento-a-elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a * b).shape: {(a * b).shape}, \\na * b = \\n{a * b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"./images/C2_W1_Assign1_VectorAdd.PNG\"  alt='missing' width=\"740\" >\n",
    "    <center><figcaption><b>Row-Column Element-Wise Operations</b></figcaption></center>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4]).reshape(-1,1)\n",
    "b = np.array([1,2,3]).reshape(1,-1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é o cenário na camada densa que você criou acima. Adição de um vetor 1-D $b$ a uma matriz (m,j).\n",
    "<figure>\n",
    "    <img src=\"./images/C2_W1_Assign1_BroadcastMatrix.PNG\"  alt='missing' width=\"740\" >\n",
    "    <center><figcaption><b>Matrix + Vetor 1-D</b></figcaption></center>\n",
    "<figure/>"
   ]
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
