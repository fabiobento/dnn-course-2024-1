{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_01/Laborat%C3%B3rios/lab_utils_ml_adv_week_1.zip\n",
    "      \n",
    "!unzip -n -q lab_utils_ml_adv_week_1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neurônios e Camadas\n",
    "Neste laboratório, exploraremos o funcionamento interno dos neurônios/unidades e camadas. Em particular, o laboratório estabelecerá paralelos com os modelos que você viu anteriormente, o modelo de regressão/linear e o modelo logístico. O laboratório apresentará o Tensorflow e demonstrará como esses modelos são implementados nessa estrutura.<figure>\n",
    "   <img src=\"./images/C2_W1_NeuronsAndLayers.png\"  style=\"width:540px;height:200px;\" >\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes\n",
    "**Tensorflow e Keras**  \n",
    "O Tensorflow é um pacote de aprendizado de máquina desenvolvido pelo Google. Em 2019, o Google integrou o Keras ao Tensorflow e lançou o Tensorflow 2.0. O Keras é uma estrutura desenvolvida de forma independente por François Chollet que cria uma interface simples e centrada em camadas para o Tensorflow. Este curso usará a interface do Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from lab_utils_common import dlc\n",
    "from lab_neurons_utils import plt_prob_1d, sigmoidnp, plt_linear, plt_logistic\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurônios sem ativação - Modelo de Regressão/Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conjunto deDados\n",
    "Usaremos um exemplo do visto anteriormente: a regressão linear dos preços de imóveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(tamanha em 1000 de pés quadrados)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)       #(preço em 1000s de dólares)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Pontos de Dados\")\n",
    "ax.legend( fontsize='xx-large')\n",
    "ax.set_ylabel('Preço (em 1000s de dólares)', fontsize='xx-large')\n",
    "ax.set_xlabel('Tamanho (1000 sqft)', fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regressão/Linear\n",
    "A função implementada por um neurônio sem ativação é a regressão linear vista anteriormente:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = \\mathbf{w}\\cdot x^{(i)} + b \\tag{1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir uma camada com um neurônio ou unidade e compará-la com a conhecida função de regressão linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos examinar os pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há pesos, pois os pesos ainda não foram instanciados. Vamos testar o modelo em um exemplo em `X_train`. Isso acionará a instanciação dos pesos. Observe que a entrada para a camada deve ser 2-D, portanto, vamos reformulá-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é um tensor (outro nome para uma matriz) com uma forma de (1,1) ou uma entrada.   \n",
    "Agora vamos dar uma olhada nos pesos e no bias . Esses pesos são inicializados aleatoriamente com números pequenos e o bias tem como padrão ser inicializada com zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b= linear_layer.get_weights()\n",
    "print(f\"w = {w}, b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo de regressão linear (1) com um único recurso de entrada terá um único peso e bias. Isso corresponde às dimensões da nossa `linear_layer` acima.   \n",
    "\n",
    "Os pesos são inicializados com valores aleatórios, portanto, vamos defini-los com alguns valores conhecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "\n",
    "# set_weights usa uma lista de matrizes numéricas\n",
    "linear_layer.set_weights([set_w, set_b])\n",
    "print(linear_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar a equação (1) com a saída da camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "alin = np.dot(set_w,X_train[0].reshape(1,1)) + set_b\n",
    "print(alin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eles produzem os mesmos valores!\n",
    "Agora, podemos usar nossa camada linear para fazer previsões em nossos dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tf = linear_layer(X_train)\n",
    "prediction_np = np.dot( X_train, set_w) + set_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_linear(X_train, Y_train, prediction_tf, prediction_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurônio com ativação Sigmoid\n",
    "A função implementada por um neurônio/unidade com uma ativação sigmoide é a mesma da regressão logística:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
    "onde $$g(x) = sigmoid(x)$$ \n",
    "\n",
    "Vamos definir $w$ e $b$ para alguns valores conhecidos e verificar o modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conjunto de Dados\n",
    "Usaremos agora um exemplo de regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # Matriz 2-D\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # Matriz 2-D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "X_train[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
    "              edgecolors=dlc[\"dlblue\"],lw=3)\n",
    "\n",
    "ax.set_ylim(-0.08,1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('gráfico de uma variável')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurônio Logístico\n",
    "Podemos implementar um \"neurônio logístico\" adicionando uma ativação sigmoide. A função do neurônio é então descrita por (2) acima.   \n",
    "Esta seção criará um modelo do Tensorflow que contém nossa camada logística para demonstrar um método alternativo de criação de modelos. O Tensorflow é usado com mais frequência para criar modelos de várias camadas. O modelo [Sequential] (https://keras.io/guides/sequential_model/) é um meio conveniente de construir esses modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, input_dim=1,  activation = 'sigmoid', name='L1')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `model.summary()` mostra as camadas e o número de parâmetros no modelo. Há apenas uma camada nesse modelo e essa camada tem apenas uma unidade. A unidade tem dois parâmetros, $w$ e $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_layer = model.get_layer('L1')\n",
    "w,b = logistic_layer.get_weights()\n",
    "print(w,b)\n",
    "print(w.shape,b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir o peso e a polarização para alguns valores conhecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "# set_weights usa uma lista de numpy arrays\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar a equação (2) com a saída da camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = model.predict(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "alog = sigmoidnp(np.dot(set_w,X_train[0].reshape(1,1)) + set_b)\n",
    "print(alog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eles produzem os mesmos valores!\n",
    "Agora, podemos usar nossa camada logística e o modelo NumPy para fazer previsões em nossos dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_logistic(X_train, Y_train, model, set_w, set_b, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sombreamento acima reflete a saída do sigmoide, que varia de 0 a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns!\n",
    "Você criou uma rede neural muito simples e explorou as semelhanças de um neurônio com a regressão linear e logística."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
