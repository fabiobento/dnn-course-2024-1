{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_01/Laborat%C3%B3rios/lab_utils_ml_adv_week_1.zip\n",
    "      \n",
    "!unzip -n -q lab_utils_ml_adv_week_1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Rede Neural Simples com Numpy\n",
    "Neste laboratório, criaremos uma pequena rede neural usando o Numpy. Será a mesma rede de \"torrefação de café\" que você implementou no Tensorflow.\n",
    "   <center> <img  src=\"./images/C2_W1_CoffeeRoasting.png\" width=\"400\" />   <center/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from lab_utils_common import dlc, sigmoid\n",
    "from lab_coffee_utils import load_coffee_data, plt_roast, plt_prob, plt_layer, plt_network, plt_output_unit\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Dados\n",
    "Este é o mesmo conjunto de dados do laboratório anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_coffee_data();\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar os dados de torrefação de café abaixo. Os dois recursos são Temperatura em Celsius e Duração em minutos. A [Coffee Roasting at Home](https://www.merchantsofgreencoffee.com/how-to-roast-green-coffee-in-your-oven/) sugere que a duração deve ser mantida entre 12 e 15 minutos, enquanto a temperatura deve estar entre 175 e 260 graus Celsius. É claro que, à medida que a temperatura aumenta, a duração deve diminuir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_roast(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar dados\n",
    "Para corresponder ao laboratório anterior, normalizaremos os dados. Consulte o laboratório anterior para obter mais detalhes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temperature Máxima, Min antes da normalização: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min antes da normalização: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min após a normalização: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min após a normalização: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Numpy - Propagação direta(_Forward Propagation_) no NumPy\n",
    "<center> <img  src=\"./images/C2_W1_RoastingNetwork.PNG\" width=\"200\" />   <center/>  \n",
    "Vamos criar a \"Rede de torrefação de café\" descrita na aula. Há duas camadas com ativações sigmoides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Conforme descrito na aula, é possível criar sua própria camada densa usando o NumPy. Isso pode ser utilizado para criar uma rede neural de várias camadas.\n",
    "\n",
    "<img src=\"images/C2_W1_dense3.png\" width=\"600\" height=\"450\">\n",
    "\n",
    "No primeiro laboratório você construiu um neurônio no NumPy e no Tensorflow e observou a semelhança entre eles. Uma camada simplesmente contém vários neurônios/unidades. Conforme descrito na aula, é possível utilizar um loop for para visitar cada unidade (`j`) na camada e executar o produto escalar dos pesos dessa unidade (`W[:,j]`) e somar o viés  da unidade (`b[j]`) para formar `z`. Uma função de ativação `g(z)` pode então ser aplicada a esse resultado. Vamos tentar isso abaixo para criar uma sub-rotina de \"camada densa\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, você definirá a função de ativação `g()`. Você usará a função `sigmoid()` que já está implementada para você no arquivo `lab_utils_common.py` fora deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de ativação\n",
    "g = sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você definirá a função `my_dense()` que calcula as ativações de uma camada densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b):\n",
    "    \"\"\"\n",
    "    Calcula a camada densa\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Dados, 1 exemplo\n",
    "      W    (ndarray (n,j)) : Matriz de peso, n recursos por unidade, j unidades\n",
    "      b    (ndarray (j, )) : vetor de bias, j unidades\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j unidades|\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):               \n",
    "        w = W[:,j]                                    \n",
    "        z = np.dot(w, a_in) + b[j]         \n",
    "        a_out[j] = g(z)               \n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação: você também pode implementar a função acima para aceitar `g` como um parâmetro adicional (por exemplo, `my_dense(a_in, W, b, g)`). No entanto, neste notebook, você usará apenas um tipo de função de ativação (ou seja, sigmoide), portanto, não há problema em torná-la constante e defini-la fora da função. Foi o que você fez no código acima e isso simplifica as chamadas de função nas próximas células de código. Lembre-se de que passá-lo como um parâmetro também é uma implementação aceitável. Você verá isso na tarefa desta semana.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula a seguir cria uma rede neural de duas camadas utilizando a sub-rotina `my_dense` acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1)\n",
    "    a2 = my_dense(a1, W2, b2)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos copiar os pesos e os vieses treinados no laboratório anterior no Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predições\n",
    "<img align=\"left\" src=\"./images/C2_W1_RoastingDecision.PNG\"     style=\" width:380px; padding: 10px 20px; \" >\n",
    "\n",
    "Quando você tiver um modelo treinado, poderá usá-lo para fazer previsões. Lembre-se de que o resultado do nosso modelo é uma probabilidade. Nesse caso, a probabilidade de uma boa torrefação. Para tomar uma decisão, é preciso aplicar a probabilidade a um limiar. Nesse caso, usaremos 0,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar escrevendo uma rotina semelhante ao `model.predict()` do Tensorflow. Isso pegará uma matriz $X$ com todos os $m$ exemplos nas linhas e fará uma previsão executando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar essa rotina em dois exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # exemplo positivo\n",
    "    [200,17]])   # exemplo negativo\n",
    "X_tstn = norm_l(X_tst)  # lembre-se de normalizar\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para converter as probabilidades em uma decisão, aplicamos um limiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso pode ser feito de forma mais sucinta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse gráfico mostra a operação de toda a rede e é idêntico ao resultado do Tensorflow do laboratório anterior.\n",
    "O gráfico à esquerda é a saída bruta da camada final representada pelo sombreamento azul. Ela é sobreposta aos dados de treinamento representados pelos Xs e Os.   \n",
    "O gráfico da direita é a saída da rede após um limiar de decisão. Os Xs e Os aqui correspondem às decisões tomadas pela rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netf= lambda x : my_predict(norm_l(x),W1_tmp, b1_tmp, W2_tmp, b2_tmp)\n",
    "plt_network(X,Y,netf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parabéns!\n",
    "Você criou uma pequena rede neural no NumPy. \n",
    "Espero que este laboratório tenha revelado as funções bastante simples e familiares que compõem uma camada em uma rede neural."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
