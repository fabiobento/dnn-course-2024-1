Atualmente, os álbuns de aprendizado de máquina estão afetando bilhões de pessoas. Você já me ouviu mencionar ética em outros vídeos antes. E espero que, se você está construindo um sistema de aprendizado de máquina que afeta as pessoas, pense um pouco em garantir que seu sistema seja razoavelmente justo, razoavelmente livre de preconceitos. E que você está adotando uma abordagem ética para sua aplicação. Vamos dar uma olhada em algumas questões relacionadas à justiça, preconceito e ética. Infelizmente, na história do aprendizado de máquina, alguns sistemas, alguns amplamente divulgados, acabaram apresentando um nível de preconceito completamente inaceitável. Por exemplo, houve uma contratação de duas pessoas que uma vez demonstrou discriminar mulheres. A empresa que construiu o sistema parou de usá-lo, mas desejamos que o sistema nunca tivesse sido lançado em primeiro lugar. Ou também havia exemplos bem documentados de sistemas de reconhecimento facial que combinam indivíduos de pele escura com fotos de criminosos com muito mais frequência do que indivíduos de pele mais clara. E, claramente, isso não é aceitável e deveríamos. Sim, é aí que a comunidade simplesmente não constrói e implanta sistemas com um problema como esse. Em primeiro lugar, existem sistemas que concederam aprovações de empréstimos bancários de uma forma tendenciosa e discriminatória contra subgrupos. E também gostamos muito de aprender algoritmos para não ter o efeito tóxico de reforçar estereótipos negativos. Por exemplo, eu tenho uma filha e se ela pesquisar certas profissões on-line e não vê ninguém que se pareça com ela, eu odiaria que isso a desencorajasse de assumir certas profissões. Além das questões de preconceito e tratamento justo dos indivíduos, também houve casos de uso adverso ou casos de uso negativo de algoritmos de aprendizado de máquina. Por exemplo, houve um lançamento de vídeo amplamente citado e amplamente visto com divulgação total e transparência total. Pela empresa buzzfeed de um deepfake do ex-presidente dos EUA, Barack Obama, você pode realmente encontrar e assistir o vídeo inteiro on-line, se quiser. Mas a empresa que criou este vídeo fez isso com total transparência e divulgação total. Mas, claramente, usar essa tecnologia para gerar vídeos falsos sem consentimento e sem divulgação seria antiético. Infelizmente, também vimos as mídias sociais espalharem discursos tóxicos ou incendiários porque a otimização do engajamento do usuário fez com que algoritmos fizessem isso. Existem barcos que foram usados para gerar conteúdo falso para fins comerciais, como postar comentários falsos em produtos, ou para fins políticos. E há usuários de aprendizado de máquina para criar produtos nocivos, cometer fraudes e assim por diante. E em partes do mundo do aprendizado de máquina, assim como um e-mail, houve uma batalha entre os spammers e a comunidade anti-spam. Estou vendo hoje, por exemplo, no setor financeiro, uma batalha entre pessoas que tentam cometer fraudes e pessoas que combatem fraudes. E, infelizmente, o aprendizado de máquina é usado por alguns dos fraudadores e por alguns dos padrões. Então, pelo amor de Deus, por favor, não construa um sistema de aprendizado de máquina que tenha um impacto negativo na sociedade. E se você for convidado a trabalhar em um aplicativo que considera antiético, recomendo que você se afaste pelo que vale. Várias vezes eu analisei o projeto que parecia ser financeiramente sólido. Você ganhará dinheiro para alguma empresa. Mas eu acabei com o projeto apenas por motivos éticos porque acho que, embora o argumento financeiro soe, senti que isso piora a situação do mundo e simplesmente não quero nunca me envolver em um projeto como esse.
Reproduza o vídeo começando em :4:11 e siga a transcrição4:11
A ética é um assunto muito complicado e muito rico que a humanidade estudou por pelo menos alguns 1000 anos. Quando a IA se tornou mais difundida, na verdade li vários livros sobre filosofia e vários livros sobre ética porque esperava ingenuamente que surgisse uma lista de cinco coisas que poderíamos fazer e, ao fazer essas cinco coisas, poderíamos ser éticos, mas eu falhei. E acho que ninguém jamais conseguiu criar uma lista simples de coisas a fazer para dar esse nível de orientação concreta sobre como ser ético. Então, o que espero compartilhar com vocês não é uma lista de verificação, porque eu nem mesmo criei uma com apenas algumas orientações gerais e algumas sugestões de como garantir que o trabalho seja menos tendencioso, mais justo e mais ético. E espero que algumas dessas orientações, algumas que seriam relativamente gerais, também o ajudem em seu trabalho. Então, aqui estão algumas sugestões para tornar seu trabalho mais justo, menos tendencioso e mais ético antes de implantar um sistema que poderia causar danos. Normalmente, tento reunir uma equipe diversificada para debater possíveis coisas que podem dar errado, com ênfase em possíveis danos. Dois grupos vulneráveis que descobri muitas vezes em minha vida: ter uma equipe mais diversificada e, por diversa, quero dizer, diversidade em várias dimensões, desde gênero até etnia, cultura e muitas outras características. Descobri que ter equipes mais diversificadas, na verdade, faz com que uma equipe coletivamente seja melhor em
Reproduza o vídeo começando em :6: e siga a transcrição6:00
ter ideias sobre coisas que podem dar errado e aumenta as chances de reconhecer o problema e resolvê-lo antes de implantar o sistema e causar danos a algum grupo em particular. Além de ter uma diversidade e realizar um brain storming. Também achei útil realizar uma pesquisa bibliográfica sobre quaisquer padrões ou diretrizes para seu setor ou área de aplicação específica, por exemplo, no setor financeiro, estão começando a ser estabelecidos padrões para o que significa ser um sistema. Então, eles querem que isso decida quem aprovar esses dois, o que significa para um sistema como esse ser razoavelmente justo e livre de preconceitos e os padrões que ainda estão surgindo em diferentes setores podem informar seu trabalho, dependendo do que você está trabalhando. Depois de identificar possíveis problemas. Achei útil então auditar o sistema em relação às dimensões identificadas de uma possível casa. Antes da implantação, você viu no último vídeo o ciclo completo do projeto de aprendizado de máquina. E uma etapa fundamental que geralmente é uma linha crucial de defesa contra a implantação de algo problemático é depois de treinar o modelo. Mas antes de você entrar na produção, se a equipe tiver feito um brainstorming, isso pode ser tendencioso em relação a certos subgrupos, como certos gêneros ou certas etnias. Em seguida, você pode solicitar que o sistema meça o desempenho para ver se realmente é preconceituoso contra certos gêneros, etnias ou outros subgrupos e para garantir que quaisquer problemas sejam identificados e corrigidos. Antes da implantação. Finalmente, achei útil desenvolver um plano de mitigação, se aplicável. E um plano simples de mitigação seria reverter para o sistema anterior que sabíamos ser razoavelmente justo. E, mesmo após a implantação, continue monitorando os danos para que você possa acionar um plano de mitigação e agir rapidamente caso haja um problema que precise ser resolvido. Por exemplo, todas as equipes de carros autônomos, antes de lançar carros autônomos na estrada, desenvolveram planos de mitigação sobre o que fazer no caso de o carro se envolver em um acidente, de modo que, se o carro sofresse um acidente, já existisse um plano de mitigação que eles poderiam executar imediatamente, em vez de um carro sofrer um acidente e, em seguida, apenas correr atrás do fato para descobrir o que fazer. Eu trabalhei em muitos sistemas de aprendizado de máquina e deixe-me falar sobre questões de ética, justiça e preconceito que devemos levar a sério. Não é algo para ignorar. Não é algo que se considere provável. Agora, é claro, existem alguns projetos com implicações éticas mais sérias do que outros. Por exemplo, se estou construindo uma rede neural para decidir por quanto tempo torrar meus grãos de café, claramente, as implicações éticas disso parecem significativamente menores do que se, digamos, você estivesse construindo um sistema para decidir quais empréstimos. Empréstimos bancários são aprovados e, se forem compradores, podem causar danos significativos. Mas espero que todos nós, trabalhando coletivamente em aprendizado de máquina, possamos continuar debatendo melhor essas questões. Identifique problemas, corrija-os antes que causem danos para que possamos, coletivamente, evitar alguns dos erros que o mundo do aprendizado de máquina cometeu antes, porque essas coisas são importantes e os sistemas que criamos podem afetar muitas pessoas. E pronto, vamos ao processo de desenvolvimento de um sistema de aprendizado de máquina e parabéns por ter chegado ao final dos vídeos obrigatórios desta semana. Tenho apenas mais dois vídeos opcionais esta semana para você sobre como lidar com conjuntos de dados distorcidos, o que significa que Steve diz que a proporção de exemplos positivos e negativos está muito longe de 50, 50. E acontece que algumas técnicas especiais são necessárias para lidar com aplicativos de aprendizado de máquina como esse. Então, espero ver você no próximo vídeo (vídeo opcional) sobre como lidar com conjuntos de dados distorcidos.
