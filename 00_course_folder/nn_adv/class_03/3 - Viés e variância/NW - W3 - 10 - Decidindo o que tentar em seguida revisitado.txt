Você viu como, observando J train e Jcv, esse é o erro de treinamento e o erro de validação cruzada, ou talvez até mesmo traçando uma curva de aprendizado. Você pode tentar ter uma ideia se seu algoritmo de aprendizado tem alto viés ou alta variância. Esse é o procedimento que eu faço rotineiramente quando estou treinando um algoritmo de aprendizado. Examine com mais frequência o erro de treinamento e o erro de validação cruzada para tentar decidir se meu algoritmo tem alto viés ou alta variância. Acontece que isso ajudará você a tomar melhores decisões sobre o que tentar a seguir para melhorar o desempenho do seu algoritmo de aprendizado. Vamos dar uma olhada em um exemplo. Na verdade, este é o exemplo que você viu anteriormente. Se você implementou a regressão linear regularizada na previsão dos preços da habitação, mas seu algoritmo mistura no conjunto três grandes erros desde as previsões, o que você deve tentar a seguir? Essas foram as seis ideias que tivemos quando examinamos este slide anteriormente. Para obter mais exemplos de treinamento, experimente um pequeno conjunto de recursos , recursos adicionais e assim por diante. Acontece que cada um desses seis itens ajuda a corrigir um problema de alta variância ou de alto viés. Em particular, se seu algoritmo de aprendizado tiver um alto viés, três dessas técnicas serão úteis. Se o seu algoritmo de aprendizado tiver uma alta variação, três dessas técnicas diferentes serão úteis. Vamos ver se conseguimos descobrir qual é qual. O primeiro é obter mais exemplos de treinamento. Vimos no último vídeo que, se seu algoritmo tem um viés alto , se a única coisa que fazemos é obter mais dados de treinamento, isso por si só provavelmente não ajudará muito. Mas, por outro lado, se seu algoritmo tiver uma alta variância, digamos que ele esteja se ajustando demais a um conjunto de treinamento muito pequeno , obter mais exemplos de treinamento ajudará muito. Essa primeira opção ou obter mais exemplos de treinamento ajuda a corrigir um problema de alta variância. Que tal os outros cinco? Você acha que pode descobrir quais dos cinco restantes corrigem problemas de alto viés ou alta variância? Eu vou ver o resto deles neste vídeo em um minuto, mas se você quiser, você pode pausar o vídeo e ver se consegue pensar nessas outras cinco coisas sozinho. Sinta-se à vontade para pausar o vídeo. Brincadeira, fui eu fazendo uma pausa e não seu vídeo. Mas, falando sério, se você quiser, pause o vídeo e pense no que você quer ou não, e analisaremos essas análises em um minuto. Que tal experimentar um conjunto menor de recursos? Às vezes, se seu algoritmo de aprendizado tem muitos recursos , ele oferece flexibilidade demais para caber em modelos muito complicados. É um pouco como se você tivesse x, x ao quadrado, x ao cubo, x^4, x^5 e assim por diante. Se você eliminasse apenas alguns deles, seu modelo não será tão complexo e não terá uma variação tão alta. Se você suspeitar que seu algoritmo tem muitos recursos que não são realmente relevantes ou úteis para prever o preço da habitação, ou se você suspeitar que tinha recursos um tanto redundantes , eliminar ou reduzir o número de recursos ajudará a reduzir a flexibilidade do seu algoritmo para sobrecarregar os dados. Essa é uma tática que o ajudará a corrigir a alta variação. Conversar, obter recursos adicionais, ou seja, apenas adicionar recursos adicionais, é o oposto de usar um conjunto menor de recursos. Isso ajudará você a corrigir um problema de alto viés. Como um exemplo concreto, se você está tentando prever o preço da casa apenas com base no tamanho, mas acontece que o preço da casa também depende realmente do número de quartos, do número de andares e da idade da casa, o algoritmo nunca funcionará bem, a menos que você adicione esses recursos adicionais. Esse é um problema de alto viés, porque você simplesmente não consegue se sair bem no conjunto de treinamento quando apenas o tamanho é quando você diz ao algoritmo quantos quartos existem, quantos andares existem? Qual é a idade da casa para que ela finalmente tenha informações suficientes para se sair ainda melhor no conjunto de treinamento. Adicionar recursos adicionais é uma forma de corrigir um problema de alto viés. Adicionar recursos polinomiais é um pouco como adicionar recursos adicionais. Se você usa funções lineares, três linhas podem se ajustar muito bem ao conjunto de treinamento, então adicionar recursos polinomiais adicionais pode ajudá-lo a se sair melhor no conjunto de treinamento, e ajudá-lo a se sair melhor no conjunto de treinamento é uma forma de corrigir um problema de alto viés. Então, diminuir o Lambda significa usar um valor menor para o parâmetro de regularização. Isso significa que vamos prestar menos atenção a esse termo e prestar mais atenção a esse termo para tentar melhorar o conjunto de treinamento. Novamente, isso ajuda você a resolver um problema de alto viés. Finalmente, aumentar o Lambda, bem, isso é o oposto disso, mas isso significa que você está superajustando os dados.
Reproduza o vídeo começando em :5:14 e siga a transcrição5:14
Aumentar o Lambda fará sentido se for sobreajustar o conjunto de treinamento, apenas dando muita atenção ao ajuste do conjunto de treinamento, mas às custas de generalizar para novos exemplos, portanto, aumentar o Lambda forçaria o algoritmo a ajustar uma função mais suave, pode ser uma função menos instável e usá-la para corrigir um problema de alta variância. Percebi que havia muita coisa nesse slide. Mas espero que você saiba que, se você achar que seu algoritmo tem alta variância, as duas principais maneiras de corrigir isso são: não obter mais dados de treinamento nem simplificar seu modelo. Ao simplificar o modelo, quero dizer, obter um conjunto menor de recursos ou aumentar o parâmetro de regularização Lambda. Seu algoritmo tem menos flexibilidade para se ajustar a curvas muito complexas e muito onduladas. Por outro lado, se seu algoritmo tem um viés alto , isso significa que não está indo bem nem mesmo no conjunto de treinamento. Se for esse o caso, as principais correções são tornar seu modelo mais poderoso ou dar a ele mais flexibilidade para caber em funções mais complexas ou mais compatíveis comigo. Algumas maneiras de fazer isso são fornecer recursos adicionais ou adicionar esses recursos polinomiais ou diminuir o parâmetro de regularização Lambda. De qualquer forma, caso você esteja se perguntando se deveria corrigir o alto viés reduzindo o tamanho do conjunto de treinamento, isso realmente não ajuda. Se você reduzir o tamanho do conjunto de treinamento, você se ajustará melhor ao conjunto de treinamento, mas isso tende a piorar o erro de validação cruzada e o desempenho do seu algoritmo de aprendizado, portanto, não jogue fora aleatoriamente exemplos de treinamento apenas para tentar corrigir um problema de alto viés. Um dos meus alunos de doutorado em Stanford, muitos anos depois de já ter se formado em Stanford, uma vez me disse que, enquanto estudava em Stanford, ele aprendeu sobre preconceitos e variações e sentiu que entendia, entendia. Mas, posteriormente, após muitos anos de experiência profissional em algumas empresas diferentes, ele percebeu que preconceito e variação são um daqueles conceitos que levam pouco tempo para serem aprendidos, mas levam uma vida inteira para serem dominados. Essas foram suas palavras exatas. Preconceito e variação são uma dessas ideias muito poderosas. Quando estou treinando algoritmos de aprendizado, quase sempre tento descobrir se é um alto viés ou uma alta variância. Mas a maneira como você aborda isso sistematicamente é algo em que você continuará melhorando por meio de práticas repetidas. Mas você descobrirá que entender essas ideias o ajudará a ser muito mais eficaz na forma como você decide o que tentar a seguir ao desenvolver um algoritmo de aprendizado. Agora, eu sei que passamos por muita coisa neste vídeo e se você acha que, cara, isso não é coisa perdida aqui, tudo bem, não se preocupe. No final desta semana, nos laboratórios práticos e nos questionários práticos, também haverá oportunidades adicionais de analisar essas ideias para que você possa praticar mais. Estamos pensando no viés e na variação de diferentes algoritmos de aprendizado. Se parece que muita coisa agora está bem, você poderá praticar essas ideias ainda esta semana e, com sorte, ter aprofundado sua compreensão delas naquela época. Antes de prosseguir, o viés e a variância também são muito úteis quando se pensa em como treinar uma rede neural. No próximo vídeo, vamos dar uma olhada nesses conceitos aplicados ao treinamento de redes neurais. Vamos para o próximo vídeo.
