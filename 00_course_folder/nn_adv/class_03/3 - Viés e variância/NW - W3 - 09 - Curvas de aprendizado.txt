As curvas de aprendizado são uma forma de ajudar a entender o desempenho do seu algoritmo de aprendizado em função da quantidade de experiência que ele tem, ou seja, a experiência, quero dizer, por exemplo, o número de exemplos de treinamento que ele tem. Vamos dar uma olhada. Deixe-me traçar as curvas de aprendizado para um modelo que se ajusta a uma função quadrática polinomial de segunda ordem da seguinte forma. Vou traçar tanto J_CV, o erro de validação cruzada, quanto J_train, o erro de treinamento. Nesta figura, o eixo horizontal será m_train. Esse é o tamanho do conjunto de treinamento ou o número de exemplos com os quais o algoritmo pode aprender. No eixo vertical, vou traçar o erro. Por erro, quero dizer J_CV ou J_train. Vamos começar traçando o erro de validação cruzada. Vai ficar mais ou menos assim. Essa é a aparência de J_cv de (w, b). Talvez não seja surpresa que, com m_train, o tamanho do conjunto de treinamento aumente, você aprenda um modelo melhor e, portanto, o erro de validação cruzada diminua. Agora, vamos traçar J_train de (w, b) da aparência do erro de treinamento à medida que o tamanho do conjunto de treinamento aumenta. Acontece que o erro de treinamento, na verdade, ficará assim. Quando o tamanho do conjunto de treinamento aumenta, o erro do conjunto de treinamento realmente aumenta. Vamos dar uma olhada em por que esse é o caso. Começaremos com um exemplo de quando você tem apenas um único exemplo de treinamento. Bem, se você ajustar um modelo quadrático a isso, poderá ajustar a linha reta ou curva mais fácil e seu erro de treinamento será zero. Que tal se você tivesse dois exemplos de treinamento como esse? Bem, você pode novamente ajustar uma linha reta e obter zero erro de treinamento. Na verdade, se você tiver três exemplos de treinamento, a função quadrática ainda pode se encaixar muito bem e ter praticamente zero erro de treinamento, mas agora, se seu conjunto de treinamento ficar um pouco maior, digamos que você tenha quatro exemplos de treinamento , fica um pouco mais difícil encaixar perfeitamente todos os quatro exemplos. Você pode ter uma curva parecida com esta, é muito boa, mas você está um pouco errada em alguns lugares aqui e ali. Quando você tem inscrições, o tamanho do conjunto de treinamento para quatro, o erro de treinamento na verdade aumenta um pouco. Que tal termos cinco exemplos de treinamento. Bem, novamente, você pode encaixá-lo muito bem, mas fica ainda mais difícil encaixar todos eles perfeitamente. Não temos conjuntos de sombreamento ainda maiores; fica cada vez mais difícil ajustar perfeitamente cada um dos seus exemplos de treinamento. Recapitulando, quando você tem um número muito pequeno de exemplos de treinamento, como um, dois ou até três, é relativamente fácil obter zero ou muito pequeno erro de treinamento, mas quando você tem um conjunto de treinamento maior, é mais difícil para a função quadrática se encaixar perfeitamente em todos os exemplos de treinamento. É por isso que, à medida que o conjunto de treinamento aumenta, o erro de treinamento aumenta porque é mais difícil ajustar perfeitamente todos os exemplos de treinamento. Observe outra coisa sobre essas curvas, que é o erro de validação cruzada, que normalmente será maior do que o erro de treinamento porque você ajusta os parâmetros ao conjunto de treinamento. Você espera se sair pelo menos um pouco melhor ou quando m é pequeno, talvez até muito melhor no conjunto de treinamento do que no conjunto de validação trans. Vamos agora dar uma olhada em como serão as curvas de aprendizado para uma média com alto viés versus uma com alta variância. Vamos começar com o caso de alto viés ou de falta de ajuste. Lembre-se de que um exemplo de alto viés seria se você estivesse ajustando uma função linear, então uma curva parecida com esta. Se você representar graficamente o erro de treinamento, o erro de treinamento aumentará conforme o esperado. Na verdade, essa curva de erro de treinamento pode começar a se achatar. Nós o chamamos de platô, o que significa achatar depois de um tempo. Isso porque, à medida que você obtém mais e mais exemplos de treinamento ao ajustar a função linear simples, seu modelo não muda muito mais. É uma linha reta e, mesmo que você obtenha mais e mais exemplos, simplesmente não há muito mais a mudar, e é por isso que o erro médio de treinamento diminui depois de um tempo. Da mesma forma, seu erro de validação cruzada diminuirá e também diminuirá depois de um tempo, e é por isso que J_CV novamente é maior do que J_train, mas J_CV tenderá a ter essa aparência. É porque, seja honesto, seus pontos finais, mesmo que você receba mais e mais exemplos, não mudará muita coisa na rua agora que você está se adaptando. É um modelo muito simples para caber em tantos dados. É por isso que essas duas curvas, J_cv e J_train, tendem a se achatar depois de um tempo. Se você tivesse uma medida desse nível básico de desempenho, como desempenho em nível humano, eles tenderiam a ser um valor menor do que seu J_train e seu J_CV. O desempenho em nível humano pode ser assim. Há uma grande lacuna entre o nível básico de desempenho e o J_train, que foi nosso indicador de que esse algoritmo tinha alto viés. Ou seja, poderíamos esperar estar se saindo muito melhor se pudéssemos ajustar uma função mais complexa do que apenas uma linha reta. Agora, uma coisa interessante sobre esse enredo é que você pode perguntar: o que você acha que aconteceria se você pudesse ter um conjunto de treinamento muito maior? Como seria se pudéssemos aumentar ainda mais do que a direita desse gráfico, você pode ir mais para a direita da seguinte maneira? Bem, você pode imaginar que se estendesse essas duas curvas para a direita, ambas se achatariam e provavelmente continuariam planas desse jeito. Não importa o quanto você se estenda à direita desse gráfico, dessas duas curvas, elas nunca encontrarão uma maneira de cair até esse desempenho de nível humano ou simplesmente permanecerem planas assim, praticamente para sempre, não importa o tamanho do conjunto de treinamento. Isso dá a conclusão, talvez um pouco surpreendente, de que, se um algoritmo de aprendizado tem alto viés, obter mais dados de treinamento, por si só, não é uma esperança muito grande. Sei que estamos acostumados a pensar que ter mais dados é bom, mas se seu algoritmo tem alto viés , se a única coisa que você faz é adicionar mais dados de treinamento, isso por si só nunca permitirá que você reduza tanto a taxa de erro. É por isso que, na verdade, não importa quantos exemplos você adicione a essa figura, o ajuste linear reto simplesmente não vai ficar muito melhor. É por isso que, antes de investir muito esforço na coleta de mais dados de treinamento, vale a pena verificar se seu algoritmo de aprendizado tem um alto viés, porque, se isso acontecer, você provavelmente precisará fazer outras coisas além de adicionar mais dados de treinamento. Vamos agora dar uma olhada em como é a curva de aprendizado para algoritmos de aprendizado com alta variância.
Reproduza o vídeo começando em :7:25 e siga a transcrição7:25
Você deve se lembrar de que, se ajustasse o polinômio anterior com lambda pequeno, digamos, ou mesmo lambda igual a zero, obteria uma curva parecida com essa e, embora ela se ajuste muito bem aos dados de treinamento, ela não generaliza. Vamos agora ver como seria uma curva de aprendizado nesse cenário de alta variação. O trem J aumentará à medida que o tamanho do conjunto de treinamento aumentar, então você obtém uma curva parecida com essa, e o J cv será muito maior, então seu erro de validação cruzada é muito maior do que seu erro de treinamento. O fato de haver uma grande lacuna aqui é o que posso dizer que essa alta variância está se saindo muito melhor no conjunto de treinamento do que no seu conjunto de validação cruzada. Se você fosse traçar um nível básico de desempenho, como desempenho em nível humano, você poderia descobrir que está aqui, que o treinamento J às vezes pode ser ainda menor do que o desempenho de nível humano ou talvez o desempenho em nível humano seja um pouco menor do que isso. Mas quando você está ajustando demais o conjunto de treinamento, você pode se ajustar tão bem ao conjunto de treinamento a ponto de ter um erro irrealisticamente baixo, como erro zero neste exemplo aqui, o que é realmente melhor do que o quão bem os humanos realmente serão capazes de prever os preços da habitação ou qualquer outro aplicativo em que você esteja trabalhando. Mas, novamente, sinalizar uma alta variação é se J cv é muito maior do que o trem J. Quando você tem alta variância , aumentar o tamanho do conjunto de treinamento pode ajudar muito e, em particular, se pudéssemos extrapolar essas curvas para a direita, aumentar o trem M, o erro de treinamento continuará aumentando, mas o erro de validação cruzada, esperançosamente, diminuirá e se aproximará do trem J. Portanto, nesse cenário, pode ser possível aumentar o tamanho do conjunto de treinamento para diminuir o erro de validação cruzada e fazer com que seu algoritmo tenha um desempenho cada vez melhor, e isso é diferente do caso de alto viés, em que se a única coisa que você faz é obter mais dados de treinamento, isso não o ajudará a aprender muito o desempenho do algoritmo. Resumindo, se um algoritmo de aprendizado sofre de alta variância, é provável que obter mais dados de treinamento ajude. Porque extrapolando para a direita dessa curva, você vê que pode esperar que J cv continue descendo. Neste exemplo, o simples fato de obter mais dados de treinamento permite que o algoritmo passe de um erro de validação cruzada relativamente alto para se aproximar muito do desempenho em nível humano. Você pode ver que, se adicionasse muito mais exemplos de treinamento e continuasse preenchendo o polinômio de quarta ordem, você poderia simplesmente obter um melhor ajuste polinomial de quarta ordem a esses dados do que apenas uma curva muito fraca para cima. Se você estiver construindo um aplicativo de aprendizado de máquina, pode traçar as curvas de aprendizado se quiser, ou seja, pode pegar diferentes subconjuntos de seus conjuntos de treinamento e, mesmo que tenha, digamos, 1.000 exemplos de treinamento, treinar um modelo em apenas 100 exemplos de treinamento e analisar o erro de treinamento e o erro de validação cruzada e, em seguida, treiná-los em 200 exemplos, mantendo 800 exemplos e simplesmente não os usando por enquanto, e traçar J train e J cv e assim por diante, repita e trace a aparência da curva de aprendizado. Se fôssemos visualizá-la dessa forma , essa poderia ser outra maneira de você ver se sua curva de aprendizado se parece mais com um viés alto ou com uma alta variância.
Reproduza o vídeo começando em :11: e siga a transcrição11:00
Uma desvantagem de traçar curvas de aprendizado como essa é algo que eu fiz, mas uma desvantagem é que é computacionalmente muito caro treinar tantos modelos diferentes usando subconjuntos de tamanhos diferentes do seu conjunto de treinamento, então, na prática, isso não é feito com muita frequência, mas mesmo assim, acho que ter essa imagem mental visual da aparência do conjunto de treinamento às vezes me ajuda a pensar no que acho que estou aprendendo o algoritmo está funcionando e se tem alto viés ou alta variância. Sei que já falamos muito sobre preconceito e variação. Vamos voltar ao nosso exemplo anterior de, se você treinou um modelo para previsão de preços de imóveis, como o viés e a variação ajudam você a decidir o que fazer a seguir? Vamos voltar ao exemplo anterior, que espero que agora faça muito mais sentido para você. Vamos fazer isso no próximo vídeo.
