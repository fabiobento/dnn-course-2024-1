Você viu no último vídeo como diferentes escolhas do grau do polinômio D afetam o viés na variância do seu algoritmo de aprendizado e, portanto, seu desempenho geral. Neste vídeo, vamos ver como a regularização, especificamente a escolha do parâmetro de regularização Lambda, afeta o viés e a variância e, portanto, o desempenho geral do algoritmo. Isso, ao que parece, será útil quando você quiser escolher um bom valor de Lambda do parâmetro de regularização para seu algoritmo. Vamos dar uma olhada. Neste exemplo, vou usar um polinômio de quarta ordem, mas vamos ajustar esse modelo usando regularização. Aqui, o valor do Lambda é o parâmetro de regularização que controla o quanto você troca, mantendo os parâmetros pequenos versus ajustando bem os dados de treinamento. Vamos começar com o exemplo de definir o Lambda como um valor muito grande. Digamos que Lambda seja igual a 10.000. Se você fizesse isso, acabaria escolhendo um modelo que se parece mais ou menos com este. Porque se o Lambda fosse muito grande , o algoritmo está altamente motivado para manter esses parâmetros w muito pequenos e, portanto, você acaba com w_1, w_2, na verdade, todos esses parâmetros estarão muito próximos de zero. O modelo acaba sendo f de x é aproximadamente b um valor constante, e é por isso que você acaba com um modelo como este. Esse modelo claramente tem um alto viés e prejudica os dados de treinamento porque nem mesmo funciona bem no conjunto de treinamento e o J_train é grande. Vamos dar uma olhada no outro extremo. Digamos que você definiu o Lambda como um valor muito pequeno. Com um pequeno valor de Lambda, na verdade, vamos ao extremo de definir Lambda como zero.
Reproduza o vídeo começando em :2:11 e siga a transcrição2:11
Com essa opção de Lambda, não há regularização, então estamos apenas ajustando um polinômio de quarta ordem sem regularização e você acaba com a curva que viu anteriormente que se ajusta aos dados. O que vimos anteriormente foi que quando você tem um modelo como esse, o J_train é pequeno, mas o J_CV é muito maior do que o J_train ou o J_CV é grande. Isso indica que temos uma alta variância e isso supera esses dados. Seria se você tivesse algum valor intermediário de Lambda, não muito em grande parte 10.000, mas não tão pequeno quanto zero, que espero obter um modelo parecido com este, que seja perfeito e se encaixe bem nos dados com um pequeno J_train e um pequeno J_cv. Se você está tentando decidir qual é um bom valor do Lambda a ser usado para o parâmetro de regularização, a validação cruzada também oferece uma maneira de fazer isso. Vamos dar uma olhada em como podemos fazer isso. Apenas como um lembrete, o problema que estamos abordando é que se você está ajustando um polinômio de quarta ordem, então esse é o modelo e você está usando a regularização, como você pode escolher um bom valor de Lambda? Esses seriam procedimentos semelhantes aos que você viu para escolher o grau do polinômio D usando validação cruzada. Especificamente, digamos que tentemos ajustar um modelo usando Lambda igual a 0.
Reproduza o vídeo começando em :3:44 e siga a transcrição3:44
Minimizaríamos a função de custo usando Lambda igual a 0 e acabaríamos com alguns parâmetros w1, b1 e você poderia então calcular o erro de validação cruzada, J_cv de w1, b1. Agora vamos testar um valor diferente de Lambda. Digamos que você experimente Lambda igual a 0,01. Por outro lado, minimizar a função de custo fornece um segundo conjunto de parâmetros, w2, b2, e você também pode ver como isso funciona no conjunto de validação cruzada e assim por diante.
Reproduza o vídeo começando em :4:17 e siga a transcrição4:17
Vamos continuar tentando outros valores de Lambda e, neste exemplo, vou tentar duplicá-los para Lambda igual a 0,02 e isso fornecerá J_cv de w3, b3 e assim por diante. Então vamos dobrar novamente e dobrar novamente. Depois de dobrar várias vezes, você acaba com Lambda aproximadamente igual a 10, e isso fornecerá os parâmetros w12, b12 e J_cv w12 de b12. Ao testar uma grande variedade de valores possíveis para o Lambda, ajustar os parâmetros usando esses diferentes parâmetros de regularização e, em seguida, avaliar o desempenho no conjunto de validação cruzada, você pode tentar escolher qual é o melhor valor para o parâmetro de regularização. Rapidamente. Se neste exemplo, você descobrir que J_CV de W5, B5 tem o menor valor de todos esses diferentes erros de validação cruzada, você pode decidir escolher esse valor para Lambda e, assim, usar W5, B5 como parâmetros escolhidos. Finalmente, se você quiser relatar uma estimativa do erro de generalização, você deve relatar o erro do conjunto de testes, testes J de W5, B5. Para aprimorar ainda mais a intuição sobre o que esse algoritmo está fazendo, vamos dar uma olhada em como o erro de treinamento e o erro de validação cruzada variam em função do parâmetro Lambda. Nesta figura, mudei o eixo x novamente.
Reproduza o vídeo começando em :5:51 e siga a transcrição5:51
Observe que o eixo x aqui é anotado com o valor do parâmetro de regularização Lambda, e se observarmos que o extremo de Lambda é igual a zero aqui à esquerda, isso corresponde a não usar nenhuma regularização, e é aí que terminamos com essa curva muito irregular. Se o Lambda fosse pequeno ou mesmo zero, e nesse caso, temos um modelo de alta variância, então o trem J será pequeno e o J_CV será grande porque funciona muito bem nos dados de treinamento, mas se sai muito pior nos dados de validação cruzada. Esse extremo à direita eram valores muito grandes de Lambda. Digamos que Lambda seja igual a 10.000 e acabe com um modelo parecido com esse. Isso tem um alto viés, prejudica os dados e acontece que o trem J estará alto e o J_cv também estará alto. Na verdade, se você observar como o trem J varia em função do Lambda, descobrirá que o trem J aumentará assim porque na função de custo de otimização, quanto maior o Lambda, mais o algoritmo está tentando manter W ao quadrado pequeno. Ou seja, quanto mais peso é dado a esse termo de regularização e, portanto, menos atenção é dada para realmente se sair bem no conjunto de treinamento. Esse termo à esquerda é J train, então quanto mais tenta manter os parâmetros pequenos, menos bom é o trabalho que ele faz para minimizar o erro de treinamento. É por isso que, à medida que o Lambda aumenta, o erro de treinamento J train tende a aumentar dessa forma. Agora, que tal o erro de validação cruzada? Acontece que o erro de validação cruzada ficará assim. Porque vimos que, se o Lambda for muito pequeno ou muito grande, ele não funciona bem no conjunto de validação cruzada. Ou se encaixa demais aqui à esquerda ou se encaixa aqui à direita. Haverá algum valor intermediário do Lambda que fará com que o algoritmo tenha um melhor desempenho. O que a validação cruzada está fazendo é testar vários valores diferentes do Lambda. Isso é o que vimos no último slide; teste Lambda é igual a zero, Lambda é igual a 0,01, lógica é 0,02. Experimente vários valores diferentes do Lambda e avalie o erro de validação cruzada em vários desses pontos diferentes e, em seguida, escolha um valor com baixo erro de validação cruzada, e espero que isso corresponda a um bom modelo para seu aplicativo.
Reproduza o vídeo começando em :8:36 e siga a transcrição8:36
Se você comparar esse diagrama com o que tínhamos no vídeo anterior, onde o eixo horizontal era o grau de polinômio, esses dois diagramas parecem um pouco não matematicamente e não de forma formal, mas parecem um pouco com imagens espelhadas um do outro, e isso porque quando você ajusta um grau de polinômio, a parte esquerda dessa curva correspondia a baixo ajuste e alto viés, a direita a peça correspondeu a sobreajuste e alta variação. Já neste caso, a alta variância estava à esquerda e o alto viés estava à direita. Mas é por isso que essas duas imagens são um pouco como imagens espelhadas uma da outra. Mas em ambos os casos, a validação cruzada e a avaliação de valores diferentes podem ajudar você a escolher um bom valor de t ou um bom valor de Lambda.
Reproduza o vídeo começando em :9:24 e siga a transcrição9:24
É assim que a escolha do parâmetro de regularização Lambda afeta o viés, a variância e o desempenho geral do seu algoritmo, e você também viu como pode usar a validação cruzada para fazer uma boa escolha para o parâmetro de regularização Lambda. Agora, até agora, falamos sobre como ter um alto erro de conjunto de treinamento, alto treinamento J é indicativo de alto viés e como ter um alto erro de validação cruzada de J_CV, especificamente se for muito maior do que o trem J, é indicativo de problema de variância. Mas o que essas palavras “alto” ou “muito mais alto” realmente significam? Vamos dar uma olhada nisso no próximo vídeo, onde veremos como você pode analisar os números J train e J_cv e julgar se estão altos ou baixos, e acontece que um refinamento adicional dessas ideias, ou seja, estabelecer um nível básico de desempenho que estamos aprendendo. O algoritmo tornará muito mais fácil para você analisar esses números, treinar J, J_CV e julgar se eles são altos ou baixos. Vamos dar uma olhada no que tudo isso significa no próximo vídeo.
