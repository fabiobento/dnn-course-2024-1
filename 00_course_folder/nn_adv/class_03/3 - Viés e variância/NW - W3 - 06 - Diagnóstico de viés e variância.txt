O fluxo de trabalho típico do desenvolvimento de um sistema de aprendizado de máquina é que você tem uma ideia e treina o modelo, e quase sempre descobre que ele ainda não funciona tão bem quanto você gostaria. Quando estou treinando um modelo de aprendizado de máquina, ele praticamente nunca funciona tão bem na primeira vez. A chave para o processo de criação de um sistema de aprendizado de máquina é como decidir o que fazer a seguir para melhorar seu desempenho. Eu descobri em muitos aplicativos diferentes que analisar o viés e a variância de um algoritmo de aprendizado fornece uma orientação muito boa sobre o que tentar a seguir. Vamos dar uma olhada no que isso significa. Você deve se lembrar desse exemplo do primeiro curso sobre regressão linear. Quando dado esse conjunto de dados, se você encaixasse uma linha reta nele, ele não funcionaria muito bem. Dissemos que esse algoritmo tem um alto viés ou que prejudica esse conjunto de dados. Se você ajustasse um polinômio de quarta ordem, ele teria alta variância ou se sobreajusta. No meio, se você ajustar um polinômio quadrático, ele ficará muito bom. Então eu disse que estava certo. Como esse é um problema com apenas um único recurso x, poderíamos traçar a função f e vê-la assim. Mas se você tivesse mais recursos, não conseguiria plotar f e visualizar se ele está indo bem com tanta facilidade. Em vez de tentar analisar gráficos como esse, uma forma mais sistemática de diagnosticar ou descobrir se seu algoritmo tem alto viés ou alta variância será observar o desempenho do seu algoritmo no conjunto de treinamento e no conjunto de validação cruzada. Em particular, vamos ver o exemplo à esquerda. Se você fosse calcular o J_train, o desempenho do algoritmo no conjunto de treinamento? Não muito bem. Eu diria que o treinamento J aqui seria alto porque, na verdade, existem erros muito grandes entre os exemplos e as previsões reais do modelo. Que tal J_CV? J_cv seria se tivéssemos alguns exemplos novos, talvez exemplos como esses, que o algoritmo não tivesse visto anteriormente. Aqui, o algoritmo também não funciona muito bem em exemplos que não havia visto anteriormente, então J_CV também será alto. Uma característica de um algoritmo com alto viés, algo inadequado, é que ele nem mesmo está se saindo muito bem no conjunto de treinamento. Quando J_train está alto, esse é o seu forte indicador de que esse algoritmo tem um alto viés. Vamos agora ver o exemplo à direita. Se você fosse calcular o J_train, quão bem isso está funcionando no conjunto de treinamento? Bem, na verdade está indo muito bem no set de treinamento. Se ajusta muito bem aos dados de treinamento. O J_train aqui será baixo. Mas se você avaliar esse modelo em outras casas que não estão no conjunto de treinamento, descobrirá que J_CV, o erro de validação cruzada, será bastante alto. Uma assinatura característica ou uma característica Q em que seu algoritmo tem alta variância será de J_CV é muito maior do que J_train. Em outras palavras, ele se sai muito melhor com dados que viu do que com dados que não viu. Isso acaba sendo um forte indicador de que seu algoritmo tem alta variância. Novamente, o objetivo do que estamos fazendo é que estou computando J_train e J_cv e vendo se J _train é alto ou se J_cv é muito maior que J_train. Isso lhe dá uma ideia, mesmo que você não consiga representar graficamente para a função f, se seu algoritmo tem alto viés ou alta variância. Finalmente, a perseguição no meio. Se você observar o J_train, é bem baixo, então está indo muito bem no conjunto de treinamento. Se você analisasse alguns exemplos novos, como os de, digamos, seu conjunto de validação cruzada, descobriria que J_CV também é muito baixo. J_train não sendo muito alto indica que não há um problema de alta polarização e J_CV não sendo muito pior do que J_train, isso indica que ele também não tem um problema de alta variância. É por isso que o modelo quadrático parece ser muito bom para esta aplicação. Resumindo, quando d é igual a 1 para um polinômio linear, J_train era alto e J_cv era alto. Quando d é igual a 4, o trem J estava baixo, mas J_cv é alto. Quando d é igual a 2, ambos eram bem baixos. Vamos agora ter uma visão diferente sobre preconceito e variância. Em particular, no próximo slide, gostaria de mostrar como J_train e J_cv variam em função do grau do polinômio que você está ajustando. Deixe-me desenhar uma figura em que o eixo horizontal, esse d aqui, será o grau de polinômio que estamos ajustando aos dados. À esquerda, corresponderemos a um pequeno valor de d, como d igual a 1, que corresponde ao ajuste da linha reta. À direita, vamos corresponder a, digamos, d igual a 4 ou até valores maiores de d. Estamos ajustando esse polinômio de alta ordem.
Reproduza o vídeo começando em :5:33 e siga a transcrição5:33
Então, se você plotasse o trem J ou W, B em função do grau de polinômio, o que você descobriria é que, ao ajustar um polinômio de maior e maior grau, aqui estou assumindo que não estamos usando regularização, mas quando você ajusta um polinômio de ordem cada vez maior, o erro de treinamento tenderá a diminuir porque quando você tem uma função linear muito simples, ela não se ajusta aos dados de treinamento que Bem, quando você ajusta uma função quadrática ou polinômio de terceira ordem ou polinômio de quarta ordem, ela se ajusta cada vez melhor aos dados de treinamento. Conforme o grau de polinômio aumenta, o trem J normalmente diminui. A seguir, vamos dar uma olhada no J_CV, que é o quão bem ele se sai com dados aos quais não conseguiu se ajustar? O que vimos foi que quando d é igual a um, quando o grau de polinômio era muito baixo, J_CV era bem alto porque era inadequado, então não funcionou bem no conjunto de validação cruzada. Também aqui à direita, quando o grau de polinômio é muito grande, digamos quatro, ele também não funciona bem no conjunto de validação cruzada e, portanto, também é alto. Mas se d estivesse entre, digamos, um polinômio de segunda ordem, na verdade ele se saiu muito melhor. Se você variasse o grau do polinômio, na verdade obteria uma curva parecida com essa, que desce e depois volta para cima. Onde, se o grau de polinômio for muito baixo, ele se ajusta menos e, portanto, não o conjunto de validação cruzada; se for muito alto, ele se ajusta demais e também não funciona bem no conjunto de validação cruzada.
Reproduza o vídeo começando em :7:16 e siga a transcrição7:16
É só se estiver em algum lugar no meio, está certo, e é por isso que o polinômio de segunda ordem em nosso exemplo acaba com um erro de validação cruzada menor e nem alto viés nem alta variância. Resumindo, como você diagnostica o viés e a variação em seu algoritmo de aprendizado? Se o seu algoritmo de aprendizado tiver um viés alto ou tiver dados invictos, o indicador principal será se o treinamento J estiver alto. Isso corresponde a essa parte mais à esquerda da curva, que é onde eu treino tão alto. Normalmente você tem o trem J e o J_CV estará próximo um do outro. Como você diagnostica se você tem alta variância? Embora o principal indicador de alta variância seja se J_cv for muito maior que J, o trem dobra mais do que o sinal em matemática se refere a um muito maior que, então isso é maior e isso significa muito maior. Esta parte mais à direita do gráfico é onde J_CV é muito maior do que o trem J. Normalmente, o trem J é bem baixo, mas o principal indicador é se o trem J_CV é muito maior do que o trem J. Isso é o que acontece quando ajustamos um polinômio de ordem muito alta a esse pequeno conjunto de dados. Embora tenhamos acabado de ver compradores nas áreas, acontece que, em alguns casos, é possível ter um viés alto e uma alta variação simultaneamente. Você não verá isso acontecer muito com a regressão linear, mas acontece que, se você estiver treinando uma rede neural, existem alguns aplicativos em que, infelizmente, você tem alto viés e alta variância. Uma maneira de reconhecer essa situação será se o treinamento J estiver alto, então você não está se saindo muito bem no conjunto de treinamento, mas, pior ainda, o erro de validação cruzada é, novamente, ainda maior do que o conjunto de treinamento. A noção de alto viés e alta variância realmente não acontece para modelos lineares aplicados a uma profundidade. Mas, para dar uma intuição sobre sua aparência, seria como se, para parte da entrada, você tivesse um modelo muito complicado que se encaixa demais, então ele se adapta a parte das entradas. Mas, por algum motivo, para outras partes da entrada, ela nem mesmo se ajusta bem aos dados de treinamento e, portanto, é inadequada para parte da entrada. Neste exemplo, que parece artificial porque é uma entrada de recurso único, ajustamos muito bem o conjunto de treinamento e superajustamos parte da entrada, nem mesmo ajustamos bem os dados de treinamento e subestimamos a parte da entrada. É assim que, em alguns aplicativos, infelizmente, você pode acabar com alto viés e alta variância. O indicador para isso será se o algoritmo se sair mal no conjunto de treinamento e até se sair muito pior do que no conjunto de treinamento. Para a maioria dos aplicativos de aprendizado, você provavelmente tem principalmente um problema de alto viés ou alta variância, em vez de ambos ao mesmo tempo. Mas às vezes é possível que os dois estejam ao mesmo tempo. Sei que há muitos processos, muitos conceitos nos slides, mas a principal conclusão é que alto viés significa que nem mesmo está indo bem no conjunto de treinamento, e alta variância significa que é muito pior no conjunto de validação cruzada e no conjunto de treinamento. Sempre que estou treinando um algoritmo de aprendizado de máquina, quase sempre tento descobrir até que ponto o algoritmo tem um alto viés ou um problema de ajuste inadequado versus uma alta variação no sobreajuste. Isso fornecerá uma boa orientação, como veremos no final desta semana, sobre como você pode melhorar o desempenho do algoritmo. Mas primeiro, vamos dar uma olhada em como a regularização afeta o viés e a variância de um algoritmo de aprendizado, pois isso o ajudará a entender melhor quando você deve usar a regularização. Vamos dar uma olhada nisso no próximo vídeo.
