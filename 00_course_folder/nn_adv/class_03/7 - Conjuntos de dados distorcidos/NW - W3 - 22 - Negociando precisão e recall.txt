No caso ideal, gostamos de aprender algoritmos que tenham alta precisão e alta recuperação. Alta precisão significaria que, se um diagnóstico de pacientes tem essa doença rara, provavelmente o paciente a tem e é um diagnóstico preciso. Uma alta recordação significa que, se houver um paciente com essa doença rara, provavelmente o algoritmo identificará corretamente que ele tem essa doença. Mas acontece que, na prática, muitas vezes há uma troca entre precisão e recall. Neste vídeo, daremos uma olhada nessa troca e como você pode escolher um bom ponto ao longo dessa troca. Aqui estão as definições do último vídeo sobre precisão e recordação. Vou escrevê-las aqui. Bem, você lembra que a precisão é o número de positivos verdadeiros dividido pelo número total que foi previsto como positivo, e a lembrança é o número de positivos verdadeiros dividido pelo número total real de positivos. Se você estiver usando regressão logística para fazer previsões, o modelo de regressão logística produzirá números entre 0 e 1. Normalmente, limitaríamos a saída da regressão logística em 0,5 e predizemos 1 se f de x for maior que igual a 0,5 e predizemos 0 se for menor que 0,5. Mas suponha que queiramos prever que y é igual a 1. Ou seja, a doença rara só está presente se estivermos muito confiantes. Se nossa filosofia é: sempre que predizemos que o paciente tem uma doença, talvez tenhamos que enviá-lo para um tratamento possivelmente invasivo e caro. Se as consequências da doença não forem tão ruins, mesmo que não seja tratada de forma agressiva, talvez queiramos prever que y é igual a 1 somente se estivermos muito confiantes. Nesse caso, podemos escolher definir um limite mais alto em que predizemos que y é 1 somente se f de x for maior ou igual a 0,7, então isso quer dizer que vamos prever que y é igual a 1 só que temos pelo menos 70 por cento de certeza, em vez de apenas 50 por cento de certeza e, portanto, esse número também se torna 0,7. Observe que esses dois números precisam ser os mesmos porque depende apenas de ser maior ou igual ou menor que esse número que você prevê 1 ou 0. Ao aumentar esse limite, você prevê que y é igual a 1 somente se estiver bastante confiante e isso significa que a precisão aumentará porque sempre que você prevê um, é mais provável que você esteja certo, então aumentar os limites resultará em maior precisão, mas também resultará em menor recordação, porque agora estamos prevendo um com menos frequência e, portanto, do número total de pacientes com a doença, diagnosticaremos corretamente menos deles. Ao aumentar esse limite para 0,7, você obtém maior precisão, mas menor recordação. Na verdade, se você quiser prever que y é igual a 1 somente se estiver muito confiante, você pode até aumentar isso para 0,9 e isso resulta em uma precisão ainda maior. Portanto, sempre que você prevê que o paciente tem a doença, provavelmente está certo e isso lhe dará uma precisão muito alta. O recall será ainda mais baixo. Por outro lado, suponha que queiramos evitar perder muitos casos da doença rara ; portanto, se o que queremos é, em caso de dúvida, prever que y seja igual a 1, esse pode ser o caso em que, se o tratamento não for muito invasivo, doloroso ou caro, mas deixar uma doença sem tratamento tem consequências muito piores para o paciente. Nesse caso, você pode dizer que, em caso de dúvida, no interesse da segurança, vamos apenas prever que eles a têm e considerá-los para tratamento, porque casos não tratados podem ser muito ruins. Se, para o seu aplicativo, essa for a melhor maneira de tomar decisões, você adotaria esse limite em vez de diminuí-lo, digamos, defini-lo para 0,3. Nesse caso, você prevê uma desde que ache que talvez haja 30% ou mais de chance de a doença estar presente e prevê zero somente se tiver certeza de que a doença está ausente. Como você pode imaginar, o impacto na precisão e na recordação será oposto ao que você viu aqui, e reduzir esse limite resultará em menor precisão porque agora estamos mais frouxos, estamos mais dispostos a prever uma, mesmo que não tenhamos certeza, mas para resultar em um maior recall, porque de todos os pacientes que têm essa doença, provavelmente identificaremos corretamente mais deles.
Reproduza o vídeo começando em :5:4 e siga a transcrição5:04
De forma mais geral, temos a flexibilidade de prever um somente se f estiver acima de algum limite e, ao escolher esse limite, podemos fazer diferentes compensações entre precisão e recall. Acontece que, para a maioria dos algoritmos de aprendizado, há uma compensação entre precisão e recuperação. A precisão e o recall variam entre zero e um e, se você definir um limite muito alto, digamos, um limite de 0,99, você entra com uma precisão muito alta, mas com menor recuperação. Ao reduzir o valor desse limite, você acaba com uma curva que troca precisão e recall até que, eventualmente, se você tiver um limite muito baixo, então o limite é igual a 0,01, então você acaba com uma precisão muito baixa mas um recall relativamente alto. Às vezes, ao traçar essa curva, você pode tentar escolher um limite que corresponda à escolha de um ponto nessa curva. Os saldos, o custo de falsos positivos e falsos negativos ou os saldos, os benefícios da alta precisão e do alto recall. A precisão de plotagem e a recuperação de diferentes valores do limite permitem que você escolha o ponto desejado. Observe que escolher o limite não é algo que você realmente possa fazer com a validação cruzada, pois cabe a você especificar os melhores pontos. Para muitas aplicações, escolher manualmente o limite entre precisão e recall será o que você acabará fazendo. Acontece que, se você quiser trocar precisão e recall automaticamente, em vez de ter que fazer isso sozinho, existe outra métrica chamada pontuação F1 que às vezes é usada para combinar automaticamente a recuperação de precisão para ajudá-lo a escolher o melhor valor ou a melhor compensação entre os dois. Um desafio com a recuperação de precisão é que agora você está avaliando seus algoritmos usando duas métricas diferentes, então, se você treinou três algoritmos diferentes e os números da recuperação de precisão são assim, não é óbvio escolher qual algoritmo usar. Se houvesse um algoritmo que fosse melhor em precisão e melhor em recuperação, então você provavelmente gostaria de usar esse. Mas neste exemplo, o Algoritmo 2 tem a maior precisão, mas o Algoritmo 3 tem a maior recordação, e o Algoritmo 1 troca os dois intermediários, portanto, nenhum algoritmo é obviamente a melhor escolha. Para ajudá-lo a decidir qual algoritmo escolher, pode ser útil encontrar uma maneira de combinar precisão e recuperação em uma única pontuação, para que você possa ver qual algoritmo tem a pontuação mais alta e talvez escolher aquela. Uma maneira de combinar precisão e recall é calcular a média. Isso acaba não sendo uma boa maneira, então eu realmente não recomendo isso. Mas se tomarmos a média, obtemos 0,45 , 0,4 e 0,5. Mas acontece que calcular a média e escolher o algoritmo com a maior média entre precisão e recall não funciona muito bem porque esse algoritmo tem uma precisão muito baixa e, na verdade, isso talvez corresponda a um algoritmo que realmente imprime y igual a 1 e diagnostica todos os pacientes como portadores da doença. É por isso que o recall é perfeito, mas a precisão é muito baixa. Na verdade, o algoritmo 3 não é um algoritmo particularmente útil, embora a média entre precisão e recuperação seja bastante alta. Não vamos usar a média entre precisão e recall. Em vez disso, a maneira mais comum de combinar a recuperação de precisão é computar algo chamado pontuação F1, e a pontuação F1 é uma forma de combinar a precisão e a recuperação P e R, mas isso dá mais ênfase a qualquer um desses valores que seja menor. Porque acontece que se um algoritmo tem uma precisão muito baixa ou uma recuperação muito baixa, não é muito útil. A pontuação da F1 é uma forma de calcular um tipo de média que presta mais atenção ao que for menor. A fórmula para calcular a pontuação F1 é a seguinte: você calculará uma sobre P e outra sobre R, calculará a média delas e, em seguida, calculará o inverso disso. Em vez de calcular a média de precisão de P e R, vamos calcular a média de um sobre P e um sobre R e, em seguida, calcular uma sobre isso. Se você simplificar essa equação, ela também poderá ser calculada da seguinte forma. Mas calculando a média de um sobre P e um sobre R, isso dá uma ênfase muito maior ao fato de P ou R serem muito pequenos. Se você calcular a pontuação F1 para esses três algoritmos, descobrirá que a pontuação F1 para o algoritmo 1 é 0,444 e para o segundo algoritmo é 0,175. Você percebe que 0,175 está muito mais próximo do valor mais baixo do que do valor mais alto e, para o terceiro algoritmo, é 0,0392. A pontuação F1 cede a precisão e o recall e, nesse caso, nos dirá que talvez o primeiro algoritmo seja melhor do que o segundo ou o terceiro algoritmo. A propósito, em matemática, essa equação também é chamada de média harmônica de P e R, e a média harmônica é uma forma de obter uma média que enfatize mais os valores menores. Mas, para os propósitos desta aula, você não precisa se preocupar com a terminologia da média harmônica. Parabéns por assistir ao último vídeo desta semana e obrigado também por ficar comigo durante esses dois vídeos opcionais. Nesta semana, você aprendeu muitas dicas práticas, conselhos práticos sobre como criar um sistema de aprendizado de máquina e, ao aplicar essas ideias, acho que seria muito eficaz na criação de algoritmos de aprendizado de máquina. Na próxima semana, voltaremos para falar sobre outro algoritmo de aprendizado de máquina muito poderoso. Na verdade, das técnicas avançadas que usamos em muitos ambientes de produção comercial, acho que no topo da lista estariam as redes neurais e as árvores de decisão. Na próxima semana, falaremos sobre árvores de decisão, que acho que serão outra técnica muito poderosa que você também usará para criar muitos aplicativos bem-sucedidos. Estou ansioso para ver você na próxima semana.
