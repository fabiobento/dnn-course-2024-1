{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_03/Laborat%C3%B3rios/lab_utils_ml_adv_week_3.zip\n",
    "      \n",
    "!unzip -n -q lab_utils_ml_adv_week_3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "# Necessário para ativar widgets\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvYDy9apGRlt"
   },
   "source": [
    "# Avaliação e Seleção de Modelos\n",
    "\n",
    "Quantificar o desempenho de um algoritmo de aprendizado e comparar diferentes modelos são algumas das tarefas comuns ao aplicar o aprendizado de máquina ao mundo real.\n",
    "\n",
    "Neste laboratório, você praticará essas tarefas usando as dicas compartilhadas em sala de aula. Especificamente, você irá:\n",
    "\n",
    "* dividir os conjuntos de dados em conjuntos de treinamento, validação cruzada e teste\n",
    "* avaliar modelos de regressão e classificação\n",
    "* adicionar recursos polinomiais para melhorar o desempenho de um modelo de regressão linear\n",
    "* comparar várias arquiteturas de redes neurais\n",
    "\n",
    "Este laboratório também o ajudará a se familiarizar com o código que você verá na atividade avaliativa do tópico \"Boas Práticas durante o Treino e Avaliação de Redes Neurais\". Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj1P1kTmGRlv"
   },
   "source": [
    "## Importações e configuração do laboratório\n",
    "\n",
    "Primeiro, você importará os pacotes necessários para as tarefas deste laboratório. Também foram incluídos alguns comandos para tornar os resultados mais legíveis posteriormente, reduzindo a verbosidade e suprimindo avisos não críticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuHD2EOxGRlv"
   },
   "outputs": [],
   "source": [
    "# para cálculos de matrizes e carregamento de dados\n",
    "import numpy as np\n",
    "\n",
    "# para criar modelos de regressão linear e preparar dados\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# para criar e treinar redes neurais\n",
    "import tensorflow as tf\n",
    "\n",
    "# funções personalizadas\n",
    "import utils\n",
    "\n",
    "# Reduzir a precisão da exibição em matrizes numéricas\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# suprimir avisos\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_UnQ-tWGRlw"
   },
   "source": [
    "## Regressão\n",
    "\n",
    "Primeiro, você terá a tarefa de desenvolver um modelo para um problema de regressão. Você recebeu o conjunto de dados abaixo, que consiste em 50 exemplos de um recurso de entrada `x` e seu alvo correspondente `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLsSum08GRlx",
    "outputId": "0d843000-30bf-4a55-dcd8-cd5e42dc716e"
   },
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados do arquivo de texto\n",
    "data = np.loadtxt('./data/data_w3_ex1.csv', delimiter=',')\n",
    "\n",
    "# Dividir as entradas e saídas em matrizes separadas\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "\n",
    "# Converta matrizes 1-D em 2-D porque os comandos posteriores exigirão isso\n",
    "x = np.expand_dims(x, axis=1)\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "print(f\"o formato da entrada x é: {x.shape}\")\n",
    "print(f\"o formato dos alvos y é: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ar2jLTqlpt4x"
   },
   "source": [
    "Você pode plotar o conjunto de dados para ter uma ideia de como o alvo se comporta em relação à entrada. Caso queira inspecionar o código, você pode encontrar a função `plot_dataset()` no arquivo `utils.py` fora deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "VxJqex92GRlx",
    "outputId": "b6d781d1-bff3-4912-abe1-0d7fe5738b08"
   },
   "outputs": [],
   "source": [
    "# Plotar todo o conjunto de dados\n",
    "utils.plot_dataset(x=x, y=y, title=\"entrada vs. alvo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbZdSoJHGRly"
   },
   "source": [
    "## Dividir o conjunto de dados em conjuntos de treinamento, validação cruzada e teste\n",
    "\n",
    "Em laboratórios anteriores, você pode ter usado todo o conjunto de dados para treinar seus modelos. Na prática, entretanto, é melhor reter uma parte dos dados para medir a capacidade de generalização do modelo para novos exemplos. Isso permitirá que você saiba se o modelo se ajustou demais ao conjunto de treinamento (_overfitting_).\n",
    "\n",
    "Conforme mencionado na aula, é comum dividir seus dados em três partes:\n",
    "\n",
    "* ***conjunto de treinamento*** - usado para treinar o modelo\n",
    "* ***conjunto de validação cruzada (também chamado de validação, desenvolvimento ou conjunto dev)*** - usado para avaliar as diferentes configurações de modelo que você está escolhendo. Por exemplo, você pode usá-lo para tomar uma decisão sobre quais recursos polinomiais devem ser adicionados ao conjunto de dados.\n",
    "* ***conjunto de teste*** - usado para fornecer uma estimativa justa do desempenho do modelo escolhido em relação a novos exemplos. Isso não deve ser usado para tomar decisões enquanto você ainda estiver desenvolvendo os modelos.\n",
    "\n",
    "O Scikit-learn fornece uma função [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para dividir seus dados nas partes mencionadas acima. Na célula de código abaixo, você dividirá o conjunto de dados inteiro em 60% de treinamento, 20% de validação cruzada e 20% de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22JKPjmjGRly",
    "outputId": "6f02748d-e8ef-4243-d7ff-a206be7e66f5"
   },
   "outputs": [],
   "source": [
    "# Obtenha 60% do conjunto de dados como o conjunto de treinamento.\n",
    "# Coloque os 40% restantes em variáveis temporárias: x_ e y_.\n",
    "x_train, x_, y_train, y_ = train_test_split(x, y, test_size=0.40, random_state=1)\n",
    "\n",
    "# Dividir o subconjunto de 40% acima em dois:\n",
    "# uma metade para validação cruzada e a outra para o conjunto de teste\n",
    "x_cv, x_test, y_cv, y_test = train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# Excluir variáveis temporárias\n",
    "del x_, y_\n",
    "\n",
    "print(f\"o formato do conjunto de treino (entrada) é: {x_train.shape}\")\n",
    "print(f\"o formato do conjunto de treino (alvo) é: {y_train.shape}\\n\")\n",
    "print(f\"o formato do conjunto de validação cruzada (entrada) é: {x_cv.shape}\")\n",
    "print(f\"o formato do conjunto de validação cruzada (alvo) é: {y_cv.shape}\\n\")\n",
    "print(f\"o formato do conjunto de teste (entrada) é: {x_test.shape}\")\n",
    "print(f\"o formato do conjunto de teste (alvo) é: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrgciBNd1HYr"
   },
   "source": [
    "Você pode plotar o conjunto de dados novamente abaixo para ver quais pontos foram usados como dados de treinamento, validação cruzada ou teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "yGm8JbUUzoUW",
    "outputId": "2f7227ef-9e48-4df5-d913-a5b48e92fe81"
   },
   "outputs": [],
   "source": [
    "utils.plot_train_cv_test(x_train, y_train, x_cv, y_cv, x_test, y_test, title=\"input vs. target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ayr22PeEGRly"
   },
   "source": [
    "## Ajustar um modelo linear\n",
    "\n",
    "Agora que você dividiu os dados, uma das primeiras coisas que pode tentar é ajustar um modelo linear. Isso será feito nas próximas seções abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1UdF77SGRlz"
   },
   "source": [
    "### Feature scaling\n",
    "Anteriormente você viu que geralmente é uma boa ideia realizar o _feature scaling_ para ajudar o modelo a convergir mais rapidamente. Isso é especialmente verdadeiro se os recursos de entrada tiverem faixas de valores muito diferentes. \n",
    "\n",
    "Mais adiante neste laboratório, você adicionará termos polinomiais para que os recursos de entrada tenham, de fato, intervalos diferentes. Por exemplo, $x$ varia de aproximadamente 1600 a 3600, enquanto $x^2$ varia de 2,56 milhões a 12,96 milhões. \n",
    "\n",
    "Você usará apenas $x$ para esse primeiro modelo, mas é bom praticar o dimensionamento de recursos agora para poder aplicá-lo mais tarde. Para isso, você usará a classe [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) do scikit-learn. Ele calcula o _z-score_ de suas entradas.\n",
    "\n",
    "Para relembrar, o _z-score_ é dado pela _equação:\n",
    "_\n",
    "\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "em que $\\mu$ é a média dos valores dos recursos e $\\sigma$ é o desvio padrão.\n",
    "\n",
    "O código abaixo mostra como preparar o conjunto de treinamento usando a classe mencionada. Você pode plotar os resultados novamente para inspecionar se eles ainda seguem o mesmo padrão de antes. O novo gráfico deve ter um intervalo reduzido de valores para `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QlJ7eQ0TGRlz",
    "outputId": "ed899629-4c5e-468d-d5c8-a4b3349bd62a"
   },
   "outputs": [],
   "source": [
    "# Inicializar a classe\n",
    "scaler_linear = StandardScaler()\n",
    "\n",
    "# Calcule a média e o desvio padrão do conjunto de treinamento e, em seguida, transforme-o\n",
    "X_train_scaled = scaler_linear.fit_transform(x_train)\n",
    "\n",
    "print(f\"Média computada do conjunto de treinamento: {scaler_linear.mean_.squeeze():.2f}\")\n",
    "print(f\"Desvio padrão calculado do conjunto de treinamento: {scaler_linear.scale_.squeeze():.2f}\")\n",
    "\n",
    "# Plot the results\n",
    "utils.plot_dataset(x=X_train_scaled, y=y_train, title=\"entradas escaladas vs. alvo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzDw7PcJGRlz"
   },
   "source": [
    "### Treinar o modelo\n",
    "\n",
    "Em seguida, você criará e treinará um modelo de regressão. Para este laboratório, você usará a classe [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), mas observe que há outros [linear regressors](https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors) que também podem ser usados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIol3uTkGRlz",
    "outputId": "283e5e1c-9aff-41bb-c2d3-6977861d63bd"
   },
   "outputs": [],
   "source": [
    "# Inicializar a classe\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Treinar o modelo\n",
    "linear_model.fit(X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8LW5leOGRlz"
   },
   "source": [
    "### Avaliar o modelo\n",
    "\n",
    "Para avaliar o desempenho do seu modelo, você medirá o erro dos conjuntos de treinamento e validação cruzada. Para o erro de treinamento, lembre-se da equação para calcular o erro quadrático médio (MSE):\n",
    "\n",
    "$$J_{train}(\\vec{w}, b) = \\frac{1}{2m_{train}}\\left[\\sum_{i=1}^{m_{train}}(f_{\\vec{w},b}(\\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2\\right]$$\n",
    "\n",
    "O Scikit-learn também tem uma função interna [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) que você pode usar. Observe, porém, que [de acordo com a documentação](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error), a implementação do scikit-learn divide apenas por `m` e não por `2*m`, em que `m` é o número de exemplos. Conforme mencionado anteriormente(aulas sobre a função de custo), a divisão por `2m` é uma convenção que seguiremos, mas os cálculos ainda devem funcionar independentemente de você incluí-la ou não. Portanto, para corresponder à equação acima, você pode usar a função scikit-learn e dividir por 2, conforme mostrado abaixo. Também foi incluída uma implementação de loop-for para que você possa verificar se é igual. \n",
    "\n",
    "Outro aspecto a ser observado: como você treinou o modelo em valores escalonados (ou seja, usando o _z-score_), você também deve alimentar o conjunto de treinamento escalonado em vez de seus valores brutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmuskcDhfy8z",
    "outputId": "10bb7e65-1723-4ab6-8bbf-f800e8777474"
   },
   "outputs": [],
   "source": [
    "# Alimente o conjunto de treinamento escalado e obtenha as previsões\n",
    "yhat = linear_model.predict(X_train_scaled)\n",
    "\n",
    "# Use a função do scikit-learn e divida por 2\n",
    "print(f\"MSE de treino (usando a função do sklearn): {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "# Implementação do for-loop\n",
    "total_squared_error = 0\n",
    "\n",
    "for i in range(len(yhat)):\n",
    "    squared_error_i  = (yhat[i] - y_train[i])**2\n",
    "    total_squared_error += squared_error_i                                              \n",
    "\n",
    "mse = total_squared_error / (2*len(yhat))\n",
    "\n",
    "print(f\"treinamento MSE (implementação loop-for): {mse.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lujrQns9f-vu"
   },
   "source": [
    "Em seguida, você pode calcular o MSE para o conjunto de validação cruzada basicamente com a mesma equação:\n",
    "\n",
    "$$J_{cv}(\\vec{w}, b) = \\frac{1}{2m_{cv}}\\left[\\sum_{i=1}^{m_{cv}}(f_{\\vec{w},b}(\\vec{x}_{cv}^{(i)}) - y_{cv}^{(i)})^2\\right]$$\n",
    "\n",
    "Assim como no conjunto de treinamento, você também deverá escalar o conjunto de validação cruzada. Um aspecto *importante* a ser observado ao usar o _z-score_ é que você deve usar a média e o desvio padrão do **conjunto de treinamento** ao escalar o conjunto de validação cruzada. Isso serve para garantir que seus recursos de entrada sejam transformados conforme o esperado pelo modelo. Uma maneira de obter intuição é com este cenário:\n",
    "\n",
    "* Digamos que seu conjunto de treinamento tenha um recurso de entrada igual a \"500\", que é reduzido para \"0,5\" usando o _z-score_.\n",
    "* Após o treinamento, seu modelo é capaz de mapear com precisão essa entrada escalonada `x=0,5` para a saída de destino `y=300`. \n",
    "* Agora, digamos que você tenha implantado esse modelo e um dos seus usuários tenha fornecido uma amostra igual a 500. \n",
    "* Se você obtiver o z-score dessa amostra de entrada usando qualquer outro valor da média e do desvio padrão, ele poderá não ser escalado para `0,5` e seu modelo provavelmente fará uma previsão errada (ou seja, não será igual a `y=300`). \n",
    "\n",
    "\n",
    "\n",
    "Você dimensionará o conjunto de validação cruzada abaixo usando o mesmo `StandardScaler` usado anteriormente, mas apenas chamando o método [`transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform) em vez de [`fit_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJQbmq70GRl0",
    "outputId": "7b75d664-7cf0-4a27-c79c-3236857f444b"
   },
   "outputs": [],
   "source": [
    "# Escale o conjunto de validação cruzada usando a média e o desvio padrão do conjunto de treinamento\n",
    "X_cv_scaled = scaler_linear.transform(x_cv)\n",
    "\n",
    "print(f\"Média usada para escalar o conjunto de VC: {scaler_linear.mean_.squeeze():.2f}\")\n",
    "print(f\"Desvio padrão usado para dimensionar o conjunto de VC: {scaler_linear.scale_.squeeze():.2f}\")\n",
    "\n",
    "# Alimentar o conjunto de validação cruzada escalonada\n",
    "yhat = linear_model.predict(X_cv_scaled)\n",
    "\n",
    "# Use a função de utilidade do scikit-learn e divida por 2\n",
    "print(f\"MSE de validação cruzada: {mean_squared_error(y_cv, yhat) / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZtb_blcGRl0"
   },
   "source": [
    "## Adição de recursos polinomiais\n",
    "\n",
    "Nos gráficos anteriores, você deve ter notado que o alvo `y` aumenta mais acentuadamente em valores menores de `x` em comparação com os maiores. Uma linha reta pode não ser a melhor escolha porque o alvo `y` parece se achatar à medida que `x` aumenta. Agora que você tem esses valores de MSE de treinamento e validação cruzada do modelo linear, pode tentar adicionar recursos polinomiais para ver se consegue obter um desempenho melhor. O código será basicamente o mesmo, mas com algumas etapas extras de pré-processamento. Vamos ver isso a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar os recursos adicionais\n",
    "\n",
    "Primeiro, você gerará os recursos polinomiais do seu conjunto de treinamento. O código abaixo demonstra como fazer isso usando a classe [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). Ele criará um novo recurso de entrada que tem os valores ao quadrado da entrada `x` (ou seja, grau=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt1FCgQOGRl0"
   },
   "outputs": [],
   "source": [
    "# Instanciar a classe para criar recursos polinomiais\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Calcular o número de recursos e transformar o conjunto de treinamento\n",
    "X_train_mapped = poly.fit_transform(x_train)\n",
    "\n",
    "# Visualize os primeiros 5 elementos do novo conjunto de treinamento. A coluna da esquerda é `x` e a da direita é `x^2`\n",
    "# Observação: o `e+<número>` na saída indica quantas casas o ponto decimal deve \n",
    "# ser movido. Por exemplo, `3.24e+03` é igual a `3240`\n",
    "print(X_train_mapped[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você dimensionará as entradas como antes para restringir o intervalo de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVJUmPQKGRl1"
   },
   "outputs": [],
   "source": [
    "# Instanciar a classe\n",
    "scaler_poly = StandardScaler()\n",
    "\n",
    "# Calcule a média e o desvio padrão do conjunto de treinamento e, em seguida, transforme-o\n",
    "X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)\n",
    "\n",
    "# Visualize os primeiros 5 elementos do conjunto de treinamento escalado.\n",
    "print(X_train_mapped_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você pode prosseguir com o treinamento do modelo. Depois disso, você medirá o desempenho do modelo em relação ao conjunto de validação cruzada. Como antes, você deve se certificar de realizar as mesmas transformações que fez no conjunto de treinamento. Você adicionará o mesmo número de recursos polinomiais e dimensionará o intervalo de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO7rK-f9GRl1",
    "outputId": "12a61725-7eab-40c0-91c2-2acc9f1c5d2a"
   },
   "outputs": [],
   "source": [
    "# Inicializar a classe\n",
    "model = LinearRegression()\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_mapped_scaled, y_train )\n",
    "\n",
    "# Calcular o MSE de treinamento\n",
    "yhat = model.predict(X_train_mapped_scaled)\n",
    "print(f\"MSE de treino: {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "# Adicionar os recursos polinomiais ao conjunto de validação cruzada\n",
    "X_cv_mapped = poly.transform(x_cv)\n",
    "\n",
    "# Dimensionar o conjunto de validação cruzada usando a média e o desvio padrão do conjunto de treinamento\n",
    "X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)\n",
    "\n",
    "# Calcular a validação cruzada MSE\n",
    "yhat = model.predict(X_cv_mapped_scaled)\n",
    "print(f\"MSE de validação cruzada: {mean_squared_error(y_cv, yhat) / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você notará que os MSEs são significativamente melhores tanto para o conjunto de treino quanto para o conjunto de validação cruzada quando você adicionou o polinômio de 2ª ordem. É possível que você queira introduzir mais termos polinomiais e ver qual deles apresenta o melhor desempenho. Conforme mostrado na aula, você pode ter 10 modelos diferentes como este:\n",
    "\n",
    "<img src='images/C2_W3_poly.png' width=50%>\n",
    "\n",
    "Você pode criar um loop que contenha todas as etapas das células de código anteriores. Aqui está uma implementação que adiciona recursos polinomiais de até grau = 10. Vamos plotá-la no final para facilitar a comparação dos resultados de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar listas para salvar os erros, os modelos e as transformações de recursos\n",
    "train_mses = []\n",
    "cv_mses = []\n",
    "models = []\n",
    "polys = []\n",
    "scalers = []\n",
    "\n",
    "# Faça um loop de 10 vezes. Cada vez adicionando mais um grau de polinômio maior que o anterior.\n",
    "for degree in range(1,11):\n",
    "    \n",
    "    # Adicionar recursos polinomiais ao conjunto de treinamento\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    X_train_mapped = poly.fit_transform(x_train)\n",
    "    polys.append(poly)\n",
    "    \n",
    "    # Escalar o conjunto de treinamento\n",
    "    scaler_poly = StandardScaler()\n",
    "    X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)\n",
    "    scalers.append(scaler_poly)\n",
    "    \n",
    "    # Criar e treinar o modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_mapped_scaled, y_train )\n",
    "    models.append(model)\n",
    "    \n",
    "    # Calcular o MSE de treinamento\n",
    "    yhat = model.predict(X_train_mapped_scaled)\n",
    "    train_mse = mean_squared_error(y_train, yhat) / 2\n",
    "    train_mses.append(train_mse)\n",
    "    \n",
    "    # Adicionar recursos polinomiais e dimensionar o conjunto de validação cruzada\n",
    "    X_cv_mapped = poly.transform(x_cv)\n",
    "    X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)\n",
    "    \n",
    "    # Calcular a validação cruzada MSE\n",
    "    yhat = model.predict(X_cv_mapped_scaled)\n",
    "    cv_mse = mean_squared_error(y_cv, yhat) / 2\n",
    "    cv_mses.append(cv_mse)\n",
    "    \n",
    "# Plotar os resultados\n",
    "degrees=range(1,11)\n",
    "utils.plot_train_cv_mses(degrees, train_mses, cv_mses, title=\"grau do polinômio vs. MSEs do trem e do CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R83nSGpXGRl2"
   },
   "source": [
    "### Escolhendo o melhor modelo\n",
    "\n",
    "Ao selecionar um modelo, você deve escolher um que tenha bom desempenho tanto no conjunto de treinamento quanto no de validação cruzada. Isso significa que ele é capaz de aprender os padrões do conjunto de treinamento sem se ajustar demais. Se você usou os padrões neste laboratório, notará uma queda acentuada no erro de validação cruzada dos modelos com grau = 1 para grau = 2. Isso é seguido por uma linha relativamente plana até grau=5. Depois disso, no entanto, o erro de validação cruzada geralmente piora à medida que você adiciona mais recursos polinomiais. Diante disso, você pode decidir usar o modelo com o menor `cv_mse` como o mais adequado para o seu aplicativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenha o modelo com o menor CV MSE (adicione 1 porque os índices da lista começam em 0)\n",
    "# Isso também corresponde ao grau do polinômio adicionado\n",
    "degree = np.argmin(cv_mses) + 1\n",
    "print(f\"O CV MSE mais baixo é encontrado no modelo com grau={degree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você pode imprmir o erro de generalização calculando o MSE do conjunto de teste. Como de costume, você deve transformar esses dados da mesma forma que fez com os conjuntos de treinamento e validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar recursos polinomiais ao conjunto de teste\n",
    "X_test_mapped = polys[degree-1].transform(x_test)\n",
    "\n",
    "# Escalar o conjunto de teste\n",
    "X_test_mapped_scaled = scalers[degree-1].transform(X_test_mapped)\n",
    "\n",
    "# Calcular o MSE de teste\n",
    "yhat = models[degree-1].predict(X_test_mapped_scaled)\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"MSE de treino: {train_mses[degree-1]:.2f}\")\n",
    "print(f\"MSE de validação cruzada: {cv_mses[degree-1]:.2f}\")\n",
    "print(f\"MSE de teste: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5uStJF3GRl2"
   },
   "source": [
    "## Redes neurais\n",
    "\n",
    "O mesmo processo de seleção de modelos também pode ser usado ao escolher entre diferentes arquiteturas de redes neurais. Nesta seção, você criará os modelos mostrados abaixo e os aplicará à mesma tarefa de regressão acima.\n",
    "\n",
    "<img src='images/C2_W3_NN_Arch.png' width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar os dados\n",
    "\n",
    "Você usará os mesmos conjuntos de treinamento, validação cruzada e teste que gerou na seção anterior.\n",
    "\n",
    "Com base em aulas anteriores, você já deve saber que as redes neurais podem aprender relações não lineares, portanto, pode optar por não adicionar recursos polinomiais. O código ainda está incluído abaixo, caso você queira tentar mais tarde e ver o efeito que isso terá nos resultados. O `degree` padrão é definido como `1` para indicar que ele usará apenas `x_train`, `x_cv` e `x_test` como estão (ou seja, sem nenhum recurso polinomial adicional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-armALWpGRl2"
   },
   "outputs": [],
   "source": [
    "# Adicionar recursos polinomiais\n",
    "degree = 1\n",
    "poly = PolynomialFeatures(degree, include_bias=False)\n",
    "X_train_mapped = poly.fit_transform(x_train)\n",
    "X_cv_mapped = poly.transform(x_cv)\n",
    "X_test_mapped = poly.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você dimensionará os recursos de entrada para ajudar o gradiente de descida a convergir mais rapidamente. Novamente, observe que você está usando a média e o desvio padrão calculados a partir do conjunto de treinamento usando apenas `transform()` na validação cruzada e nos conjuntos de teste em vez de `fit_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBn-0m0IGRl2"
   },
   "outputs": [],
   "source": [
    "# Escale as características usando o z-score\n",
    "scaler = StandardScaler()\n",
    "X_train_mapped_scaled = scaler.fit_transform(X_train_mapped)\n",
    "X_cv_mapped_scaled = scaler.transform(X_cv_mapped)\n",
    "X_test_mapped_scaled = scaler.transform(X_test_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar e treinar os modelos\n",
    "\n",
    "Em seguida, você criará as arquiteturas de rede neural mostradas anteriormente. O código é fornecido na função `build_models()` no arquivo `utils.py`, caso você queira inspecioná-lo ou modificá-lo. Você o usará no loop abaixo e, em seguida, prosseguirá com o treinamento dos modelos. Para cada modelo, você também registrará os erros de treinamento e validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar as listas que conterão os erros de cada modelo\n",
    "nn_train_mses = []\n",
    "nn_cv_mses = []\n",
    "\n",
    "# Criar os modelos\n",
    "nn_models = utils.build_models()\n",
    "\n",
    "# Fazer um loop sobre os modelos\n",
    "for model in nn_models:\n",
    "    \n",
    "    # Configurar a perda e o otimizador\n",
    "    model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    )\n",
    "\n",
    "    print(f\"Treinando {model.name}...\")\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(\n",
    "        X_train_mapped_scaled, y_train,\n",
    "        epochs=300,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Concluído!\\n\")\n",
    "\n",
    "    \n",
    "    # Registre as MPEs de treinamento\n",
    "    yhat = model.predict(X_train_mapped_scaled)\n",
    "    train_mse = mean_squared_error(y_train, yhat) / 2\n",
    "    nn_train_mses.append(train_mse)\n",
    "    \n",
    "    # Registre os MSEs da validação cruzada \n",
    "    yhat = model.predict(X_cv_mapped_scaled)\n",
    "    cv_mse = mean_squared_error(y_cv, yhat) / 2\n",
    "    nn_cv_mses.append(cv_mse)\n",
    "\n",
    "    \n",
    "# imprimir resultados\n",
    "print(\"RESULTADOS:\")\n",
    "for model_num in range(len(nn_train_mses)):\n",
    "    print(\n",
    "        f\"Modelo {model_num+1}: MSE de treino: {nn_train_mses[model_num]:.2f}, \" +\n",
    "        f\"MSE de VC: {nn_cv_mses[model_num]:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos erros registrados, você pode decidir qual é o melhor modelo para o sua aplicação. Observe os resultados acima e veja se você concorda com o `model_num` selecionado abaixo. Por fim, você calculará o erro de teste para estimar o grau de generalização para novos exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecione o modelo com o menor CV MSE\n",
    "model_num = 3\n",
    "\n",
    "# Calcule o MSE de teste\n",
    "yhat = nn_models[model_num-1].predict(X_test_mapped_scaled)\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"Modelo Selecionado: {model_num}\")\n",
    "print(f\"MSE de treino: {nn_train_mses[model_num-1]:.2f}\")\n",
    "print(f\"MSE de validação cruzada: {nn_cv_mses[model_num-1]:.2f}\")\n",
    "print(f\"MSE de teste: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "\n",
    "Nesta última parte do laboratório, você praticará a avaliação e a seleção de modelos em uma tarefa de classificação. O processo será semelhante, com a principal diferença sendo o cálculo dos erros. Você verá isso nas seções a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar o conjunto de dados\n",
    "\n",
    "Primeiro, você carregará um conjunto de dados para uma tarefa de classificação binária. Ele tem 200 exemplos de dois recursos de entrada (`x1` e `x2`) e um alvo `y` de `0` ou `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados de um arquivo de texto\n",
    "data = np.loadtxt('./data/data_w3_ex2.csv', delimiter=',')\n",
    "\n",
    "# Dividir as entradas e saídas em matrizes separadas\n",
    "x_bc = data[:,:-1]\n",
    "y_bc = data[:,-1]\n",
    "\n",
    "# Converta y em 2-D porque os comandos posteriores exigirão isso (x já é 2-D)\n",
    "y_bc = np.expand_dims(y_bc, axis=1)\n",
    "\n",
    "print(f\"o formato das entradas x é: {x_bc.shape}\")\n",
    "print(f\" formato dos alvos y é: {y_bc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode plotar o conjunto de dados para examinar como os exemplos são separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_bc_dataset(x=x_bc, y=y_bc, title=\"x1 vs. x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir e preparar o conjunto de dados\n",
    "\n",
    "Em seguida, você gerará os conjuntos de treinamento, validação cruzada e teste. Você usará as mesmas proporções 60/20/20 de antes. Você também dimensionará os recursos como fez na seção anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Obtenha 60% do conjunto de dados como o conjunto de treinamento.\n",
    "# Coloque os 40% restantes em variáveis temporárias.\n",
    "x_bc_train, x_, y_bc_train, y_ = train_test_split(x_bc, y_bc, test_size=0.40, random_state=1)\n",
    "\n",
    "# Dividir o subconjunto de 40% acima em dois: uma metade para validação cruzada e a outra para o conjunto de teste\n",
    "x_bc_cv, x_bc_test, y_bc_cv, y_bc_test = train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# Excluir variáveis temporárias\n",
    "del x_, y_\n",
    "\n",
    "print(f\"o formato do conjunto de treinamento (entrada) é: {x_bc_train.shape}\")\n",
    "print(f\"o formato do conjunto de treinamento (alvo) é: {y_bc_train.shape}\\n\")\n",
    "print(f\"o formato do conjunto de validação cruzada (entrada) é: {x_bc_cv.shape}\")\n",
    "print(f\"o formato do conjunto de validação cruzada (alvo) é: {y_bc_cv.shape}\\n\")\n",
    "print(f\"o formato do conjunto de teste (entrada) é: {x_bc_test.shape}\")\n",
    "print(f\"o formato do conjunto de teste (alvo) é: {y_bc_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar os recursos\n",
    "\n",
    "# Inicializar a classe\n",
    "scaler_linear = StandardScaler()\n",
    "\n",
    "# Calcule a média e o desvio padrão do conjunto de treinamento e, em seguida, transforme-o\n",
    "x_bc_train_scaled = scaler_linear.fit_transform(x_bc_train)\n",
    "x_bc_cv_scaled = scaler_linear.transform(x_bc_cv)\n",
    "x_bc_test_scaled = scaler_linear.transform(x_bc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o erro dos modelos de classificação\n",
    "\n",
    "Nas seções anteriores sobre modelos de regressão, você usou o erro quadrático médio para medir o desempenho do seu modelo. Para classificação, você pode obter uma métrica semelhante obtendo a fração dos dados que o modelo classificou incorretamente. Por exemplo, se o seu modelo fez previsões erradas para 2 amostras de 5, você informará um erro de `40%` ou `0,4`. O código abaixo demonstra isso usando um loop for e também com a função [`mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) do Numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saída do modelo de amostra\n",
    "probabilities = np.array([0.2, 0.6, 0.7, 0.3, 0.8])\n",
    "\n",
    "# Aplique um limite à saída do modelo. Se for maior que 0,5, defina como 1. Caso contrário, 0.\n",
    "predictions = np.where(probabilities >= 0.5, 1, 0)\n",
    "\n",
    "# Rótulos de alvo (ground-truth)\n",
    "ground_truth = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "# Inicializar o contador de dados com classificação incorreta\n",
    "misclassified = 0\n",
    "\n",
    "# Obter o número de previsões\n",
    "num_predictions = len(predictions)\n",
    "\n",
    "# Fazer um loop em cada previsão\n",
    "for i in range(num_predictions):\n",
    "    \n",
    "    # Verificar se corresponde ao ground-truth\n",
    "    if predictions[i] != ground_truth[i]:\n",
    "        \n",
    "        # Adicione um ao contador se a previsão estiver errada\n",
    "        misclassified += 1\n",
    "\n",
    "# Calcule a fração dos dados que o modelo classificou incorretamente\n",
    "fraction_error = misclassified/num_predictions\n",
    "\n",
    "print(f\"probabilidades: {probabilities}\")\n",
    "print(f\"predições com limiar=0.5: {predictions}\")\n",
    "print(f\"alvos: {ground_truth}\")\n",
    "print(f\"fração de dados com classificação incorreta (loop-for): {fraction_error}\")\n",
    "print(f\"fração de dados com classificação incorreta (com np.mean()): {np.mean(predictions != ground_truth)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir e treinar o modelo\n",
    "\n",
    "Você usará as mesmas arquiteturas de rede neural da seção anterior, portanto, poderá chamar a função `build_models()` novamente para criar novas instâncias desses modelos. \n",
    "\n",
    "Você seguirá a abordagem recomendada mencionada na semana passada, em que usa uma ativação `linear` para a camada de saída (em vez de `sigmoid`) e define `from_logits=True` ao declarar a função de perda do modelo. Você usará a [binary crossentropy loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) porque esse é um problema de classificação binária.\n",
    "\n",
    "Após o treinamento, você usará uma [sigmoid function](https://www.tensorflow.org/api_docs/python/tf/math/sigmoid) para converter os resultados do modelo em probabilidades. A partir daí, você pode definir um limite e obter a fração de exemplos com classificação incorreta dos conjuntos de treinamento e validação cruzada.\n",
    "\n",
    "Você pode ver tudo isso na célula de código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar as listas que conterão os erros de cada modelo\n",
    "nn_train_error = []\n",
    "nn_cv_error = []\n",
    "\n",
    "# Criar os modelos\n",
    "models_bc = utils.build_models()\n",
    "\n",
    "# Fazer um loop em cada modelo\n",
    "for model in models_bc:\n",
    "    \n",
    "    # Configurar a perda e o otimizador\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    )\n",
    "\n",
    "    print(f\"Treinando {model.name}...\")\n",
    "\n",
    "    # Treinar o modelo\n",
    "    model.fit(\n",
    "        x_bc_train_scaled, y_bc_train,\n",
    "        epochs=200,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Done!\\n\")\n",
    "    \n",
    "    # Definir o limite para classificação\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Registre a fração de exemplos com classificação incorreta para o conjunto de treinamento\n",
    "    yhat = model.predict(x_bc_train_scaled)\n",
    "    yhat = tf.math.sigmoid(yhat)\n",
    "    yhat = np.where(yhat >= threshold, 1, 0)\n",
    "    train_error = np.mean(yhat != y_bc_train)\n",
    "    nn_train_error.append(train_error)\n",
    "\n",
    "    # Registre a fração de exemplos com classificação incorreta para o conjunto de validação cruzada\n",
    "    yhat = model.predict(x_bc_cv_scaled)\n",
    "    yhat = tf.math.sigmoid(yhat)\n",
    "    yhat = np.where(yhat >= threshold, 1, 0)\n",
    "    cv_error = np.mean(yhat != y_bc_cv)\n",
    "    nn_cv_error.append(cv_error)\n",
    "\n",
    "# Imprimir o resultado\n",
    "for model_num in range(len(nn_train_error)):\n",
    "    print(\n",
    "        f\"Modelo {model_num+1}: Erro de classificação do conjunto de treinamento: {nn_train_error[model_num]:.5f}, \" +\n",
    "        f\"Erro de classificação do conjunto VC: {nn_cv_error[model_num]:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no resultado acima, você pode escolher qual deles teve o melhor desempenho. Se houver um empate no erro do conjunto de validação cruzada, você poderá adicionar outro critério para desempatar. Por exemplo, você pode escolher o que tiver um erro de treinamento menor. Uma abordagem mais comum é escolher o modelo menor porque ele economiza recursos computacionais. Em nosso exemplo, o Modelo 1 é o menor e o Modelo 3 é o maior.\n",
    "\n",
    "Por fim, você pode calcular o erro de teste para informar o erro de generalização do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecione o modelo com o menor erro\n",
    "model_num = 3\n",
    "\n",
    "# Calcular o erro de teste\n",
    "yhat = models_bc[model_num-1].predict(x_bc_test_scaled)\n",
    "yhat = tf.math.sigmoid(yhat)\n",
    "yhat = np.where(yhat >= threshold, 1, 0)\n",
    "nn_test_error = np.mean(yhat != y_bc_test)\n",
    "\n",
    "print(f\"Modelo Selecionado: {model_num}\")\n",
    "print(f\"Erro de classificação do conjunto de treinamento: {nn_train_error[model_num-1]:.4f}\")\n",
    "print(f\"Erro de classificação do conjunto VC: {nn_cv_error[model_num-1]:.4f}\")\n",
    "print(f\"Erro de classificação do conjunto de teste: {nn_test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparâmetros com o [painel HParams](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Neste laboratório, você praticou a avaliação do desempenho de um modelo e a escolha entre diferentes configurações de modelos. Você dividiu seus conjuntos de dados em conjuntos de treinamento, validação cruzada e teste e viu como cada um deles é usado em aplicativos de aprendizado de máquina. Na próxima seção do curso, você verá mais dicas sobre como aprimorar seus modelos diagnosticando o viés e a variação. Continue assim!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
