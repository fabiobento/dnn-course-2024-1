{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3c5fa5",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37db419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_02/Laborat%C3%B3rios/lab_utils_ml_adv_add_week_2\n",
    "      \n",
    "!unzip -n -q lab_utils_ml_adv_add_week_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "# Necessário para ativar widgets\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagação Posterior com Grafo Computacional (_Back Propagation_)\n",
    "Ao trabalhar neste laboratório, você terá uma visão geral de um algoritmo importante usado pela maioria dos _frameworks_ de aprendizado de máquina.\n",
    "\n",
    "A descida de gradiente requer a derivada do custo em relação a cada parâmetro da rede. As redes neurais podem ter milhões ou até bilhões de parâmetros. O algoritmo de *back propagation* é usado para calcular essas derivadas. *Os grafos computacionais são usados para simplificar a operação. Vamos nos aprofundar nisso a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e92660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import TextBox\n",
    "from matplotlib.widgets import Button\n",
    "import ipywidgets as widgets\n",
    "from lab_utils_backprop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafo Computacional\n",
    "Um grafo computacional simplifica o cálculo de derivadas complexas, dividindo-as em etapas menores. Vamos ver como isso funciona.\n",
    "\n",
    "Vamos calcular a derivada dessa expressão ligeiramente complexa, $J = (2+3w)^2$. Gostaríamos de encontrar a derivada de $J$ com relação a $w$ ou $\\frac{\\partial J}{\\partial w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt_network(config_nw0, \"./images/C2_W2_BP_network0.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, você pode ver que dividimos a expressão em dois nós, nos quais podemos trabalhar de forma independente. Se você já tem um bom entendimento do processo da aula, pode ir em frente e preencher as caixas no diagrama acima.\n",
    "\n",
    "Primeiro, preencha as caixas azuis da esquerda para a direita e, em seguida, preencha as caixas verdes, começando à direita e indo para a esquerda.\n",
    "\n",
    "Se você tiver os valores corretos, eles serão exibidos como verde ou azul. Se o valor estiver incorreto, ele será vermelho. Observe que o gráfico interativo não é particularmente robusto. Se você tiver problemas com a interface, execute a célula acima novamente para reiniciar.\n",
    "\n",
    "Se você não tiver certeza do processo, trabalharemos nesse exemplo passo a passo a seguir.\n",
    "\n",
    "### Propagação direta   \n",
    "Vamos calcular os valores na propagação direta (_forward propagation_).\n",
    "\n",
    ">Apenas uma observação sobre esta seção. Ela usa variáveis globais e as reutiliza à medida que o cálculo avança. Se você executar as células fora de ordem, poderá obter resultados estranhos. Se isso acontecer, volte a este ponto e execute-as em ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3\n",
    "a = 2+3*w\n",
    "J = a**2\n",
    "print(f\"a = {a}, J = {J}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode preencher esses valores nas caixas azuis acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _Backprop_\n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network0_j.PNG\" style=\" width:100px; padding: 10px 20px; \" > _Backprop_ é o algoritmo que usamos para calcular as derivadas. Conforme descrito nas aulas, o _backprop_ começa à direita e se move para a esquerda. O primeiro nó a ser considerado é $J = a^2 $ e a primeira etapa é encontrar $\\frac{\\partial J}{\\partial a}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial J}{\\partial a}$ \n",
    "#### Aritmeticamente\n",
    "Encontre $\\frac{\\partial J}{\\partial a}$ descobrindo como $J$ muda como resultado de uma pequena mudança em $a$. Isso é descrito em detalhes no laboratório de derivadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2664f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_epsilon = a + 0.001  # a mais um pequeno valor, epsilon\n",
    "J_epsilon = a_epsilon**2\n",
    "k = (J_epsilon - J)/0.001   # diferença dividida por epsilon\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_da ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial J}{\\partial a}$ é 22, que é $2\\times a$. Nosso resultado não é exatamente $2 \\times a$ porque nosso valor de epsilon não é infinitesimalmente pequeno. \n",
    "#### Simbolicamente\n",
    "Agora, vamos usar o SymPy para calcular as derivadas simbolicamente, como fizemos no laboratório sobre derivadas. Vamos prefixar o nome da variável com um \"s\" para indicar que se trata de uma variável *simbólica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b60436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw,sJ,sa = symbols('w,J,a')\n",
    "sJ = sa**2\n",
    "sJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d663db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sJ.subs([(sa,a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_da = diff(sJ, sa)\n",
    "dJ_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, $\\frac{\\partial J}{\\partial a} = 2a$. Quando $a=11$, $\\frac{\\partial J}{\\partial a} = 22$. Isso corresponde ao nosso cálculo aritmético acima.\n",
    "Se ainda não tiver feito isso, você pode voltar ao diagrama acima e preencher o valor de $\\frac{\\partial J}{\\partial a}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $\\frac{\\partial J}{\\partial w}$ \n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network0_a.PNG\"     style=\" width:100px; padding: 10px 20px; \" >\n",
    "\n",
    " Indo da direita para a esquerda, o próximo valor que gostaríamos de calcular é $\\frac{\\partial J}{\\partial w}$. Para fazer isso, primeiro precisamos calcular $\\frac{\\partial a}{\\partial w}$, que descreve como a saída desse nó, $a$, muda quando a entrada $w$ muda um pouco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aritmeticamente\n",
    "Encontre $\\frac{\\partial a}{\\partial w}$ descobrindo como $a$ muda como resultado de uma pequena mudança em $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_epsilon = w + 0.001       # a mais um pequeno valor, epsilon\n",
    "a_epsilon = 2 + 3*w_epsilon\n",
    "k = (a_epsilon - a)/0.001   # diferença dividida por epsilon\n",
    "print(f\"a = {a}, a_epsilon = {a_epsilon}, da_dw ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6ab69",
   "metadata": {},
   "source": [
    "Calculado aritmeticamente, $\\frac{\\partial a}{\\partial w} \\approx 3$. Vamos tentar isso com o SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4cf55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sa = 2 + 3*sw\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dw = diff(sa,sw)\n",
    "da_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d873c",
   "metadata": {},
   "source": [
    ">A próxima etapa é a parte interessante:\n",
    "> - Sabemos que uma pequena mudança em $w$ fará com que $a$ mude 3 vezes esse valor.\n",
    "> - Sabemos que uma pequena mudança em $a$ fará com que $J$ mude em $2\\times a$ vezes esse valor. (a=11 neste exemplo)    \n",
    " Então, juntando tudo isso, \n",
    "> Sabemos que uma pequena mudança em $w$ fará com que $J$ mude em $3 \\times 2\\times a$ vezes esse valor.\n",
    "> \n",
    "> Essas alterações em cascata têm o nome de *regra da cadeia*.  Ela pode ser escrita da seguinte forma: \n",
    " $$\\frac{\\partial J}{\\partial w} = \\frac{\\partial a}{\\partial w} \\frac{\\partial J}{\\partial a} $$\n",
    " \n",
    "Se não estiver claro, vale a pena pensar um pouco sobre isso. Essa é a principal conclusão.\n",
    " \n",
    " Vamos tentar calculá-la:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_dw = da_dw * dJ_da\n",
    "dJ_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13b082",
   "metadata": {},
   "source": [
    "E $a$ é 11 neste exemplo, portanto $\\frac{\\partial J}{\\partial w} = 66$. Podemos verificar isso aritmeticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b342530",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_epsilon = w + 0.001\n",
    "a_epsilon = 2 + 3*w_epsilon\n",
    "J_epsilon = a_epsilon**2\n",
    "k = (J_epsilon - J)/0.001   # diferença dividida por epsilon\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee4f7f",
   "metadata": {},
   "source": [
    "OK! Agora você pode preencher os valores de $\\frac{\\partial a}{\\partial w}$ e $\\frac{\\partial J}{\\partial w}$ no diagrama, caso ainda não o tenha feito. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7f72b",
   "metadata": {},
   "source": [
    "**Outra visão**  \n",
    "É possível visualizar essas mudanças em cascata da seguinte forma:  \n",
    "\n",
    "<img align=\"center\" src=\"./images/C2_W2_BP_network0_diff.PNG\"  style=\" width:500px; padding: 10px 20px; \" >  \n",
    "\n",
    "Uma pequena alteração em $w$ é multiplicada por $\\frac{\\partial a}{\\partial w}$, resultando em uma alteração que é 3 vezes maior. Essa alteração maior é então multiplicada por $\\frac{\\partial J}{\\partial a}$, resultando em uma alteração que agora é $3 \\times 22 = 66$ vezes maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1fb1b",
   "metadata": {},
   "source": [
    "## Gráfico Computacional de uma Rede Neural Simples\n",
    "Abaixo está um gráfico da rede neural usada na aula com valores diferentes. Tente preencher os valores nas caixas. Observe que o gráfico interativo não é particularmente robusto. Se você tiver problemas com a interface, execute a célula abaixo novamente para reiniciar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c132f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt_network(config_nw1, \"./images/C2_W2_BP_network1.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0e07c",
   "metadata": {},
   "source": [
    "A seguir, analisaremos detalhadamente os cálculos necessários para preencher o grafo computacional acima. Começaremos com o caminho para direto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad128d1",
   "metadata": {},
   "source": [
    "### Propagação direta(_Forward propagation_)\n",
    "Os cálculos na Propagação direta são os que você aprendeu recentemente para redes neurais. Você pode comparar os valores abaixo com aqueles que calculou para o diagrama acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular valores por etapa \n",
    "x = 2\n",
    "w = -2\n",
    "b = 8\n",
    "y = 1\n",
    "  \n",
    "c = w * x\n",
    "a = c + b\n",
    "d = a - y\n",
    "J = d**2/2\n",
    "print(f\"J={J}, d={d}, a={a}, c={c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5421ee",
   "metadata": {},
   "source": [
    "### _Backward propagation_ (Backprop)\n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network1_jdsq.PNG\"     style=\" width:100px; padding: 10px 20px; \" >\n",
    "\n",
    "Conforme descrito nas aulas, o backprop começa à direita e se move para a esquerda. O primeiro nó a ser considerado é $J = \\frac{1}{2}d^2 $ e a primeira etapa é encontrar $\\frac{\\partial J}{\\partial d}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e51c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $\\frac{\\partial J}{\\partial d}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c70c0",
   "metadata": {},
   "source": [
    "#### Aritmeticamente\n",
    "Encontre $\\frac{\\partial J}{\\partial d}$ descobrindo como $J$ muda como resultado de uma pequena mudança em $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_epsilon = d + 0.001\n",
    "J_epsilon = d_epsilon**2/2\n",
    "k = (J_epsilon - J)/0.001   # diferença dividida por epsilon\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dd ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3754c9",
   "metadata": {},
   "source": [
    "$\\frac{\\partial J}{\\partial d}$ é 3, que é o valor de $d$. Nosso resultado não é exatamente $d$ porque nosso valor de epsilon não é infinitesimalmente pequeno. \n",
    "#### Simbolicamente\n",
    "Agora, vamos usar o SymPy para calcular as derivadas simbolicamente, como fizemos no laboratório opcional de derivadas.\n",
    "O prefixo do nome da variável com um \"s\" indicará que se trata de uma variável *simbólica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c35a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sx,sw,sb,sy,sJ = symbols('x,w,b,y,J')\n",
    "sa, sc, sd = symbols('a,c,d')\n",
    "sJ = sd**2/2\n",
    "sJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119a751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sJ.subs([(sd,d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_dd = diff(sJ, sd)\n",
    "dJ_dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce7b0c",
   "metadata": {},
   "source": [
    "Portanto, $\\frac{\\partial J}{\\partial d}$ = d. Quando $d=3$, $\\frac{\\partial J}{\\partial d}$ = 3. Isso corresponde ao nosso cálculo aritmético acima.\n",
    "Se ainda não tiver feito isso, você pode voltar ao diagrama acima e preencher o valor de $\\frac{\\partial J}{\\partial d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667caed8",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial J}{\\partial a}$ \n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network1_d.PNG\"     style=\" width:100px; padding: 10px 20px; \" >\n",
    "\n",
    "Indo da direita para a esquerda, o próximo valor que gostaríamos de calcular é $\\frac{\\partial J}{\\partial a}$.\n",
    "\n",
    "Para fazer isso, primeiro precisamos calcular $\\frac{\\partial d}{\\partial a}$, que descreve como a saída desse nó muda quando a entrada $a$ muda um pouco. (Observe que não estamos interessados em como a saída muda quando $y$ muda, pois $y$ não é um parâmetro)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f85b8f",
   "metadata": {},
   "source": [
    "#### Aritmeticamente\n",
    "Encontre $\\frac{\\partial d}{\\partial a}$ descobrindo como $d$ muda como resultado de uma pequena mudança em $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_epsilon = a + 0.001         #a mais um pequeno valor\n",
    "d_epsilon = a_epsilon - y\n",
    "k = (d_epsilon - d)/0.001   # diferença dividida por epsilon\n",
    "print(f\"d = {d}, d_epsilon = {d_epsilon}, dd_da ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2232ca",
   "metadata": {},
   "source": [
    "Calculado aritmeticamente, $\\frac{\\partial d}{\\partial a} \\approx 1$. Vamos tentar isso com o SymPy.\n",
    "#### Simbolicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e76eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sd = sa - sy\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bfd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_da = diff(sd,sa)\n",
    "dd_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324b720",
   "metadata": {},
   "source": [
    "Calculado aritmeticamente, $\\frac{\\partial d}{\\partial a}$ também é igual a 1.  \n",
    ">A próxima etapa é a parte interessante, repetida novamente neste exemplo:\n",
    "> - Sabemos que uma pequena alteração em $a$ fará com que $d$ seja alterado em 1 vez esse valor.\n",
    "> - Sabemos que uma pequena mudança em $d$ fará com que $J$ mude em $d$ vezes esse valor. (d=3 neste exemplo)    \n",
    " Então, juntando tudo isso, \n",
    "> Sabemos que uma pequena mudança em $a$ fará com que $J$ mude em $1\\times d$ vezes esse valor.\n",
    "> \n",
    ">Isso é novamente a *regra da cadeia*.  Ela pode ser escrita da seguinte forma: \n",
    " $$\\frac{\\partial J}{\\partial a} = \\frac{\\partial d}{\\partial a} \\frac{\\partial J}{\\partial d} $$\n",
    " \n",
    " Vamos tentar calcular isso:\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c01beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_da = dd_da * dJ_dd\n",
    "dJ_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c28be",
   "metadata": {},
   "source": [
    "E $d$ é 3 neste exemplo, portanto $\\frac{\\partial J}{\\partial a} = 3$. Podemos verificar isso aritmeticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_epsilon = a + 0.001\n",
    "d_epsilon = a_epsilon - y\n",
    "J_epsilon = d_epsilon**2/2\n",
    "k = (J_epsilon - J)/0.001   \n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_da ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066fdeb",
   "metadata": {},
   "source": [
    "OK, eles coincidem! Agora você pode preencher os valores de $\\frac{\\partial d}{\\partial a}$ e $\\frac{\\partial J}{\\partial a}$ no diagrama, caso ainda não o tenha feito. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6531de",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **As etapas do backprop**   \n",
    ">Agora que você já trabalhou com vários nós, podemos escrever o método básico:\\\n",
    "> Trabalhando da direita para a esquerda, para cada nó:\n",
    ">- calcular a(s) derivada(s) local(is) do nó\n",
    ">- usando a regra da cadeia, combine com a derivada do custo com relação ao nó à direita.   \n",
    "\n",
    "A(s) \"derivada(s) local(is)\" é(são) a(s) derivada(s) da saída do nó atual com relação a todas as entradas ou parâmetros.\n",
    "\n",
    "Vamos continuar o trabalho. Seremos um pouco menos prolixos agora que você está familiarizado com o método."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1872ad8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $\\frac{\\partial J}{\\partial c}$,  $\\frac{\\partial J}{\\partial b}$\n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network1_a.PNG\"     style=\" width:100px; padding: 10px 20px; \" >\n",
    "\n",
    "O próximo nó tem duas derivadas de interesse. Precisamos calcular $\\frac{\\partial J}{\\partial c}$ para que possamos nos propagar para a esquerda. Também queremos calcular $\\frac{\\partial J}{\\partial b}$.\n",
    "\n",
    "Encontrar a derivada do custo com relação aos parâmetros $w$ e $b$ é o objetivo do backprop. Encontraremos as derivadas locais, $\\frac{\\partial a}{\\partial c}$ e $\\frac{\\partial a}{\\partial b}$ primeiro e, em seguida, combinaremos essas derivadas com a derivada vinda da direita, $\\frac{\\partial J}{\\partial a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular as derivadas locais da_dc, da_db\n",
    "sa = sc + sb\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402facd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dc = diff(sa,sc)\n",
    "da_db = diff(sa,sb)\n",
    "print(da_dc, da_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc26d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_dc = da_dc * dJ_da\n",
    "dJ_db = da_db * dJ_da\n",
    "print(f\"dJ_dc = {dJ_dc},  dJ_db = {dJ_db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7dfea",
   "metadata": {},
   "source": [
    "E, em nosso exemplo, d = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7e87e",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  $\\frac{\\partial J}{\\partial w}$\n",
    "<img align=\"left\" src=\"./images/C2_W2_BP_network1_c.PNG\"     style=\" width:100px; padding: 10px 20px; \" >\n",
    "\n",
    "O último nó deste exemplo calcula `c`. Aqui, estamos interessados em como J muda em relação ao parâmetro w. Não faremos a retropropagação para a entrada $x$, portanto, não estamos interessados em $\\frac{\\partial J}{\\partial x}$. Vamos começar calculando $\\frac{\\partial c}{\\partial w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6efdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular a derivada local\n",
    "sc = sw * sx\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ab287",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dw = diff(sc,sw)\n",
    "dc_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b47f1",
   "metadata": {},
   "source": [
    "Essa derivada é um pouco mais interessante do que a anterior. Ela varia de acordo com o valor de $x$. Em nosso exemplo, esse valor é 2.\n",
    "\n",
    "Combine isso com $\\frac{\\partial J}{\\partial c}$ para encontrar $\\frac{\\partial J}{\\partial w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a312f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_dw = dc_dw * dJ_dc\n",
    "dJ_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dJ_dw = {dJ_dw.subs([(sd,d),(sx,x)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b3e11",
   "metadata": {},
   "source": [
    "$d=3$, portanto $\\frac{\\partial J}{\\partial w} = 6$ para o nosso exemplo.   \n",
    "Vamos testar isso aritmeticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d822d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_epsilon = ((w+0.001)*x+b - y)**2/2\n",
    "k = (J_epsilon - J)/0.001  \n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eles combinam! Ótimo. Você pode adicionar $\\frac{\\partial J}{\\partial w}$ ao diagrama acima e nossa análise estará completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c72da7",
   "metadata": {},
   "source": [
    "## Parabéns!\n",
    "Você trabalhou em um exemplo de retropropagação usando um grafo computacional. Você pode aplicar isso a exemplos maiores seguindo a mesma abordagem nó a nó. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
