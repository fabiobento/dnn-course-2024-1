O gradiente descendente é um algoritmo de otimização amplamente usado no aprendizado de máquina e foi a base de muitos algoritmos, como regressão linear e regressão logística, além de implementações iniciais de redes neurais. Mas acontece que agora existem alguns outros algoritmos de otimização para minimizar a função de custo, que são ainda melhores do que o gradiente descendente. Neste vídeo, vamos dar uma olhada em um algoritmo que pode ajudar você a treinar sua rede neural muito mais rápido do que o gradiente descendente. Lembre-se de que essa é a expressão para uma etapa da descida do gradiente.
Reproduza o vídeo começando em ::42 e siga a transcrição0:42
Um parâmetro w_j é atualizado como w_j menos a taxa de aprendizado Alfa vezes esse termo derivado parcial. Como podemos tornar esse trabalho ainda melhor? Neste exemplo, tracei a função de custo J usando um gráfico de contorno que compreende essas elipses, e o mínimo dessa função de custo está no centro dessa elipse aqui embaixo. Agora, se você começasse a descida de gradiente aqui embaixo, um degrau de descida de gradiente, se Alpha for pequeno, pode levá-lo um pouco nessa direção. Depois, outra etapa, depois outra etapa, depois outra etapa, depois outra etapa, e você percebe que cada etapa do gradiente descendente está praticamente indo na mesma direção, e se você perceber que esse é o caso, você pode se perguntar, bem, por que não aumentamos o Alpha, podemos ter um algoritmo para aumentar automaticamente o Alpha? Eles apenas fazem com que ele dê passos maiores e chegue ao mínimo mais rápido. Há um algoritmo chamado algoritmo Adam que pode fazer isso. Se ele perceber que a taxa de aprendizado é muito pequena e estamos apenas dando pequenos passos em uma direção semelhante repetidamente, devemos aumentar a taxa de aprendizado Alpha. Em contraste, aqui, novamente, está a mesma função de custo. Se estivéssemos começando aqui e tivéssemos uma taxa de aprendizado relativamente grande, Alpha, então talvez uma etapa de gradiente descendente nos leve até aqui, na terceira etapa e na quarta etapa, e na quinta etapa e na sexta etapa, e se você ver a descida de gradiente fazendo isso, está oscilando para frente e para trás. Você ficaria tentado a dizer, bem, por que não diminuímos as taxas de aprendizado? O algoritmo Adam também pode fazer isso automaticamente e, com uma taxa de aprendizado menor, você pode seguir um caminho mais suave em direção ao mínimo da função de custo. Dependendo de como a descida do gradiente está ocorrendo, às vezes você gostaria de ter uma taxa de aprendizado Alpha maior, e às vezes você gostaria de ter uma taxa de aprendizado Alpha menor. O algoritmo Adam pode ajustar a taxa de aprendizado automaticamente. Adam significa Adaptive Moment Estimation, ou A-D-A-M, e não se preocupe muito com o significado desse nome, é exatamente como os autores chamaram esse algoritmo. Mas, curiosamente, o algoritmo Adam não usa uma única taxa de aprendizado global Alpha. Ele usa taxas de aprendizado diferentes para cada parâmetro do seu modelo.
Reproduza o vídeo começando em :3:18 e siga a transcrição3:18
Se você tem parâmetros w_1 a w_10, como era b, então ele realmente tem 11 parâmetros de taxa de aprendizado, Alpha_1, Alpha_2, até Alpha_10 para w_1 a w_10, e eu vou chamá-lo de Alpha_11 para o parâmetro b. A intuição por trás do algoritmo Adam é que se um parâmetro w_j ou b parece continuar se movendo aproximadamente da mesma forma direção. Isso é o que vimos no primeiro exemplo do slide anterior. Mas se ele parece continuar se movendo aproximadamente na mesma direção, vamos aumentar a taxa de aprendizado desse parâmetro. Vamos mais rápido nessa direção. Por outro lado, se um parâmetro continuar oscilando para frente e para trás, isso é o que você viu no segundo exemplo no slide anterior. Então, não vamos deixar que ele continue oscilando ou saltando para frente e para trás. Vamos reduzir um pouco o alpha_J para esse parâmetro. Os detalhes de como Adam faz isso são um pouco complicados e estão além do escopo deste curso, mas se você fizer alguns cursos mais avançados de aprendizado profundo posteriormente, poderá aprender mais sobre os detalhes desse algoritmo de Adam, mas nos códigos é assim que você o implementa. O modelo é exatamente o mesmo de antes, e a maneira como você compila o modelo é muito semelhante à que tínhamos antes, exceto que agora adicionamos um argumento extra à função de compilação, ou seja, especificamos que o otimizador que você deseja usar é o otimizador tf.keras.optimizers.Adam. O algoritmo de otimização Adam precisa de alguma taxa de aprendizado inicial padrão Alpha e, neste exemplo, defini essa taxa de aprendizado inicial como 10 ^ menos 3. Mas quando você usa o algoritmo Adam na prática, vale a pena testar alguns valores para essa taxa de aprendizado global padrão. Experimente alguns valores grandes e outros menores para ver o que oferece o desempenho de aprendizado mais rápido. No
Reproduza o vídeo começando em :5:16 e siga a transcrição5:16
entanto, comparado ao algoritmo de gradiente descendente original que você aprendeu no curso anterior, o algoritmo Adam, por poder adaptar a taxa de aprendizado de forma um pouco automática, é mais robusto à escolha exata da taxa de aprendizado que você escolher. Embora ainda haja uma maneira de ajustar um pouco esse parâmetro para ver se você pode obter um aprendizado um pouco mais rápido. Isso é tudo para o algoritmo de otimização Adam. Normalmente funciona muito mais rápido do que o gradiente descendente e se tornou um padrão de fato na forma como os profissionais treinam suas redes neurais. Se você está tentando decidir qual algoritmo de aprendizado usar, qual algoritmo de otimização usar para treinar sua rede neural. Uma escolha segura seria usar apenas o algoritmo de otimização Adam, e a maioria dos profissionais de hoje usará o Adam em vez do algoritmo de descida de gradiente opcional e, com isso, espero que seus algoritmos de aprendizado possam aprender muito mais rapidamente. Agora, nos próximos vídeos, gostaria de abordar alguns conceitos mais avançados para redes neurais e, em particular, no próximo vídeo, vamos dar uma olhada em alguns tipos alternativos de camadas.
