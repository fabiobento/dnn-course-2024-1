Todas as camadas da rede neural que estão com você até agora foram do tipo de camada densa em que cada neurônio da camada recebe suas entradas, todas as ativações da camada anterior. E acontece que apenas usando o tipo de camada densa, você pode realmente criar alguns algoritmos de aprendizado bastante poderosos. E para ajudá-lo a criar mais intuição sobre o que as redes neurais podem fazer. Acontece que também existem outros tipos de camadas com outras propriedades. Neste vídeo, gostaria de abordar brevemente isso e dar um exemplo de um tipo diferente de camada de rede neural. Vamos recapitular a camada densa em que estamos usando a ativação de um neurônio, digamos que a segunda camada oculta seja uma função de cada valor de ativação da camada anterior de um. Mas acontece que, para alguns aplicativos, alguém que projeta uma rede neural pode optar por usar um tipo diferente de camada. Um outro tipo de camada que você pode ver em algum trabalho é chamado de camada convolucional. Deixe-me ilustrar isso com um exemplo. Então, o que estou mostrando à esquerda é a entrada X. Que é um dígito nove escrito à mão. E o que vou fazer é construir uma camada oculta que computará diferentes ativações como funções dessa imagem de entrada X. Mas aqui está algo que eu posso fazer com a primeira unidade oculta, que desenhei em azul em vez de dizer que esse neurônio pode ver todos os pixels nesta imagem. Eu poderia dizer que esse neurônio só pode olhar para os pixels nessa pequena região retangular. O segundo neurônio, que vou ilustrar em magenta, também não examinará toda a imagem de entrada X, mas apenas os pixels em uma região limitada da imagem. E assim por diante para o terceiro neurônio e o quarto neurônio e assim por diante. Até o último neurônio que pode estar olhando apenas para aquela região da imagem.
Reproduza o vídeo começando em :2:14 e siga a transcrição2:14
Então, por que você pode querer fazer isso? Por que você não deixa que cada neurônio veja todos os pixels, mas, em vez disso, veja apenas alguns deles? Bem, alguns dos benefícios são os primeiros: aceleram a computação. E a segunda vantagem é que uma rede neural que usa esse tipo de camada chamada camada convolucional pode precisar de menos dados de treinamento ou , alternativamente, também pode ser menos propensa a ajustes excessivos. Você me ouviu falar um pouco sobre sobreajuste no curso anterior, mas isso também será mais detalhado na próxima semana. Quando falamos sobre dicas práticas para usar algoritmos de aprendizado e esse é o tipo de camada em que cada neurônio olha apenas para uma região da imagem de entrada é chamada de camada convolucional. Foi o pesquisador John Macoun que descobriu muitos detalhes de como fazer as camadas convolucionais funcionarem e popularizou seu uso. Deixe-me ilustrar com mais detalhes uma camada convolucional. E se você tem várias camadas convolucionais em uma rede neural, às vezes isso é chamado de rede neural convolucional. Para ilustrar a camada convolucional da rede neural convolucional neste slide, vou usar em vez de uma entrada de imagem em dois D. Vou usar uma entrada unidimensional e o exemplo motivador que vou usar é a classificação de sinais E K G ou eletrocardiogramas. Portanto, se você colocar dois eletrodos no peito, registrará as voltagens parecidas com essa que correspondem ao seu batimento cardíaco. Na verdade, isso é algo sobre o qual meu grupo de pesquisa de Stanford pesquisou. Na verdade, estávamos lendo sinais de E K G que realmente se parecem com isso para tentar diagnosticar se os pacientes podem ter um problema cardíaco. Então, um sinal E K G e cardia eleitoral graham E C G em alguns lugares E K G. Em alguns lugares, há apenas uma lista de números correspondentes à altura da superfície em diferentes pontos no tempo. Portanto, você pode ter, digamos, 100 números correspondentes à altura dessa curva em 100 pontos de tempo diferentes. E o aprendizado dado nesta série temporal, dado esse sinal E K G para classificar, digamos se esse paciente tem uma doença cardíaca ou alguma doença cardíaca diagnosticável. Veja o que a rede neural convolucional pode fazer. Então, vou pegar o sinal E K G e girar 90 graus para colocá-lo de lado. E então temos aqui 100 entradas X uma X duas até X 100. Como. Então, quando eu construo a primeira camada oculta, em vez de ter a primeira unidade oculta, inserimos todos os 100 números. Deixe-me ter a primeira unidade escondida. Veja apenas X de um a X 20. Então, isso corresponde a olhar apenas para uma pequena janela desse sinal E K G.
Reproduza o vídeo começando em :5:21 e siga a transcrição5:21
A segunda unidade oculta é mostrada em uma cor diferente aqui. Bem, veja de X 11 a X 30, então olha para uma janela diferente neste sinal E K G. E a terceira oculta olha para outra janela X21 a X 40 e assim por diante. E as unidades ocultas finais neste exemplo.
Reproduza o vídeo começando em :5:40 e siga a transcrição5:40
Bem, veja de X 81 a X100. Portanto, parece uma pequena janela no final desta série temporal de ECG. Portanto, essa é uma camada convolucional porque essas unidades nessa camada examinam apenas uma janela limitada da entrada. Agora, essa camada da rede neural tem nove unidades. A próxima camada também pode ser uma camada convolucional.
Reproduza o vídeo começando em :6:8 e siga a transcrição6:08
Então, na segunda camada oculta, deixe-me arquitetar minha primeira unidade não para observar todas as nove ativações da camada anterior, mas para observar, digamos, apenas as 5 primeiras ativações da camada anterior. E então minha segunda unidade. Nesta segunda escondida, pode ver apenas mais cinco números, digamos A3-A7. E a terceira e última unidade oculta nessa camada verá apenas de A5 a A9. E então talvez finalmente essas ativações. A2 recebe entradas para uma unidade sigmóide que analisa todos esses três valores de A2 para fazer uma classificação binária em relação à presença ou ausência de doença cardíaca. Então, este é o exemplo de uma rede neural com a primeira camada oculta sendo uma camada convolucional. A segunda camada oculta também é uma camada convolucional e, em seguida, a camada de saída é uma camada sigmóide. E acontece que, com camadas convolucionais, você tem muitas opções de arquitetura , como o tamanho da janela de entradas que um único neurônio deve observar e quantos neurônios devem ter em uma camada. E ao escolher esses parâmetros arquitetônicos de forma eficaz, você pode criar novas versões de redes neurais que podem ser ainda mais eficazes do que a camada densa para alguns aplicativos. Recapitulando, isso é tudo para a camada convolucional e as redes neurais convolucionais. Não vou me aprofundar nas redes convolucionais nesta aula e você não precisa saber nada sobre elas para fazer a lição de casa e terminar esta aula com sucesso. Mas espero que você ache útil essa intuição adicional de que as redes neurais também podem ter outros tipos de camadas. E, de fato, se você às vezes ouve falar das mais recentes arquiteturas de ponta, como um modelo de transformador, um LS TM ou um modelo de atenção. Muitas dessas pesquisas em redes neurais até hoje dizem respeito a pesquisadores que tentam inventar novos tipos de camadas para redes neurais. E unir esses diferentes tipos de camadas como blocos de construção para formar redes neurais ainda mais complexas e, esperançosamente, mais poderosas. Então, isso é tudo para os vídeos necessários para esta semana. Obrigado e parabéns por ficar comigo durante todo o processo. E espero ver você na próxima semana, onde começaremos a falar sobre conselhos práticos sobre como você pode criar sistemas de aprendizado de máquina. Espero que as dicas que você aprenderá na próxima semana ajudem você a se tornar muito mais eficaz na criação de sistemas úteis de aprendizado de máquina. Então, também espero ver você na próxima semana.
