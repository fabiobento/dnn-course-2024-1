Bem-vindo de volta à segunda semana deste curso sobre algoritmos avançados de aprendizado. Na semana passada, você aprendeu como realizar inferências na rede neural. Nesta semana, vamos revisar o treinamento de uma rede neural. Acho que poder pegar seus próprios dados e treinar sua própria rede neural neles é muito divertido. Nesta semana, veremos como você pode fazer isso. Vamos mergulhar. Vamos continuar com nosso exemplo contínuo de reconhecimento de dígitos manuscrito reconhecendo essa imagem como zero ou um. Aqui estamos usando a arquitetura de rede neural que você viu na semana passada, onde você tem uma entrada X, que é a imagem, e então a primeira camada oculta tinha 25 unidades, a segunda camada oculta com 15 unidades e, em seguida, uma unidade de saída. Se você recebesse um conjunto de exemplos de treinamento contendo imagens X, assim como o rótulo de verdade fundamental Y, como você treinaria os parâmetros dessa rede neural? Deixe-me seguir em frente e mostrar o código que você pode usar no TensorFlow para treinar essa rede. Então, nos próximos vídeos posteriores, vamos nos aprofundar nos detalhes para explicar o que o código está realmente fazendo. Esse é um código que você escreve. Essa primeira parte pode parecer familiar da semana anterior, quando você estava pedindo ao TensorFlow que juntasse sequencialmente essas três camadas de uma rede neural. A primeira camada oculta com 25 unidades e ativação sigmóide, a segunda camada oculta e, finalmente, a camada de saída. Nada de novo aqui em relação ao que você viu na semana passada. A segunda etapa é pedir ao TensorFlow que compile o modelo. A etapa principal para pedir ao TensorFlow que compile o modelo é especificar qual é a função de perda que você deseja usar. Nesse caso, usaremos algo conhecido como função binária de perda de entropia cruzada. Veremos mais no próximo vídeo o que isso realmente é.
Reproduza o vídeo começando em :2:6 e siga a transcrição2:06
Depois de especificar a função de perda, a terceira etapa é chamar a função de ajuste, que diz ao TensorFlow que ajuste o modelo que você especificou na etapa 1 usando a perda da função de custo especificada na etapa 2 para o conjunto de dados X, Y. No primeiro curso, quando falamos sobre gradiente descendente, tivemos que decidir quantas etapas executar a descida de gradiente ou por quanto tempo executar a descida de gradiente, então épocas é um termo técnico para quantas etapas de um algoritmo de aprendizado, como gradiente descendente, você pode querer executar. É isso mesmo. A etapa 1 é especificar o modelo, que informa ao TensorFlow como calcular a inferência. A etapa 2 compila o modelo usando uma função de perda específica e a etapa 3 é treinar o modelo. É assim que você pode treinar uma rede neural no TensorFlow. Como sempre, espero que vocês não chamem essas linhas de código apenas para treinar o modelo, mas que também entendam o que realmente está acontecendo por trás dessas linhas de código, para que não as chamem sem realmente entender o que está acontecendo. Acho que isso é importante porque, quando você está executando um algoritmo de aprendizado, se ele não funcionar inicialmente, ter essa estrutura mental conceitual do que realmente está acontecendo o ajudará a depurar sempre que as coisas não funcionarem da maneira esperada. Com isso, vamos ao próximo vídeo, onde vamos nos aprofundar mais no que essas etapas na implementação do TensorFlow estão realmente fazendo. Nos vemos no próximo vídeo.
