Vamos dar uma olhada nos detalhes do que o código do TensorFlow para treinar uma rede neural está realmente fazendo. Vamos mergulhar. Antes de examinar os detalhes do treinamento em rede neural, vamos relembrar como você treinou um modelo de regressão logística no curso anterior. A primeira etapa da construção de um modelo de regressão logística era especificar como calcular a saída, considerando o recurso de entrada x e os parâmetros w e b. No primeiro curso, dissemos que a função de regressão logística prediz que f de x é igual a G. A função sigmóide aplicada a W. produto X mais B, que era a função sigmóide aplicada a W.X mais B. Se Z é o produto pontual de W de X mais B, então F de X é 1 sobre 1 mais e elevado a z negativo, então a primeira etapa foi especificar qual é a função de entrada para saída da logística regressão, e isso depende da entrada x e dos parâmetros do modelo.
Reproduza o vídeo começando em :1:15 e siga a transcrição1:15
A segunda etapa que tivemos que fazer para treinar o modelo de regressão de alfabetização foi especificar a função de perda e também a função de custo, então você deve se lembrar que a função de perda dizia que, se a regressão religiosa opus f de x e o rótulo de verdade fundamental, o rótulo real e um conjunto de treinamento eram y, então a perda naquele único exemplo de treinamento era negativa y log f de x menos um menos y vezes log de um menos f de x. Isso foi um medida de quão bem a regressão logística está se saindo em um único exemplo de treinamento x vírgula y. Dada esta definição de função de perda, então definimos a função de custo, e a função de custo era uma função dos parâmetros W e B, e essa era apenas a média que está tomando uma média geral de M exemplos de treinamento calculados nos exemplos de treinamento M, X1, Y1 a XMYM, e lembre-se de que, na convenção em que estamos usando, a função de perda é uma função da saída do algoritmo de aprendizado e do rótulo de verdade fundamental calculado em um único treinamento exemplo, enquanto a função de custo J é uma média da função de perda calculado em todo o seu conjunto de treinamento. Essa foi a segunda etapa do que fizemos ao construir a regressão logística.
Reproduza o vídeo começando em :2:49 e siga a transcrição2:49
Em seguida, a terceira e última etapa para treinar um modelo de regressão logística foi usar um algoritmo específico de gradiente descendente para minimizar a função de custo J de WB para minimizá-la em função dos parâmetros W e B. Minimizamos o custo J em função dos parâmetros usando gradiente descendente, onde W é atualizado como W menos a taxa de aprendizado alfa vezes a derivada de J em relação a W. E B também é atualizado como B menos a taxa de aprendizado alfa vezes a derivada de J em relação a B. Se essas três etapas. Na primeira etapa, especificando como calcular as saídas com base na entrada X e nos parâmetros, na etapa 2, especificar perdas e custos, e na terceira etapa, minimizar a função de custo, treinamos a regressão logística. As mesmas três etapas são como podemos treinar uma rede neural no TensorFlow. Agora, vamos ver como essas três etapas são mapeadas para treinar uma rede neural. Examinaremos isso com mais detalhes nos próximos três slides, mas de forma muito breve. A primeira etapa é especificar como calcular a saída, considerando a entrada x e os parâmetros W e B, que são feitos com esse trecho de código, que deve ser familiar à especificação da rede neural na semana passada. Na verdade, isso foi suficiente para especificar os cálculos necessários na propagação direta ou para o algoritmo de inferência, por exemplo. A segunda etapa é compilar o modelo e dizer qual perda você deseja usar, e aqui está o código que você usa para especificar essa função de perda, que é a função binária de perda de entropia cruzada, e uma vez que você especifica essa perda, a média de todo o conjunto de treinamento também fornece a função de custo para a rede neural , e a etapa três é chamar a função para tentar minimizar o custo em função dos parâmetros da rede neural. Vamos examinar com mais detalhes essas três etapas no contexto do treinamento de uma rede neural. A primeira etapa é especificar como calcular a saída, considerando a entrada x e os parâmetros w e b. Esse trecho de código especifica toda a arquitetura da rede neural. Informa que há 25 unidades ocultas na primeira camada oculta, depois 15 na próxima e, em seguida, uma unidade de saída e que estamos usando o valor de ativação sigmóide. Com base nesse trecho de código, sabemos também quais são os parâmetros w1, v1, passando pelos parâmetros da primeira camada da segunda camada e parâmetros da terceira camada. Esse trecho de código especifica toda a arquitetura da rede neural e, portanto, informa ao TensorFlow tudo o que ele precisa. Para calcular a saída a 3 ou f de x em função da entrada x e dos parâmetros, aqui escrevemos w l e b l. Vamos para a etapa 2. Na segunda etapa, você precisa especificar qual é a função de perda. Isso também definirá a função de custo que usamos para treinar a rede neural. Para o problema de classificação de dígitos manuscritos em que as imagens são de zero ou de um, de longe, a função de perda a ser usada é que esta é, na verdade, a mesma função de perda que a que tínhamos para regressão logística é negativa y log f de x menos 1 menos y vezes log 1 menos f de x, onde y é o rótulo de verdade fundamental, às vezes também chamado de rótulo alvo y, e f de x agora é a saída do neural rede. No TensorFlow, isso é chamado de função binária de perda de entropia cruzada. De onde vem esse nome? Bem, acontece que nas estatísticas essa função no topo é chamada de função de perda de entropia cruzada, então é isso que significa entropia cruzada, e a palavra binário apenas reenfatiza ou aponta que esse é um problema de classificação binária porque cada imagem é zero ou um. A sintaxe é pedir ao TensorFlow que compile a rede neural usando essa função de perda. Outra observação histórica: carers era originalmente uma biblioteca desenvolvida independentemente do TensorFlow e, na verdade, um projeto totalmente separado do TensorFlow. Mas, eventualmente, ele foi incorporado ao TensorFlow, e é por isso que temos tf.keras library.losses pontilhado no nome dessa função de perda. A propósito, nem sempre me lembro dos nomes de todas as funções de perda e do TensorFlow, mas eu mesmo faço uma rápida pesquisa na web para encontrar o nome certo e o insiro no meu código. Depois de especificar a perda em relação a um único exemplo de treinamento, o TensorFlow sabe que os custos que você deseja minimizar são então a média, considerando a média de todos os m exemplos de treinamento da perda em todos os exemplos de treinamento. A otimização dessa função de custo resultará no ajuste da rede neural aos seus dados de classificação binária. Caso você queira resolver um problema de regressão em vez de um problema de classificação. Você também pode pedir ao TensorFlow que compile seu modelo usando uma função de perda diferente. Por exemplo, se você tiver um problema de regressão e quiser minimizar a perda de erro quadrático. Aqui está a perda quadrática do erro. A perda em relação ao fato de seu algoritmo de aprendizado gerar f de x com um rótulo de verdade alvo ou fundamental de y é metade do erro quadrático. Em seguida, você pode usar essa função de perda no TensorFlow, que é usar a função de perda de erro quadrático médio, talvez mais intuitivamente chamada. Em seguida, o TensorFlow tentará minimizar o erro quadrático médio. Nessa expressão, estou usando j de capital w vírgula maiúscula b para denotar a função de custo. A função de custo é uma função de todos os parâmetros da rede neural. Você pode pensar em W maiúsculo como incluindo W1, W2, W3. Todos os parâmetros W e toda a nova rede podem incluir b1, b2 e b3. Se você está otimizando a função de custo em relação a w e b, se tentássemos otimizá-la em relação a todos os parâmetros na rede neural. Além disso, eu escrevi f de x como a saída da rede neural, mas também podemos escrever f de w b se quisermos enfatizar que a saída da rede neural em função de x depende de todos os parâmetros em todas as camadas da rede neural. Essa é a função de perda e a função de custo. Por fim, você solicitará ao TensorFlow que minimize a função cruzada. Talvez você se lembre do algoritmo de gradiente descendente do primeiro curso. Se você estiver usando gradiente descendente para treinar os parâmetros de uma rede neural, então, repetidamente, para cada camada l e para cada unidade j, atualize wlj de acordo com wlj menos a taxa de aprendizado alfa vezes a derivada parcial em relação a esse parâmetro da função de custo j de wb e da mesma forma para os parâmetros b. Depois de fazer, digamos, 100 iterações de gradiente descendente, espero que você obtenha um bom valor dos parâmetros. Para usar o gradiente descendente, a principal coisa que você precisa calcular são esses termos derivados parciais. O que o TensorFlow faz e, de fato, o que é padrão no treinamento de redes neurais, é usar um algoritmo chamado retropropagação para calcular esses termos derivados parciais. O TensorFlow pode fazer todas essas coisas por você. Ele implementa a retropropagação dentro dessa função chamada fit. Tudo o que você precisa fazer é chamar model.fit, x, y como seu conjunto de treinamento e pedir que ele faça isso por 100 iterações ou 100 épocas. Na verdade, o que você verá mais tarde é que o TensorFlow pode usar um algoritmo que é até um pouco mais rápido do que o gradiente descendente, e você também verá mais sobre isso no final desta semana. Agora, eu sei que estamos confiando muito na biblioteca TensorFlow para implementar uma rede neural. Um padrão que vi em várias ideias é que, à medida que a tecnologia evolui, as bibliotecas se tornam mais maduras e a maioria dos engenheiros usa bibliotecas em vez de implementar código do zero. Houve muitos outros exemplos disso na história da computação. Antigamente, muitas décadas atrás, os programadores precisavam implementar sua própria função de classificação do zero, mas agora as bibliotecas de classificação estão bem maduras e você provavelmente chama a função de classificação de outra pessoa em vez de implementá-la sozinho, a menos que esteja fazendo uma aula de computação e eu peça que você faça isso como um exercício. Hoje, se você quiser calcular a raiz quadrada de um número, como a raiz quadrada de sete, bem, antigamente os programadores tinham que escrever seu próprio código para computar isso, mas agora quase todo mundo chama uma biblioteca para obter raízes quadradas, ou operações matriciais, como multiplicar duas matrizes. Quando o aprendizado profundo era mais jovem e menos maduro, muitos desenvolvedores, inclusive eu, estavam implementando coisas do zero usando Python ou C++ ou alguma outra biblioteca. Mas hoje, as bibliotecas de aprendizado profundo amadureceram o suficiente para que a maioria dos desenvolvedores usasse essas bibliotecas e, de fato, a maioria das implementações comerciais de redes neurais atualmente usa uma biblioteca como TensorFlow ou PyTorch. Mas, como mencionei, ainda é útil entender como eles funcionam nos bastidores para que, se algo inesperado acontecer, o que ainda acontece com as bibliotecas atuais, você tenha mais chances de saber como corrigi-lo. Agora que você sabe como treinar uma rede neural básica, também chamada de perceptron multicamada, há algumas coisas que você pode mudar na rede neural que a tornarão ainda mais poderosa. No próximo vídeo, vamos dar uma olhada em como você pode trocar diferentes funções de ativação como alternativa à função de ativação sigmóide que estamos usando. Isso fará com que suas redes neurais funcionem ainda melhor. Vamos dar uma olhada nisso no próximo vídeo.
