{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/nn_adv/class_02/10%20-%20Atividade%20avaliativa%20-%20Redes%20neurais%20para%20classifica%C3%A7%C3%A3o%20multiclasse/lab_utils_ml_adv_assig_week_2.zip\n",
    "      \n",
    "!unzip -n -q lab_utils_ml_adv_assig_week_2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "# Necessário para ativar widgets\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório prático: Redes Neurais para Reconhecimento de Dígitos Manuscritos, Multiclasse \n",
    "\n",
    "Nesta atividade avaliativa, você usará uma rede neural para reconhecer os dígitos escritos à mão de 0 a 9.\n",
    "\n",
    "\n",
    "# Tópicos\n",
    "- [ 1 - Pacotes ](#1)\n",
    "- [ 2 - Ativação ReLU](#2)\n",
    "- [ 3 - Função Softmax](#3)\n",
    "  - [ Exercício 1](#ex01)\n",
    "- [ 4 - Redes Neurais](#4)\n",
    "  - [ 4.1 Definição do Problema](#4.1)\n",
    "  - [ 4.2 Conjunto de Dados](#4.2)\n",
    "  - [ 4.3 Representação de Modelo](#4.3)\n",
    "  - [ 4.4 Implementação em Tensorflow](#4.4)\n",
    "  - [ 4.5 Utilização do Softmax](#4.5)\n",
    "    - [ Exercício 2](#ex02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Pacotes \n",
    "\n",
    "Primeiro, vamos executar a célula abaixo para importar todos os pacotes de que você precisará durante este trabalho.\n",
    "- [numpy](https://numpy.org/) é o pacote fundamental para computação científica com Python.\n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca popular para plotar gráficos em Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) é uma plataforma popular para aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "from public_tests import * \n",
    "\n",
    "from autils import *\n",
    "from lab_utils_softmax import plt_softmax\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "\n",
    "## 2 - Ativação ReLU\n",
    "Nesta semana, uma nova ativação foi introduzida, a Unidade Linear Retificada (ReLU). \n",
    "\n",
    "$$ a = max(0,z) \\quad\\quad\\text{\\# função ReLU} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt_act_trio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"./images/C2_W2_ReLu.png\"     style=\" width:380px; padding: 10px 20px; \" >\n",
    "\n",
    "O exemplo da aula à direita mostra uma aplicação do ReLU. Nesse exemplo, o recurso derivado de \"awareness\" não é binário, mas tem uma faixa contínua de valores. O sigmoide é melhor para situações de ligado/desligado ou binárias. O ReLU fornece uma relação linear contínua. Além disso, ele tem um intervalo \"desligado\" em que a saída é zero.     \n",
    "O recurso \"off\" torna o ReLU uma ativação não linear. Por que isso é necessário? Isso permite que várias unidades contribuam para a função resultante sem interferir. Isso será examinado com mais detalhes no laboratório opcional de suporte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Função Softmax\n",
    "Uma rede neural multiclasse gera N saídas.\n",
    "\n",
    "Uma saída é selecionada como a resposta prevista.\n",
    "\n",
    "Na camada de saída, um vetor $\\mathbf{z}$ é gerado por uma função linear que é alimentada em uma função softmax.\n",
    "\n",
    "A função softmax converte $\\mathbf{z}$ em uma distribuição de probabilidade, conforme descrito abaixo.\n",
    "\n",
    "Depois de aplicar a softmax, cada saída estará entre 0 e 1 e as saídas somarão 1. Elas podem ser interpretadas como probabilidades.\n",
    "\n",
    "As entradas maiores para o softmax corresponderão a probabilidades de saída maiores.\n",
    "<center>  <img  src=\"./images/C2_W2_NNSoftmax.PNG\" width=\"600\" />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função softmax pode ser escrita:\n",
    "$$a_j = \\frac{e^{z_j}}{ \\sum_{k=0}^{N-1}{e^{z_k} }} \\tag{1}$$\n",
    "\n",
    "Onde $z = \\mathbf{w} \\cdot \\mathbf{x} + b$ e N é o número de recursos/categorias na camada de saída.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercício 1\n",
    "Vamos criar uma implementação do NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def my_softmax(z):  \n",
    "    \"\"\" O Softmax converte um vetor de valores em uma distribuição de probabilidade.\n",
    "    Args:\n",
    "      z (ndarray (N,))  : dados de entrada, N recursos\n",
    "    Returns:\n",
    "      a (ndarray (N,))  : softmax of z\n",
    "    \"\"\"    \n",
    "    ### INICIAR O CÓDIGO AQUI ### \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    ### FINALIZAR O CÓDIGO AQUI### \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "z = np.array([1., 2., 3., 4.])\n",
    "a = my_softmax(z)\n",
    "atf = tf.nn.softmax(z)\n",
    "print(f\"my_softmax(z):         {a}\")\n",
    "print(f\"tensorflow softmax(z): {atf}\")\n",
    "\n",
    "# COMEÇO DO TESTE DA UNIDADE\n",
    "test_my_softmax(my_softmax)\n",
    "# FIM DO TESTE DA UNIDADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para dicas</b></font></summary>\n",
    "    Uma implementação usa o loop for para construir primeiro o denominador e, em seguida, um segundo loop para calcular cada saída.\n",
    "    \n",
    "```python\n",
    "def my_softmax(z):  \n",
    "    N = len(z)\n",
    "    a =                     # inicializar a em zeros  \n",
    "    ez_sum =                # inicializar a soma em zero\n",
    "    for k in range(N):      # loop sobre o número de saídas           \n",
    "        ez_sum +=           # soma exp(z[k]) para construir o denominador compartilhado      \n",
    "    for j in range(N):      # loop over number of outputs again                \n",
    "        a[j] =              # repetir o loop sobre o número de saídas novamente  \n",
    "    return(a)\n",
    "```\n",
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click para ver o código</b></font></summary>\n",
    "   \n",
    "```python\n",
    "def my_softmax(z):  \n",
    "    N = len(z)\n",
    "    a = np.zeros(N)\n",
    "    ez_sum = 0\n",
    "    for k in range(N):                \n",
    "        ez_sum += np.exp(z[k])       \n",
    "    for j in range(N):                \n",
    "        a[j] = np.exp(z[j])/ez_sum   \n",
    "    return(a)\n",
    "\n",
    "Ou uma implementação vetorial:\n",
    "\n",
    "def my_softmax(z):  \n",
    "    ez = np.exp(z)              \n",
    "    a = ez/np.sum(ez)           \n",
    "    return(a)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, varie os valores das entradas `z`. Observe, em particular, como o exponencial no numerador amplia pequenas diferenças nos valores. Observe também que os valores de saída somam um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt_softmax(my_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Redes Neurais\n",
    "\n",
    "Na atividade avaliativa passada, você implementou uma rede neural para fazer a classificação binária. Nesta semana, você estenderá essa rede para a classificação multiclasse. Isso utilizará a ativação softmax.\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1 Definição do Problema\n",
    "Neste exercício, você usará uma rede neural para reconhecer dez dígitos escritos à mão, de 0 a 9. Essa é uma tarefa de classificação multiclasse em que uma das n opções é selecionada. O reconhecimento automatizado de dígitos manuscritos é amplamente utilizado atualmente, desde o reconhecimento de códigos postais em envelopes de correio até o reconhecimento de valores escritos em cheques bancários. \n",
    "\n",
    "\n",
    "<a name=\"4.2\"></a>\n",
    "### 4.2 Dataset\n",
    "\n",
    "Você começará carregando o conjunto de dados para essa tarefa. \n",
    "- A função `load_data()` mostrada abaixo carrega os dados nas variáveis `X` e `y`\n",
    "\n",
    "\n",
    "- O conjunto de dados contém 5.000 exemplos de treinamento de dígitos manuscritos $^1$.  \n",
    "\n",
    "    - Cada exemplo de treinamento é uma imagem em escala de cinza de 20 pixels x 20 pixels do dígito. \n",
    "        - Cada pixel é representado por um número de ponto flutuante que indica a intensidade da escala de cinza naquele local. \n",
    "        - A grade de 20 por 20 pixels é \"desenrolada\" em um vetor de 400 dimensões. \n",
    "        - Each training examples becomes a single row in our data matrix `X`. \n",
    "        - Isso nos dá uma matriz 5000 x 400 `X` em que cada linha é um exemplo de treinamento de uma imagem de dígito manuscrito.\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- A segunda parte do conjunto de treinamento é um vetor dimensional de 5000 x 1 `y` que contém rótulos para o conjunto de treinamento\n",
    "    - `y = 0` se a imagem for do dígito `0`, `y = 4` se a imagem for do dígito `4` e assim por diante.\n",
    "\n",
    "$^1$<sub> Esse é um subconjunto do conjunto de dados de dígitos manuscritos MNIST de [Yann Lecun](https://ai.meta.com/people/yann-lecun/)</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Visualizar as variáveis\n",
    "Vamos nos familiarizar mais com seu conjunto de dados.  \n",
    "- Uma boa maneira de começar é imprimir cada variável e ver o que ela contém.\n",
    "\n",
    "O código abaixo imprime o primeiro elemento nas variáveis `X` e `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('O primeiro elemento de X é: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O primeiro elemento de y é: ', y[0,0])\n",
    "print ('O pultimo elemento de y é: ', y[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Verifique as dimensões de suas variáveis\n",
    "\n",
    "Outra maneira de se familiarizar com seus dados é visualizar suas dimensões. Imprima a forma de `X` e `y` e veja quantos exemplos de treinamento você tem em seu conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O formato de X é: ' + str(X.shape))\n",
    "print ('O formato de y é: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Visualização dos dados\n",
    "\n",
    "Você começará visualizando um subconjunto do conjunto de treinamento. \n",
    "- Na célula abaixo, o código seleciona aleatoriamente 64 linhas de `X`, mapeia cada linha de volta para uma imagem em escala de cinza de 20 pixels por 20 pixels e exibe as imagens juntas. \n",
    "- O rótulo de cada imagem é exibido acima da imagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(5,5))\n",
    "fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[esquerda, inferior, direita, superior]\n",
    "\n",
    "#fig.tight_layout(pad=0.5)\n",
    "widgvis(fig)\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Selecionar índices aleatórios\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecionar as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Exibir o rótulo acima da imagem\n",
    "    ax.set_title(y[random_index,0])\n",
    "    ax.set_axis_off()\n",
    "    fig.suptitle(\"Rótulo, imagem\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3 Representação de Modelo\n",
    "\n",
    "A rede neural que você usará nesta tarefa é mostrada na figura abaixo. \n",
    "- Ela tem duas camadas densas com ativações ReLU seguidas de uma camada de saída com ativação linear. \n",
    "    - Lembre-se de que nossas entradas são valores de pixel de imagens de dígitos.\n",
    "    - Como as imagens são de tamanho $20\\times20$, isso nos dá $400$ de entradas  \n",
    "    \n",
    "<img src=\"images/C2_W2_Assigment_NN.png\" width=\"600\" height=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os parâmetros têm dimensões que são dimensionadas para uma rede neural com $25$ unidades na camada 1, $15$ unidades na camada 2 e $10$ unidades de saída na camada 3, uma para cada dígito.\n",
    "\n",
    "    - Lembre-se de que as dimensões desses parâmetros são determinadas da seguinte forma:\n",
    "        - Se a rede tiver $s_{in}$ unidades em uma camada e $s_{out}$ unidades na camada seguinte, então \n",
    "            - $W$ terá uma dimensão de $s_{in} \\times s_{out}$.\n",
    "            - $b$ será um vetor com elementos $s_{out}$\n",
    "  \n",
    "    - Portanto, as formas de `W` e `b` são \n",
    "        - camada1: A forma de `W1` é (400, 25) e a forma de `b1` é (25,)\n",
    "        - camada2: A forma de `W2` é (25, 15) e a forma de `b2` é: (15,)\n",
    "        - camada3: A forma de `W3` é (15, 10) e a forma de `b3` é: (10,)\n",
    ">**Nota:** O vetor de bias `b` pode ser representado como uma matriz 1-D (n,) ou 2-D (n,1). O Tensorflow utiliza uma representação 1-D e este laboratório manterá essa convenção: \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### 4.4 Implementação em Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos do Tensorflow são criados camada por camada. As dimensões de entrada de uma camada ($s_{in}$ acima) são calculadas para você. Você especifica as *dimensões de saída* de uma camada e isso determina a dimensão de entrada da próxima camada. A dimensão de entrada da primeira camada é derivada do tamanho dos dados de entrada especificados na instrução `model.fit` abaixo. \n",
    ">**Nota:** Também é possível adicionar uma camada de entrada que especifique a dimensão de entrada da primeira camada. Por exemplo:  \n",
    "`tf.keras.Input(shape=(400,)),    #specify input shape`  \n",
    "Incluiremos isso aqui para ilustrar o dimensionamento de alguns modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.5\"></a>\n",
    "### 4.5 Utilização do Softmax\n",
    "Conforme descrito na aula teórica e no laboratório opcional de softmax, a estabilidade numérica é aprimorada se o softmax for agrupado com a função de perda em vez da camada de saída durante o treinamento. Isso tem implicações ao *construir* o modelo e *usar* o modelo.  \n",
    "Construção:  \n",
    "* A camada Dense final deve usar uma ativação \"linear\". Na verdade, isso significa que não há ativação. \n",
    "* A instrução `model.compile` indicará isso ao incluir `from_logits=True`.\n",
    "`loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) `  \n",
    "* Isso não afeta a forma do alvo. No caso do SparseCategorialCrossentropy, o alvo é o dígito esperado, 0-9.\n",
    "\n",
    "Usando o modelo:\n",
    "* Os resultados não são probabilidades. Se as probabilidades de saída forem desejadas, aplique uma função softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercício 2\n",
    "\n",
    "Abaixo, use [Sequential model](https://keras.io/guides/sequential_model/) e [Dense Layer](https://keras.io/api/layers/core_layers/dense/) do Keras com uma ativação ReLU para construir a rede de três camadas descrita acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) # para resultados consistentes em diferentes execuções do código\n",
    "model = Sequential(\n",
    "    [               \n",
    "    ### INICIAR O CÓDIGO AQUI ### \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    ### FINALIZAR O CÓDIGO AQUI### \n",
    "    ], name = \"my_model\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Saída Esperada (Clique para expandir)</b></font></summary>\n",
    "A função `model.summary()` exibe um resumo útil do modelo. Observe que os nomes das camadas podem variar, pois são gerados automaticamente, a menos que o nome seja especificado.    \n",
    "\n",
    "    \n",
    "```\n",
    "Model: \"my_model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "L1 (Dense)                   (None, 25)                10025     \n",
    "_________________________________________________________________\n",
    "L2 (Dense)                   (None, 15)                390       \n",
    "_________________________________________________________________\n",
    "L3 (Dense)                   (None, 10)                160       \n",
    "=================================================================\n",
    "Total params: 10,575\n",
    "Trainable params: 10,575\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para Dicas</b></font></summary>\n",
    "    \n",
    "```python\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "    [               \n",
    "        ### INICIAR O CÓDIGO AQUI ###  \n",
    "        tf.keras.Input(shape=(400,)),     # @REPLACE \n",
    "        Dense(25, activation='relu', name = \"L1\"), # @REPLACE \n",
    "        Dense(15, activation='relu',  name = \"L2\"), # @REPLACE  \n",
    "        Dense(10, activation='linear', name = \"L3\"),  # @REPLACE \n",
    "        ### FINALIZAR O CÓDIGO AQUI### \n",
    "    ], name = \"my_model\" \n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INICIAR TESTE DA UNIDADE     \n",
    "test_model(model, 10, 400)\n",
    "# FINALIZAR TESTE DA UNIDADE     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As contagens de parâmetros mostradas no resumo correspondem ao número de elementos nas matrizes de peso e polarização, conforme mostrado abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos examinar mais detalhadamente os pesos para verificar se o tensorflow produziu as mesmas dimensões que calculamos acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#### Examine o formato dos pesos\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"Formato de W1 = {W1.shape}, Formato de b1 = {b1.shape}\")\n",
    "print(f\"Formato de W2 = {W2.shape}, Formato de b2 = {b2.shape}\")\n",
    "print(f\"Formato de W3 = {W3.shape}, Formato de b3 = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**\n",
    "```\n",
    "Formato de W1 = (400, 25), Formato de b1 = (25,)  \n",
    "Formato de W2 = (25, 15), Formato de b2 = (15,)  \n",
    "Formato de W3 = (15, 10), Formato de b3 = (10,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir:\n",
    "* define uma função de perda, `SparseCategoricalCrossentropy` e indica que o softmax deve ser incluído no cálculo da perda adicionando `from_logits=True`)\n",
    "* define um otimizador. Uma opção popular é o Adaptive Moment (Adam), que foi descrito na aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,y,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs e batches\n",
    "Na instrução `fit` acima, o número de `epochs` foi definido como 40. Isso especifica que todo o conjunto de dados deve ser aplicado durante o treinamento 40 vezes.  Durante o treinamento, você verá uma saída descrevendo o progresso do treinamento que se parece com isto:\n",
    "```\n",
    "Época 1/40\n",
    "157/157 [==============================] - 0s 1ms/passo - perda: 2,2770\n",
    "```\n",
    "A primeira linha, `Epoch 1/40`, descreve a época em que o modelo está sendo executado no momento. Para maior eficiência, o conjunto de dados de treinamento é dividido em \"lotes\"(_batches_). O tamanho padrão de um lote no Tensorflow é 32. Há 5.000 exemplos em nosso conjunto de dados, ou seja, aproximadamente 157 lotes. A notação na segunda linha `157/157 [====` está descrevendo qual lote foi executado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perda (custo)\n",
    "Aprendemos anteriormente a acompanhar o progresso da descida do gradiente monitorando o custo. O ideal é que o custo diminua à medida que o número de iterações do algoritmo aumenta. O Tensorflow se refere ao custo como \"perda\"(_loss_). Acima, você viu a perda exibida a cada época enquanto o `model.fit` estava sendo executado. O método [.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model) retorna uma variedade de métricas, incluindo a perda. Isso é capturado na variável `history` acima. Isso pode ser usado para examinar a perda em um gráfico, conforme mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot_loss_tf(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão \n",
    "Para fazer uma previsão, use o Keras `predict`. Abaixo, X[1015] contém uma imagem de um dígito dois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "image_of_two = X[1015]\n",
    "display_digit(image_of_two)\n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1,400))  # prediction\n",
    "\n",
    "print(f\" predizendo um Dois: \\n{prediction}\")\n",
    "print(f\" Maior índice de previsão: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior saída é prediction[2], indicando que o dígito previsto é um '2'. Se o problema exigir apenas uma seleção, isso é suficiente. Use NumPy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) para selecioná-la. Se o problema exigir uma probabilidade, será necessário um softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" Prevendo um Dois. Vetor de probabilidade: \\n{prediction_p}\")\n",
    "print(f\"Total das predições: {np.sum(prediction_p):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar um número inteiro que represente o alvo previsto, você deseja o índice da maior probabilidade.Isso é feito com a função Numpy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar as previsões com os rótulos de uma amostra aleatória de 64 dígitos.Isso demora um pouco para ser executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Não é necessário modificar nada nessa célula\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(5,5))\n",
    "fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[esquerda, inferior, direita, superior]\n",
    "widgvis(fig)\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Selecione índices aleatórios\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Selecione as linhas correspondentes aos índices aleatórios e\n",
    "    # remodelar a imagem\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Prever usando a rede neural\n",
    "    prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    prediction_p = tf.nn.softmax(prediction)\n",
    "    yhat = np.argmax(prediction_p)\n",
    "    \n",
    "    # Exibir o rótulo acima da imagem\n",
    "    ax.set_title(f\"{y[random_index,0]},{yhat}\",fontsize=10)\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Rótulo, yhat\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em alguns dos erros. \n",
    ">Observação: aumentar o número de épocas de treinamento pode eliminar os erros nesse conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print( f\"{display_errors(model,X,y)} erros em {len(X)} imagens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parabéns!\n",
    "Você construiu e utilizou com sucesso uma rede neural para fazer a classificação multiclasse."
   ]
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
