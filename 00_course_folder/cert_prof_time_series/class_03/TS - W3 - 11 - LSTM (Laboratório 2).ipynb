{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_time_series/class_03/TS%20-%20W3%20-%2011%20-%20LSTM%20(Laborat%C3%B3rio%202).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV_nvXSQGJPK"
   },
   "source": [
    "# Uso de um LSTM de várias camadas para previsão\n",
    "\n",
    "Neste laboratório, você usará a mesma arquitetura RNN do primeiro laboratório, mas empilhará camadas [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) em vez de `SimpleRNN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IMbAWETGOWD"
   },
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOjujz601HcS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD7RQQ0xGQVH"
   },
   "source": [
    "## Utilitários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zswl7jRtGzkk"
   },
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    \"\"\"\n",
    "    Visualiza dados de séries temporais\n",
    "\n",
    "    Args:\n",
    "      time (array of int) - contém as etapas de tempo\n",
    "      series (array of int) - contém as medidas para cada etapa de tempo\n",
    "      format - estilo de linha ao plotar o gráfico\n",
    "      start - primeiro passo de tempo a ser plotado\n",
    "      end - última etapa de tempo a ser plotada\n",
    "    \"\"\"\n",
    "\n",
    "    # Configuração das dimensões da figura do gráfico\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if type(series) is tuple:\n",
    "\n",
    "      for series_num in series:\n",
    "        # Plotar os dados da série temporal\n",
    "        plt.plot(time[start:end], series_num[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plotar os dados da série temporal\n",
    "      plt.plot(time[start:end], series[start:end], format)\n",
    "\n",
    "    # Rotular o eixo x\n",
    "    plt.xlabel(\"Time\")\n",
    "\n",
    "    # Rotular o eixo y\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    # Sobrepor uma grade no gráfico\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Desenhe o gráfico na tela\n",
    "    plt.show()\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    \"\"\"\n",
    "    Gera dados sintéticos que seguem uma linha reta com um valor de inclinação.\n",
    "\n",
    "    Args:\n",
    "      time (vetor de int) - contém as etapas de tempo\n",
    "      slope (float) - determina a direção e a inclinação da linha\n",
    "\n",
    "    Retorna:\n",
    "      series (vetor de float) - medições que seguem uma linha reta\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula a série linear dada a inclinação\n",
    "    series = slope * time\n",
    "\n",
    "    return series\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"\n",
    "    Apenas um padrão arbitrário, você pode alterá-lo se desejar\n",
    "    \n",
    "    Args:\n",
    "      season_time (vetor de float) - contém as medições por etapa de tempo\n",
    "\n",
    "    Retorna:\n",
    "      data_pattern (vetor de float) - contém os valores de medição revisados de acordo com o padrão definido. \n",
    "                                  de acordo com o padrão definido\n",
    "    \"\"\"\n",
    "\n",
    "    # Gerar os valores usando um padrão arbitrário\n",
    "    data_pattern = np.where(season_time < 0.4,\n",
    "                    np.cos(season_time * 2 * np.pi),\n",
    "                    1 / np.exp(3 * season_time))\n",
    "    \n",
    "    return data_pattern\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"\n",
    "    Repete o mesmo padrão em cada período\n",
    "\n",
    "    Args:\n",
    "      time (vetor de int) - contém as etapas de tempo\n",
    "      period (int) - número de etapas de tempo antes da repetição do padrão\n",
    "      amplitude (int) - valor de pico medido em um período\n",
    "      phase (int) - número de etapas de tempo para deslocar os valores medidos\n",
    "\n",
    "    Retorna:\n",
    "      data_pattern (vetor de float) - dados sazonais dimensionados pela amplitude definida\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definir os valores medidos por período\n",
    "    season_time = ((time + phase) % period) / period\n",
    "\n",
    "    # Gera os dados sazonais dimensionados pela amplitude definida\n",
    "    data_pattern = amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "    return data_pattern\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    \"\"\"Gera um sinal ruidoso normalmente distribuído\n",
    "\n",
    "    Args:\n",
    "      time (array of int) - contém as etapas de tempo\n",
    "      noise_level (float) - fator de escala para o sinal gerado\n",
    "      seed (int) - semente do gerador de números para repetibilidade\n",
    "\n",
    "    Retorna:\n",
    "      noise (matriz de float) - o sinal ruidoso\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar o gerador de números aleatórios\n",
    "    rnd = np.random.RandomState(seed)\n",
    "\n",
    "    # Gerar um número aleatório para cada etapa de tempo e dimensionar pelo nível de ruído\n",
    "    noise = rnd.randn(len(time)) * noise_level\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxNyeFWjGSdj"
   },
   "source": [
    "## Gerar os dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYEUfDbdpHPm"
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "baseline = 10\n",
    "amplitude = 40\n",
    "slope = 0.05\n",
    "noise_level = 5\n",
    "\n",
    "# Criar a série\n",
    "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
    "\n",
    "# Atualizar com ruído\n",
    "series += noise(time, noise_level, seed=42)\n",
    "\n",
    "# Plotar os resultados\n",
    "plot_series(time, series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYKCvv-eGWRc"
   },
   "source": [
    "## Dividir o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpp0slenpKVD"
   },
   "outputs": [],
   "source": [
    "# Definir o tempo de divisão\n",
    "split_time = 1000\n",
    "\n",
    "# Obter o conjunto de treino\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "\n",
    "# Obter o conjunto de validação\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cktHz9aOGYtV"
   },
   "source": [
    "## Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_j_2_Mqwn7-"
   },
   "outputs": [],
   "source": [
    "# Hiperoparâmetros\n",
    "window_size = 20\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sTTIOCbyShY"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"Gera janelas de conjunto de dados\n",
    "\n",
    "    Args:\n",
    "      series (vetor de float) - contém os valores da série temporal\n",
    "      window_size (int) - o número de etapas de tempo a serem incluídas no recurso\n",
    "      batch_size (int) - o tamanho do lote\n",
    "      shuffle_buffer(int) - tamanho do buffer a ser usado para o método shuffle\n",
    "\n",
    "    Retorna:\n",
    "      dataset (TF Dataset) - Conjunto de dados TF contendo janelas de tempo\n",
    "    \"\"\"\n",
    "  \n",
    "    # Gerar um conjunto de dados TF a partir dos valores da série\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    \n",
    "    # Janela de dados, mas só pega aqueles com o tamanho especificado\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    \n",
    "    # Achatar as janelas, colocando seus elementos em um único lote\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    # Criar tuplas com recursos e rótulos \n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    # Embaralhar as janelas\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    \n",
    "    # Criar lotes de janelas\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGj5-InSwtQQ"
   },
   "outputs": [],
   "source": [
    "# Gerar as janelas do conjunto de dados\n",
    "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9-Ke8ZaGcjd"
   },
   "source": [
    "## Criar o modelo\n",
    "\n",
    "Conforme mencionado, você trocará o `SimpleRNN` pelo `LSTM` neste laboratório. Ele também está definido como bidirecional abaixo, mas fique à vontade para revisá-lo mais tarde e ver os resultados obtidos. Os LSTMs são muito mais complexos em sua arquitetura interna do que os simpleRNNs. Ele implementa um estado de célula que lhe permite lembrar sequências melhor do que as implementações simples. Essa complexidade adicional resulta em um conjunto maior de parâmetros a serem treinados e você verá isso ao imprimir o resumo do modelo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1Hl39rklkLm"
   },
   "outputs": [],
   "source": [
    "# Criar o modelo\n",
    "model_tune = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[window_size]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
    "])\n",
    "\n",
    "# Imprimir o resumo do modelo\n",
    "model_tune.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHaFblbwq0GV"
   },
   "source": [
    "## Ajuste a taxa de aprendizado\n",
    "\n",
    "Como de costume, você escolherá uma taxa de aprendizagem executando o código de ajuste abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE7al18qw48G"
   },
   "outputs": [],
   "source": [
    "# Definir o agendador de taxa de aprendizado\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "# Inicializar o otimizador\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "# Definir os parâmetros de treinamento\n",
    "model_tune.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkBsrsXMzoWR"
   },
   "outputs": [],
   "source": [
    "# Definir a matriz de taxa de aprendizado\n",
    "lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
    "\n",
    "# Definir o tamanho da figura\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Definir a grade\n",
    "plt.grid(True)\n",
    "\n",
    "# Plotar a perda em escala logarítmica\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n",
    "\n",
    "# Aumentar o tamanho dos tickmarks\n",
    "plt.tick_params('both', length=10, width=1, which='both')\n",
    "# Definir os limites do gráfico\n",
    "plt.axis([1e-8, 1e-3, 0, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-lKNp4pq_w8"
   },
   "source": [
    "## Treinar o modelo\n",
    "\n",
    "Em seguida, você pode continuar a treinar o modelo com a taxa de aprendizado escolhida. \n",
    "\n",
    "*Dica: ao fazer experimentos e executar diferentes iterações de um modelo, talvez você queira usar o método [`clear_session()`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) para organizar a memória usada pelo Keras. Isso é adicionado na primeira linha abaixo.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uh-97bpLZCA"
   },
   "outputs": [],
   "source": [
    "# Redefinir estados gerados pelo Keras\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Construir o modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),\n",
    "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
    "])\n",
    "\n",
    "# Definir a taxa de aprendizado\n",
    "learning_rate = 2e-6\n",
    "\n",
    "# Definir o otimizador \n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# Definir os parâmetros de treinamento\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(dataset,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjP4kbGiI7cw"
   },
   "source": [
    "## Previsão do modelo\n",
    "\n",
    "Em seguida, você gerará lotes de janelas para gerar previsões que se alinham com o conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QO8cfKwKBBG6"
   },
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    \"\"\"Usa um modelo de entrada para gerar previsões em janelas de dados\n",
    "\n",
    "    Args:\n",
    "      model (TF Keras Model) - modelo que aceita janelas de dados\n",
    "      series (array of float) - contém os valores da série temporal\n",
    "      window_size (int) - o número de etapas de tempo a serem incluídas na janela\n",
    "      batch_size (int) - o tamanho do lote\n",
    "\n",
    "    Retorna:\n",
    "      forecast (matriz numpy) - matriz que contém as previsões\n",
    "    \"\"\"\n",
    "\n",
    "    # Gerar um conjunto de dados TF a partir dos valores da série\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    \n",
    "    # Janela de dados, mas só pega aqueles com o tamanho especificado\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Achatar as janelas, colocando seus elementos em um único lote\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "    \n",
    "    # Criar lotes de janelas\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    # Obter previsões em todo o conjunto de dados\n",
    "    forecast = model.predict(dataset)\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_plB3UseBD8o"
   },
   "outputs": [],
   "source": [
    "# Reduzir a série original\n",
    "forecast_series = series[split_time-window_size:-1]\n",
    "\n",
    "# Use a função auxiliar para gerar previsões\n",
    "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Retirar eixo unidimensional\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plotar os resultados\n",
    "plot_series(time_valid, (x_valid, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nn8iSQkZtaRC"
   },
   "source": [
    "Em seguida, você pode gerar as métricas para avaliar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IKhueZaBGID"
   },
   "outputs": [],
   "source": [
    "# Calcular o MSE e o MAE\n",
    "print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\n",
    "print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5PqTePGHeMH"
   },
   "source": [
    "## Inclusão de um conjunto de validação durante o treinamento\n",
    "\n",
    "Você já viu antes como também pode monitorar o desempenho do seu modelo em relação a um conjunto de validação durante o treinamento. Você também pode fazer isso neste laboratório. \n",
    "\n",
    "Primeiro, você precisa gerar um `val_set`, que são janelas de dados e rótulos que o modelo pode aceitar. Você pode simplesmente reutilizar a função `windowed_dataset` para isso e passar os pontos `x_valid` para gerar as janelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvFVwL3PC4iX"
   },
   "outputs": [],
   "source": [
    "# Gerar janelas de dados do conjunto de validação\n",
    "val_set = windowed_dataset(x_valid, window_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p68j6XxEvP9K"
   },
   "source": [
    "Em seguida, você pode fazer o mesmo treinamento de antes, mas passar o `val_set` para o parâmetro `validation_data` do método `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wujKz6tXDSn0"
   },
   "outputs": [],
   "source": [
    "# Redefinir estados gerados pelo Keras\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Construir o modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),\n",
    "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
    "])\n",
    "\n",
    "# Definir a taxa de aprendizado\n",
    "learning_rate = 2e-6\n",
    "\n",
    "# Definir o otimizador \n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# Definir os parâmetros de treinamento\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Treine o modelo\n",
    "history = model.fit(dataset,epochs=100, validation_data=val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzPIqeMWvbPy"
   },
   "source": [
    "## Conclusão\n",
    "\n",
    "Isso conclui este breve exercício sobre o uso de LSTMs para previsão de séries temporais.\n",
    "\n",
    "Nos próximos laboratórios você se baseará nisso e adicionará convoluções.\n",
    "\n",
    "Em seguida, você começará a se afastar dos dados sintéticos e a usar conjuntos de dados do mundo real!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C4_W3_Lab_2_LSTM.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
