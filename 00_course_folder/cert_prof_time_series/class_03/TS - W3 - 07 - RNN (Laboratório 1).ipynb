{"cells":[{"cell_type":"markdown","metadata":{"id":"sC8x1SlzYhCJ"},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_time_series/class_03/TS%20-%20W3%20-%2007%20-%20RNN%20(Laborat%C3%B3rio%201).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"]},{"cell_type":"markdown","metadata":{"id":"fO0xC1Cfp5-U"},"source":["# Uso de um RNN simples para previsão\n","\n","Neste laboratório, você começará a usar redes neurais recorrentes (RNNs) para criar um modelo de previsão. Em particular, você vai:\n","\n","* Criar uma RNN empilhada usando camadas `simpleRNN`.\n","* usar camadas `Lambda` para remodelar a entrada e dimensionar a saída\n","* usar a perda Huber durante o treinamento\n","* Usar janelas de dados em lote para gerar previsões de modelos.\n","\n","Você treinará esse modelo com o mesmo conjunto de dados sintéticos vistos anteriormente, portanto, as etapas iniciais serão as mesmas. Vamos começar!"]},{"cell_type":"markdown","metadata":{"id":"w5kDhl0kp4ML"},"source":["## Importações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOjujz601HcS"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"ppd0VK_4p1c8"},"source":["## Utilitários"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zswl7jRtGzkk"},"outputs":[],"source":["def plot_series(time, series, format=\"-\", start=0, end=None):\n","    \"\"\"\n","    Visualiza dados de séries temporais\n","\n","    Args:\n","      time (vetor de int) - contém as etapas de tempo\n","      series (vetor de int) - contém as medidas para cada etapa de tempo\n","      format - estilo de linha ao plotar o gráfico\n","      start - primeiro passo de tempo a ser plotado\n","      end - última etapa de tempo a ser plotada\n","    \"\"\"\n","\n","    # Configuração das dimensões da figura do gráfico\n","    plt.figure(figsize=(10, 6))\n","\n","    if type(series) is tuple:\n","\n","      for series_num in series:\n","        # Plotar os dados da série temporal\n","        plt.plot(time[start:end], series_num[start:end], format)\n","\n","    else:\n","      # Plotar os dados da série temporal\n","      plt.plot(time[start:end], series[start:end], format)\n","\n","    # Rotular o eixo x\n","    plt.xlabel(\"Time\")\n","\n","    # Rotular o eixo y\n","    plt.ylabel(\"Value\")\n","\n","    # Sobrepor uma grade no gráfico\n","    plt.grid(True)\n","\n","    # Desenhe o gráfico na tela\n","    plt.show()\n","\n","def trend(time, slope=0):\n","    \"\"\"\n","    Gera dados sintéticos que seguem uma linha reta com um valor de inclinação.\n","\n","    Args:\n","      time (vetor de int) - contém as etapas de tempo\n","      slope (float) - determina a direção e a inclinação da linha\n","\n","    Retorna:\n","      series (vetor de float) - medições que seguem uma linha reta\n","    \"\"\"\n","\n","    # Calcula a série linear dada a inclinação\n","    series = slope * time\n","\n","    return series\n","\n","def seasonal_pattern(season_time):\n","    \"\"\"\n","    Apenas um padrão arbitrário, você pode alterá-lo se desejar\n","\n","    Args:\n","      season_time (vetor de float) - contém as medições por etapa de tempo\n","\n","    Retorna:\n","      data_pattern (vetor de float) - contém os valores de medição revisados de acordo com o padrão definido.\n","                                  de acordo com o padrão definido\n","    \"\"\"\n","\n","    # Gerar os valores usando um padrão arbitrário\n","    data_pattern = np.where(season_time < 0.4,\n","                    np.cos(season_time * 2 * np.pi),\n","                    1 / np.exp(3 * season_time))\n","\n","    return data_pattern\n","\n","def seasonality(time, period, amplitude=1, phase=0):\n","    \"\"\"\n","    Repete o mesmo padrão em cada período\n","\n","    Args:\n","      time (array of int) - contém as etapas de tempo\n","      period (int) - número de etapas de tempo antes da repetição do padrão\n","      amplitude (int) - valor de pico medido em um período\n","      phase (int) - número de etapas de tempo para deslocar os valores medidos\n","\n","    Retorna:\n","      data_pattern (array of float) - dados sazonais dimensionados pela amplitude definida\n","    \"\"\"\n","\n","    # Definir os valores medidos por período\n","    season_time = ((time + phase) % period) / period\n","\n","    # Gera os dados sazonais dimensionados pela amplitude definida\n","    data_pattern = amplitude * seasonal_pattern(season_time)\n","\n","    return data_pattern\n","\n","def noise(time, noise_level=1, seed=None):\n","    \"\"\"Gera um sinal ruidoso normalmente distribuído\n","\n","    Args:\n","      time (vetor de int) - contém as etapas de tempo\n","      noise_level (float) - fator de escala para o sinal gerado\n","      seed (int) - semente do gerador de números para repetibilidade\n","\n","    Retorna:\n","      noise (vetor de float) - o sinal ruidoso\n","    \"\"\"\n","\n","    # Inicializar o gerador de números aleatórios\n","    rnd = np.random.RandomState(seed)\n","\n","    # Gerar um número aleatório para cada etapa de tempo e dimensionar pelo nível de ruído\n","    noise = rnd.randn(len(time)) * noise_level\n","\n","    return noise"]},{"cell_type":"markdown","metadata":{"id":"B3ZFrzpCpyTo"},"source":["## Gerar os dados sintéticos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UJCR61zleGM"},"outputs":[],"source":["# Hyperparâmetros\n","time = np.arange(4 * 365 + 1, dtype=\"float32\")\n","baseline = 10\n","amplitude = 40\n","slope = 0.05\n","noise_level = 5\n","\n","# Criar a série\n","series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n","\n","# Adicionar ruído\n","series += noise(time, noise_level, seed=42)\n","\n","# Plotar os resultados\n","plot_series(time, series)"]},{"cell_type":"markdown","metadata":{"id":"RbW2GxrgpuZF"},"source":["## Dividir o conjunto de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhkuHzlol2VW"},"outputs":[],"source":["# Definir o tempo de divisão\n","split_time = 1000\n","\n","# Obter o conjunto de treino\n","time_train = time[:split_time]\n","x_train = series[:split_time]\n","\n","# Obter o conjunto de validação\n","time_valid = time[split_time:]\n","x_valid = series[split_time:]"]},{"cell_type":"markdown","metadata":{"id":"TP6a2ckVqThP"},"source":["## Prepare Features and Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SawHhwx3qOMC"},"outputs":[],"source":["# Hyperparâmetros\n","window_size = 20\n","batch_size = 32\n","shuffle_buffer_size = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sTTIOCbyShY"},"outputs":[],"source":["def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    \"\"\"Gera janelas de conjunto de dados\n","\n","    Args:\n","      series (vetor de float) - contém os valores da série temporal\n","      window_size (int) - o número de etapas de tempo a serem incluídas no recurso\n","      batch_size (int) - o tamanho do lote\n","      shuffle_buffer(int) - tamanho do buffer a ser usado para o método shuffle\n","\n","    Retorna:\n","      dataset (TF Dataset) - Conjunto de dados TF contendo janelas de tempo\n","    \"\"\"\n","\n","    # Gerar um conjunto de dados TF a partir dos valores da série\n","    dataset = tf.data.Dataset.from_tensor_slices(series)\n","\n","    # Janela de dados, mas só pega aqueles com o tamanho especificado\n","    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n","\n","    # Achatar as janelas, colocando seus elementos em um único lote\n","    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n","\n","    # Criar tuplas com recursos e rótulos\n","    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n","\n","    # Embaralhar as janelas\n","    dataset = dataset.shuffle(shuffle_buffer)\n","\n","    # Criar lotes de janelas\n","    dataset = dataset.batch(batch_size).prefetch(1)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvmPMWqhqkUh"},"outputs":[],"source":["# Gerar as janelas do conjunto de dados\n","dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDUsp8n99Zhd"},"outputs":[],"source":["# Imprimir formato de recursos e rótulos\n","for window in dataset.take(1):\n","  print(f'shape of feature: {window[0].shape}')\n","  print(f'shape of label: {window[1].shape}')"]},{"cell_type":"markdown","metadata":{},"source":["## Construir o modelo\n","\n","Seu modelo é composto principalmente de camadas [SimpleRNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN). Esse tipo de RNN simplesmente encaminha sua saída de volta para a entrada. Você empilhará duas dessas camadas em seu modelo, de modo que a primeira deve ter `return_sequences` definida como `True`.\n","\n","Conforme mencionado na [documentação](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN#call_arguments), as camadas `SimpleRNN` esperam uma entrada de tensor tridimensional com a forma `[batch, timesteps, feature`]. Com isso, você precisa remodelar sua janela de `(32, 20)` para `(32, 20, 1)`. Isso significa que os 20 pontos de dados na janela serão mapeados para 20 intervalos de tempo do RNN. Você pode fazer essa remodelagem em uma célula separada, mas também pode fazer isso dentro do próprio modelo usando camadas [Lambda](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda). Observe a primeira camada abaixo. Ela define uma função lambda que adiciona uma dimensão no último eixo da entrada. Essa é exatamente a transformação de que você precisa. Para o `input_shape`, você pode especificar `None` se quiser que o modelo seja mais flexível com o número de passos de tempo. Como alternativa, você pode defini-lo como `window_size`, conforme mostrado abaixo, se quiser definir a dimensão `timesteps` com o tamanho esperado das janelas de dados.\n","\n","Normalmente, você pode ter apenas uma saída de camada `Dense` como mostrado nos laboratórios anteriores. No entanto, você pode ajudar no treinamento aumentando a escala da saída para que ela tenha aproximadamente o mesmo valor dos rótulos. Isso dependerá das [funções de ativação](https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions) que você usou no modelo. O `SimpleRNN` usa *tanh* por padrão e tem um intervalo de saída de `[-1,1]`. Você usará outra camada `Lambda()` para dimensionar a saída em 100 antes de ajustar os pesos da camada. Sinta-se à vontade para remover essa camada depois deste laboratório e ver os resultados obtidos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4nblWkqg1NL"},"outputs":[],"source":["# Construa o modelo\n","model_tune = tf.keras.models.Sequential([\n","  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n","                      input_shape=[window_size]),\n","  tf.keras.layers.SimpleRNN(40, return_sequences=True),\n","  tf.keras.layers.SimpleRNN(40),\n","  tf.keras.layers.Dense(1),\n","  tf.keras.layers.Lambda(lambda x: x * 100.0)\n","])\n","\n","# Exiba os resultados\n","model_tune.summary()"]},{"cell_type":"markdown","metadata":{"id":"0SI_wtyh4PV1"},"source":["## Ajuste a taxa de aprendizagem\n","\n","Em seguida, você ajustará a taxa de aprendizagem como antes. Você definirá um planejamento de taxa de aprendizagem que altere esse hiperparâmetro dinamicamente. Você usará a [Perda de Huber](https://en.wikipedia.org/wiki/Huber_loss) como sua função de perda para minimizar a sensibilidade a outliers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JuO12ZOq4Gy"},"outputs":[],"source":["# Definir o agendador de taxa de aprendizado\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n","    lambda epoch: 1e-8 * 10**(epoch / 20))\n","\n","# Inicializar o otimizador\n","optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n","\n","# Definir os parâmetros de treinamento\n","model_tune.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n","\n","# Treinar o modelo\n","history = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])"]},{"cell_type":"markdown","metadata":{"id":"JnwxnPNhdwUI"},"source":["Você pode visualizar os resultados e escolher uma taxa de aprendizado ideal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5He3pp-Hj758"},"outputs":[],"source":["# Definir a matriz de taxa de aprendizado\n","lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n","\n","# Definir o tamanho da figura\n","plt.figure(figsize=(10, 6))\n","\n","# Definir a grade\n","plt.grid(True)\n","\n","# Plotar a perda em escala logarítmica\n","plt.semilogx(lrs, history.history[\"loss\"])\n","\n","# Aumentar o tamanho dos tickmarks\n","plt.tick_params('both', length=10, width=1, which='both')\n","\n","# Definir os limites do gráfico\n","plt.axis([1e-8, 1e-3, 0, 50])"]},{"cell_type":"markdown","metadata":{"id":"lKLJz8umd1wO"},"source":["Você pode alterar os limites do gráfico se quiser aumentar o zoom. A célula abaixo escolhe um intervalo mais estreito para que você possa ver mais claramente onde o gráfico se torna instável."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-XbgGzpuuVF"},"outputs":[],"source":["# Definir o tamanho da figura\n","plt.figure(figsize=(10, 6))\n","\n","# Definir a grade\n","plt.grid(True)\n","\n","# Plotar a perda em escala logarítmica\n","plt.semilogx(lrs, history.history[\"loss\"])\n","\n","# Aumentar o tamanho dos tickmarks\n","plt.tick_params('both', length=10, width=1, which='both')\n","\n","# Definir os limites do gráfico\n","plt.axis([1e-7, 1e-4, 0, 20])"]},{"cell_type":"markdown","metadata":{"id":"PD8-TGbAJUNj"},"source":["## Treinar o modelo\n","\n","Em seguida, você pode declarar o modelo novamente e treinar com a taxa de aprendizado que escolheu. Por padrão, ela é definida como `1e-6`, mas fique à vontade para alterá-la."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6y1KMowRkHkC"},"outputs":[],"source":["# Construir o modelo\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n","                      input_shape=[window_size]),\n","  tf.keras.layers.SimpleRNN(40, return_sequences=True),\n","  tf.keras.layers.SimpleRNN(40),\n","  tf.keras.layers.Dense(1),\n","  tf.keras.layers.Lambda(lambda x: x * 100.0)\n","])\n","\n","# Definir a taxa de aprendizado\n","learning_rate = 1e-6\n","\n","# Definir o otimizador\n","optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n","\n","# Definir os parâmetros de treinamento\n","model.compile(loss=tf.keras.losses.Huber(),\n","              optimizer=optimizer,\n","              metrics=[\"mae\"])\n","\n","# Treinar o modelo\n","history = model.fit(dataset,epochs=100)"]},{"cell_type":"markdown","metadata":{"id":"ewNczbMaJz5Q"},"source":["## Previsão do modelo\n","\n","Agora é hora de gerar as previsões do modelo para o intervalo de tempo do conjunto de validação. O modelo é muito maior do que os que você usou anteriormente e a natureza sequencial dos RNNs (ou seja, as entradas passam por uma série de etapas de tempo em vez de processamento paralelo) pode tornar as previsões um pouco lentas. Você pode observar isso ao usar o código que executou no laboratório anterior. Isso levará cerca de um minuto para ser concluído."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejBynEKekaKw"},"outputs":[],"source":["# Initialize a list\n","forecast = []\n","\n","# Reduzir a série original\n","forecast_series = series[split_time - window_size:]\n","\n","# Use o modelo para prever pontos de dados por tamanho de janela\n","for time in range(len(forecast_series) - window_size):\n","  forecast.append(model.predict(forecast_series[time:time + window_size][np.newaxis]))\n","\n","# Converta em uma matriz numérica e elimine os eixos de dimensão única\n","results = np.array(forecast).squeeze()\n","\n","# Plotar os resultados\n","plot_series(time_valid, (x_valid, results))"]},{"cell_type":"markdown","metadata":{"id":"Hn1QZd7LgCcu"},"source":["Você pode otimizar essa etapa aproveitando a capacidade dos modelos do Tensorflow de processar lotes. Em vez de executar o loop for acima, que processa uma única janela de cada vez, você pode passar um lote inteiro de janelas e deixar que o modelo as processe em paralelo.\n","\n","A função abaixo faz exatamente isso. Você notará que ela quase espelha a função `windowed_dataset()`, mas não embaralha as janelas. Isso ocorre porque queremos que a saída esteja em sua sequência adequada para que possamos compará-la corretamente com o conjunto de validação."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ym73y-pDKp-X"},"outputs":[],"source":["def model_forecast(model, series, window_size, batch_size):\n","    \"\"\"Usa um modelo de entrada para gerar previsões em janelas de dados\n","\n","    Args:\n","      model (TF Keras Model) - modelo que aceita janelas de dados\n","      series (vetor de float) - contém os valores da série temporal\n","      window_size (int) - o número de etapas de tempo a serem incluídas na janela\n","      batch_size (int) - o tamanho do lote\n","\n","    Retorna:\n","      forecast (matriz numpy) - matriz que contém as previsões\n","    \"\"\"\n","\n","    # Generate a TF dataset from the values in the series\n","    dataset = tf.data.Dataset.from_tensor_slices(series)\n","\n","    # Janela de dados, mas só pega aqueles com o tamanho especificado\n","    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n","\n","    # Achatar as janelas, colocando seus elementos em um único lote\n","    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n","\n","    # Criar lotes de janelas\n","    dataset = dataset.batch(batch_size).prefetch(1)\n","\n","    # Obter previsões em todo o conjunto de dados\n","    forecast = model.predict(dataset)\n","\n","    return forecast"]},{"cell_type":"markdown","metadata":{"id":"VrRFuUcfieQN"},"source":["Você pode executar a função abaixo para usar a função. Observe que as previsões são geradas quase instantaneamente.\n","\n","*Observação: você pode notar que a primeira linha corta a `série` em `split_time - window_size:-1`, o que é um pouco diferente do código for-loop mais lento. Isso ocorre porque queremos que o modelo tenha sua última previsão alinhada com o último ponto do conjunto de validação (ou seja, `t=1460`). Você conseguiu fazer isso com o código for-loop mais lento especificando o `range()` do for-loop. Com a função mais eficiente acima, você não tem esse mecanismo, portanto, em vez disso, basta remover o último ponto ao cortar a `série`. Se você não fizer isso, a função gerará uma previsão em `t=1461` que está fora do intervalo do conjunto de validação.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m23ny5uh8KTt"},"outputs":[],"source":["# Reduzir a série original\n","forecast_series = series[split_time - window_size:-1]\n","\n","# Use a função auxiliar para gerar previsões\n","forecast = model_forecast(model, forecast_series, window_size, batch_size)\n","\n","# Soltar eixo unidimensional\n","results = forecast.squeeze()\n","\n","# Plotar os resultados\n","plot_series(time_valid, (x_valid, results))"]},{"cell_type":"markdown","metadata":{"id":"7cVUoLH7k5NG"},"source":["Em seguida, você pode calcular o MSE e o MAE. Você pode comparar os resultados aqui ao usar outras arquiteturas RNN, o que será feito no próximo laboratório."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxK8haPCL48G"},"outputs":[],"source":["# Calcular o MSE e o MAE\n","print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\n","print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
