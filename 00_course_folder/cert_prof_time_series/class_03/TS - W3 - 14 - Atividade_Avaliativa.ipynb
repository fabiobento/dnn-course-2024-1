{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27a5501",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_time_series/class_03/TS%20-%20W3%20-%2014%20-%20Atividade_Avaliativa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72390a",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eea74",
   "metadata": {},
   "source": [
    "# Uso de RNNs para prever séries temporais\n",
    "\n",
    "Bem-vindo! Na atividade avaliativa anterior, você usou uma rede neural profunda vanilla para criar previsões para séries temporais geradas.\n",
    "\n",
    "Desta vez, você usará as camadas do Tensorflow para processar dados de sequência, como as camadas Recurrent ou LSTMs, para ver como essas duas abordagens se comparam.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/cert_prof_time_series/class_03/saved_model_images.zip\n",
    "!unzip -n -q saved_model_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da902388",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjujz601HcS",
    "outputId": "b0a53dee-523b-4a27-b31d-2a1daed0df1c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74720e74",
   "metadata": {},
   "source": [
    "## Gerando os dados\n",
    "\n",
    "A próxima célula inclui um conjunto de funções auxiliares para gerar e plotar a série temporal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Tempo\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.grid(False)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Apenas um padrão arbitrário, você pode alterá-lo se desejar\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 6 * np.pi),\n",
    "                    2 / np.exp(9 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repete o mesmo padrão em cada período\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d883a",
   "metadata": {},
   "source": [
    "Você gerará os mesmos dados de série temporal sintéticos dos laboratórios passados.\n",
    "\n",
    "**Observe que, desta vez, toda a geração é feita em uma função e as variáveis globais são salvas em uma classe de dados. Isso é feito para evitar o uso do escopo global, como foi feito anteriormente no curso.**\n",
    "\n",
    "Se você nunca usou classes de dados antes, elas são apenas classes Python que fornecem uma sintaxe conveniente para armazenar dados. Você pode ler mais sobre elas em [docs](https://docs.python.org/3/library/dataclasses.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aadcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series():\n",
    "    # A dimensão de tempo ou a coordenada x da série temporal\n",
    "    time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "\n",
    "    # A série inicial é apenas uma linha reta com uma interceptação y\n",
    "    y_intercept = 10\n",
    "    slope = 0.005\n",
    "    series = trend(time, slope) + y_intercept\n",
    "\n",
    "    # Adição de sazonalidade\n",
    "    amplitude = 50\n",
    "    series += seasonality(time, period=365, amplitude=amplitude)\n",
    "\n",
    "    # Adicionando algum ruído\n",
    "    noise_level = 3\n",
    "    series += noise(time, noise_level, seed=51)\n",
    "    \n",
    "    return time, series\n",
    "\n",
    "\n",
    "# Salve todas as variáveis \"globais\" na classe G (G significa global)\n",
    "@dataclass\n",
    "class G:\n",
    "    TIME, SERIES = generate_time_series()\n",
    "    SPLIT_TIME = 1100\n",
    "    WINDOW_SIZE = 20\n",
    "    BATCH_SIZE = 32\n",
    "    SHUFFLE_BUFFER_SIZE = 1000\n",
    "    \n",
    "\n",
    "# Plotar a série gerada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(G.TIME, G.SERIES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e8341",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "Como você já codificou as funções `train_val_split` e `windowed_dataset` durante as atividades anteriores, desta vez elas são fornecidas para você:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d80b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(time, series, time_step=G.SPLIT_TIME):\n",
    "\n",
    "    time_train = time[:time_step]\n",
    "    series_train = series[:time_step]\n",
    "    time_valid = time[time_step:]\n",
    "    series_valid = series[time_step:]\n",
    "\n",
    "    return time_train, series_train, time_valid, series_valid\n",
    "\n",
    "\n",
    "# Dividir o conjunto de dados\n",
    "time_train, series_train, time_valid, series_valid = train_val_split(G.TIME, G.SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d65bc2",
   "metadata": {
    "id": "4sTTIOCbyShY"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "# Aplicar a transformação ao conjunto de treinamento\n",
    "dataset = windowed_dataset(series_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c3746",
   "metadata": {},
   "source": [
    "## Definição da arquitetura do modelo\n",
    "\n",
    "Agora que você tem uma função que processará os dados antes que eles sejam inseridos na rede neural para treinamento, é hora de definir a arquitetura das camadas. Diferentemente das semanas ou cursos anteriores, nos quais você define as camadas e compila o modelo na mesma função, aqui você precisará primeiro concluir a função `create_uncompiled_model` abaixo. \n",
    "\n",
    "Isso é feito para que você possa reutilizar as camadas do seu modelo para o ajuste da taxa de aprendizado e o treinamento real.\n",
    "\n",
    "Dica:\n",
    "- Preencha as camadas `Lambda` no início e no final da rede com as funções lamda corretas.\n",
    "- Você deve usar `SimpleRNN` ou `Bidirectional(LSTM)` como camadas intermediárias.\n",
    "- A última camada da rede (antes da última `Lambda`) deve ser uma camada `Dense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded09736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uncompiled_model():\n",
    "\n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "    \n",
    "    model = tf.keras.models.Sequential([ \n",
    "        tf.keras.layers.Lambda(),\n",
    "        \n",
    "        tf.keras.layers.Lambda()\n",
    "    ]) \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste seu modelo não compilado\n",
    "uncompiled_model = create_uncompiled_model()\n",
    "\n",
    "try:\n",
    "    uncompiled_model.predict(dataset)\n",
    "except:\n",
    "    print(\"Sua arquitetura atual é incompatível com o conjunto de dados em janela, tente ajustá-la.\")\n",
    "else:\n",
    "    print(\"Sua arquitetura atual é compatível com o conjunto de dados com janelas!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fcb6b",
   "metadata": {},
   "source": [
    "## Ajuste da taxa de aprendizado\n",
    "\n",
    "Como você viu na aula, é possível aproveitar os _callbacks_ do Tensorflow para variar dinamicamente a taxa de aprendizagem durante o treinamento. Isso pode ser útil para ter uma noção melhor de qual taxa de aprendizado se adapta melhor ao problema em questão.\n",
    "\n",
    "**Observe que isso é apenas uma alteração da taxa de aprendizado durante o processo de treinamento para lhe dar uma ideia de qual é uma taxa de aprendizado razoável e não deve ser confundido com a seleção da melhor taxa de aprendizado, o que é conhecido como [otimização de hiperparâmetros](https://www.tensorflow.org/tutorials/keras/keras_tuner).**\n",
    "\n",
    "Para os otimizadores, você pode experimentar:\n",
    "- [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)\n",
    "- [`tf.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) com um momentum de 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate():\n",
    "    \n",
    "    model = create_uncompiled_model()\n",
    "    \n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "    \n",
    "    # Selecione seu otimizador\n",
    "    optimizer = None\n",
    "    \n",
    "    # Compile o modelo passando a perda apropriada\n",
    "    model.compile(loss=None,\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"mae\"]) \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "    \n",
    "    history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o treinamento com LR dinâmico\n",
    "lr_history = adjust_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1977dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traçar a perda para cada LR\n",
    "plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\n",
    "plt.axis([1e-6, 1, 0, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1971fd3a",
   "metadata": {},
   "source": [
    "## Compilação do modelo\n",
    "\n",
    "Agora que você treinou o modelo variando a taxa de aprendizado, é hora de fazer o treinamento real que será usado para prever a série temporal. Para isso, conclua a função `create_model` abaixo.\n",
    "\n",
    "Observe que você está reutilizando a arquitetura definida anteriormente em `create_uncompiled_model`. Agora você só precisa compilar esse modelo usando a perda, o otimizador (e a taxa de aprendizado) apropriados.\n",
    "\n",
    "Dica:\n",
    "- O treinamento deve ser muito rápido, portanto, se perceber que cada época está demorando mais do que alguns segundos, considere tentar uma arquitetura diferente.\n",
    "\n",
    "\n",
    "- Se após a primeira época você obtiver uma saída como esta: `loss: nan - mae: nan`, é muito provável que sua rede esteja sofrendo com a explosão de gradientes. Esse é um problema comum se você usou o `SGD` como otimizador e definiu uma taxa de aprendizado muito alta. **Se você encontrar esse problema, considere reduzir a taxa de aprendizado ou usar o Adam com a taxa de aprendizado padrão.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    tf.random.set_seed(51)\n",
    "    \n",
    "    model = create_uncompiled_model()\n",
    "\n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "\n",
    "    model.compile(loss=None,\n",
    "                  optimizer=None,\n",
    "                  metrics=[\"mae\"])  \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar uma instância do modelo\n",
    "model = create_model()\n",
    "\n",
    "# Treine-o\n",
    "history = model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aeabb6",
   "metadata": {},
   "source": [
    "## Avaliação da previsão\n",
    "\n",
    "Agora é hora de avaliar o desempenho da previsão. Para isso, você pode usar a função `compute_metrics` que codificou em uma tarefa anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_series, forecast):\n",
    "    \n",
    "    mse = tf.keras.metrics.mean_squared_error(true_series, forecast).numpy()\n",
    "    mae = tf.keras.metrics.mean_absolute_error(true_series, forecast).numpy()\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1e989",
   "metadata": {},
   "source": [
    "Nesse momento, apenas o modelo que realizará a previsão está pronto, mas você ainda precisa calcular a previsão real. \n",
    "\n",
    "## Previsões de modelo mais rápidas\n",
    "\n",
    "Na semana anterior, você usou um loop for para calcular as previsões para cada ponto da sequência. Essa abordagem é válida, mas há uma maneira mais eficiente de fazer a mesma coisa usando lotes de dados. O código para implementar isso é fornecido no `model_forecast` abaixo. Observe que o código é muito semelhante ao da função `windowed_dataset` com a diferença de que:\n",
    "\n",
    "- O conjunto de dados é janelado usando `window_size` em vez de `window_size + 1`\n",
    "- Não deve ser usado shuffle\n",
    "- Não há necessidade de dividir os dados em recursos e rótulos\n",
    "- Um modelo é usado para prever lotes do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(32).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a previsão para todas as séries\n",
    "rnn_forecast = model_forecast(model, G.SERIES, G.WINDOW_SIZE).squeeze()\n",
    "\n",
    "# Corte a previsão para obter apenas as previsões para o conjunto de validação\n",
    "rnn_forecast = rnn_forecast[G.SPLIT_TIME - G.WINDOW_SIZE:-1]\n",
    "\n",
    "# Plote-o\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plot_series(time_valid, series_valid)\n",
    "plot_series(time_valid, rnn_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212c8a9",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "Uma série semelhante a esta:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/expected.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = compute_metrics(series_valid, rnn_forecast)\n",
    "\n",
    "print(f\"mse: {mse:.2f}, mae: {mae:.2f} for forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1d7cd",
   "metadata": {},
   "source": [
    "**Para ser aprovado nesta tarefa, sua previsão deve atingir um MAE de 4,5 ou menos.**\n",
    "\n",
    "- Se a sua previsão não atingir esse limite, tente treinar novamente o modelo com uma arquitetura diferente (será necessário executar novamente as funções `create_uncompiled_model` e `create_model`) ou ajustar os parâmetros do otimizador.\n",
    "\n",
    "\n",
    "- Se a sua previsão atingiu esse limite, execute a seguinte célula para salvar o seu modelo em um arquivo `tar` que será usado para avaliação e, depois disso, envie o seu trabalho para avaliação.\n",
    "\n",
    "\n",
    "- Esse ambiente inclui um diretório fictício `SavedModel` que contém um modelo fictício treinado para uma época. **Para substituir esse arquivo pelo seu modelo real, você precisa executar a próxima célula antes de enviá-lo para avaliação.**\n",
    "\n",
    "\n",
    "- Diferentemente da atividade avaliativa anterior, desta vez o modelo é salvo usando o formato `SavedModel`. Isso é feito porque o formato HDF5 não suporta totalmente as camadas `Lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve seu modelo no formato SavedModel\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "# Comprimir o diretório usando tar\n",
    "! tar -czvf saved_model.tar.gz saved_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afab213",
   "metadata": {},
   "source": [
    "**Parabéns por ter concluído essa atividade!**\n",
    "\n",
    "Você implementou com sucesso uma rede neural capaz de prever séries temporais aproveitando as camadas do Tensorflow para modelagem de sequências, como `RNNs` e `LSTMs`! **Isso resultou em uma previsão que corresponde (ou até mesmo supera) a da atividade avaliativa anterior durante o treinamento de metade das épocas.**\n",
    "\n",
    "**Continue assim!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
