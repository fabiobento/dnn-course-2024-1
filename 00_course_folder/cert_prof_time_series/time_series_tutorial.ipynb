{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_time_series/time_series_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["[adaptado do tutorial [_Time series forecasting_](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [_Tensorflow Core Tutorials_](https://www.tensorflow.org/tutorials)]"]},{"cell_type":"markdown","metadata":{"id":"pa49bUnKyRgF"},"source":["# Previsão de séries temporais"]},{"cell_type":"markdown","metadata":{"id":"GU8C5qm_4vZb"},"source":["Este tutorial é uma introdução à previsão de séries temporais.\n","\n","Serão utilizados diferentes tipos de modelos, incluindo Redes Neurais Convolucionais e Recorrentes (CNNs e RNNs).\n","\n","O tema será abordado em duas partes principais, com subsecções:\n","\n","* Previsão para um único passo de tempo:\n","  * Uma única caraterística.\n","  * Todas as características.\n","* Previsão de vários passos:\n","  Previsão para uma única etapa:\n","  * Uma única caraterística(_single-shot_): Faz as previsões de uma só vez.\n","  * Autoregressivo: Fazer uma previsão de cada vez e alimenta o modelo com o resultado.\n"]},{"cell_type":"markdown","metadata":{"id":"XVhK72Pu1cJL"},"source":["## Configuração"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7rZnJaGTWQw0"},"outputs":[],"source":["import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"]},{"cell_type":"markdown","metadata":{"id":"TokBlnUhWFw9"},"source":["## Um conjunto de dados meteorológicos\n","\n","Esse tutorial usa <a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">weather time series dataset</a> registrado pelo <a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">Max Planck Institute for Biogeochemistry</a>.\n","\n","Este conjunto de dados contém 14 características diferentes, como a temperatura do ar, a pressão atmosférica e a humidade.\n"," Estes dados foram recolhidos a cada 10 minutos, com início em 2003. Para maior eficiência, utilizará apenas os dados recolhidos entre 2009 e 2016.\n","\n"," Esta secção do conjunto de dados foi preparada por François Chollet para o seu livro  <a href=\"https://www.manning.com/books/deep-learning-with-python\" class=\"external\">Deep Learning with Python</a>."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1712177852200,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"xyv_i85IWInT","outputId":"e4184d74-7a8e-40cb-a03b-12a91628ac88"},"outputs":[],"source":["zip_path = tf.keras.utils.get_file(\n","    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n","    fname='jena_climate_2009_2016.csv.zip',\n","    extract=True)\n","csv_path, _ = os.path.splitext(zip_path)"]},{"cell_type":"markdown","metadata":{"id":"R81Wx8WP4c3G"},"source":["Este tutorial só vai lidar com **previsões horárias**, por isso começamos por subamostrar os dados de intervalos de 10 minutos para intervalos de uma hora:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TX6uGeeeWIkG"},"outputs":[],"source":["df = pd.read_csv(csv_path)\n","# \"Fatie\" [start:stop:step], começando do índice 5 e pegando cada 6° registro.\n","df = df[5::6]\n","\n","date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"]},{"cell_type":"markdown","metadata":{"id":"VdbOWXiTWM2T"},"source":["Vamos dar uma olhadela aos dados. Aqui estão as primeiras linhas:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1712178003115,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"ojHE-iCCWIhz","outputId":"1cf1f84c-78ff-4da2-e8d7-0c4a30bb27fd"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"WRzj1inMfgcO"},"source":["Confira a evolução de algumas características ao longo do tempo:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4597,"status":"ok","timestamp":1712178108368,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"Vg5XIc5tfNlG","outputId":"86678320-861f-43aa-e4b6-034ae44790ca"},"outputs":[],"source":["plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n","plot_features = df[plot_cols]\n","plot_features.index = date_time\n","_ = plot_features.plot(subplots=True)\n","\n","plot_features = df[plot_cols][:480]\n","plot_features.index = date_time[:480]\n","_ = plot_features.plot(subplots=True)"]},{"cell_type":"markdown","metadata":{"id":"wXWLG0_WBhZS"},"source":["### Inspeção e limpeza"]},{"cell_type":"markdown","metadata":{"id":"yhmZXJew6GlS"},"source":["De seguida, veja as estatísticas do conjunto de dados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h510pgKVrrai"},"outputs":[],"source":["df.describe().transpose()"]},{"cell_type":"markdown","metadata":{"id":"TzOTnWOoWMGK"},"source":["#### Velocidade do vento"]},{"cell_type":"markdown","metadata":{"id":"i47LiW5DCVsP"},"source":["Uma coisa que deve ser destacada é o valor `min` das colunas de velocidade do vento (`wv (m/s)`) e o valor máximo (`max. wv (m/s)`). Este `-9999` é provavelmente incorreto.\n","\n","Existe uma coluna separada de direção do vento, por isso a velocidade deve ser maior que zero (`>=0`). Substitua-o por zeros:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFOq0_80vF4d"},"outputs":[],"source":["wv = df['wv (m/s)']\n","bad_wv = wv == -9999.0\n","wv[bad_wv] = 0.0\n","\n","max_wv = df['max. wv (m/s)']\n","bad_max_wv = max_wv == -9999.0\n","max_wv[bad_max_wv] = 0.0\n","\n","# The above inplace edits are reflected in the DataFrame.\n","df['wv (m/s)'].min()"]},{"cell_type":"markdown","metadata":{"id":"vtmu2IBPgPG8"},"source":["### Engenharia de recursos\n","\n","Antes de começar a construir um modelo, é importante compreender os seus dados e certificar-se de que está transmitindo ao modelo dados formatados de forma adequada."]},{"cell_type":"markdown","metadata":{"id":"FYyEaqiD6j4s"},"source":["#### Vento\n","A última coluna dos dados, `wd (deg)`, indica a direção do vento em unidades de graus. Os ângulos não são boas entradas para o modelo: 360° e 0° devem estar próximos um do outro.\n","\n","A direção não deve ter importância se o vento não estiver soprando.\n","\n","Atualmente, a distribuição dos dados do vento tem este aspecto:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"elapsed":930,"status":"ok","timestamp":1712179222921,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"YO7JGTcWQG2z","outputId":"7d8fadf4-002d-4034-ccdd-28740a3dc78a"},"outputs":[],"source":["plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n","plt.colorbar()\n","plt.xlabel('Direção do Vento [deg]')\n","plt.ylabel('Velocidade do Vento [m/s]')"]},{"cell_type":"markdown","metadata":{"id":"yWnf5dwMU1_g"},"source":["Mas será mais fácil para o modelo interpretar se você converter as colunas de direção e velocidade do vento em um **vetor** de vento:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GmSTHXw6lI1"},"outputs":[],"source":["wv = df.pop('wv (m/s)')\n","max_wv = df.pop('max. wv (m/s)')\n","\n","# Converter para radianos.\n","wd_rad = df.pop('wd (deg)')*np.pi / 180\n","\n","# Calcular os componentes x e y do vento.\n","df['Wx'] = wv*np.cos(wd_rad)\n","df['Wy'] = wv*np.sin(wd_rad)\n","\n","# Calcular os componentes máximo x e y do vento.\n","df['max Wx'] = max_wv*np.cos(wd_rad)\n","df['max Wy'] = max_wv*np.sin(wd_rad)"]},{"cell_type":"markdown","metadata":{"id":"7iI0zDoxWDyB"},"source":["A distribuição dos vetores de vento é muito mais simples de ser interpretada corretamente pelo modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMgCG5o2SYKD"},"outputs":[],"source":["plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n","plt.colorbar()\n","plt.xlabel('Wind X [m/s]')\n","plt.ylabel('Wind Y [m/s]')\n","ax = plt.gca()\n","ax.axis('tight')"]},{"cell_type":"markdown","metadata":{"id":"_8im1ttOWlRB"},"source":["#### Tempo"]},{"cell_type":"markdown","metadata":{"id":"7YE21HKK40zQ"},"source":["Da mesma forma, a coluna `Date Time` é muito útil, mas não nessa forma de string. Comece convertendo-a em segundos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIFf-VjMfnh3"},"outputs":[],"source":["timestamp_s = date_time.map(pd.Timestamp.timestamp)"]},{"cell_type":"markdown","metadata":{"id":"EC_pnM1D5Sgc"},"source":["Da mesma forma que a direção do vento, o tempo em segundos não é uma entrada útil para o modelo.\n","\n","Por serem dados meteorológicos, eles têm uma clara periodicidade diária e anual. Há muitas maneiras de lidar com a periodicidade.\n","\n","Você pode obter sinais utilizáveis usando transformações de seno e cosseno para limpar os sinais de \"_Time of day_\" e \"_Time of year_\":"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBfX6CDwax73"},"outputs":[],"source":["day = 24*60*60\n","year = (365.2425)*day\n","\n","df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n","df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n","df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n","df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXBbTJZfuuTC"},"outputs":[],"source":["plt.plot(np.array(df['Day sin'])[:25])\n","plt.plot(np.array(df['Day cos'])[:25])\n","plt.xlabel('Tempo [h]')\n","plt.title('Sinal de hora do dia')"]},{"cell_type":"markdown","metadata":{"id":"HiurzTGQgf_D"},"source":["Isso dá ao modelo acesso aos recursos de frequência mais importantes.\n","\n","Nesse caso, você sabia antecipadamente quais frequências eram importantes.\n","\n","Se você não tiver essas informações, poderá determinar quais frequências são importantes extraindo recursos com <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\">Transformada Rápida de Fourier(_Fast Fourier Transform_-FFT)</a>.\n","\n","Para verificar as suposições, aqui está o `tf.signal.rfft` da temperatura ao longo do tempo. Observe os picos óbvios em frequências próximas a `1/ano` e `1/dia`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EN4U1fcMiTYs"},"outputs":[],"source":["fft = tf.signal.rfft(df['T (degC)'])\n","f_per_dataset = np.arange(0, len(fft))\n","\n","n_samples_h = len(df['T (degC)'])\n","hours_per_year = 24*365.2524\n","years_per_dataset = n_samples_h/(hours_per_year)\n","\n","f_per_year = f_per_dataset/years_per_dataset\n","plt.step(f_per_year, np.abs(fft))\n","plt.xscale('log')\n","plt.ylim(0, 400000)\n","plt.xlim([0.1, max(plt.xlim())])\n","plt.xticks([1, 365.2524], labels=['1/Ano', '1/dia'])\n","_ = plt.xlabel('Frequência (escala logarítmica)')"]},{"cell_type":"markdown","metadata":{"id":"2rbL8bSGDHy3"},"source":["### Dividir os dados"]},{"cell_type":"markdown","metadata":{"id":"qoFJZmXBaxCc"},"source":["Você usará uma divisão `(70%, 20%, 10%)` para os conjuntos de treinamento, validação e teste.\n","\n","Observe que os dados **não** estão sendo embaralhados aleatoriamente antes da divisão. Isso ocorre por dois motivos:\n","\n","1. Ele garante que a divisão dos dados em janelas de amostras consecutivas ainda seja possível.\n","2. Garante que os resultados da validação/teste sejam mais realistas, sendo avaliados nos dados coletados depois que o modelo foi treinado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ia-MPAHxbInX"},"outputs":[],"source":["column_indices = {name: i for i, name in enumerate(df.columns)}\n","\n","n = len(df)\n","train_df = df[0:int(n*0.7)]\n","val_df = df[int(n*0.7):int(n*0.9)]\n","test_df = df[int(n*0.9):]\n","\n","num_features = df.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"-eFckdUUHWmT"},"source":["### Normalizar os dados\n","\n","É importante dimensionar os recursos antes de treinar uma rede neural. A normalização é uma forma comum de fazer esse dimensionamento: subtraia a média e divida pelo desvio padrão de cada recurso."]},{"cell_type":"markdown","metadata":{"id":"mxbIic5TMlxx"},"source":["A média e o desvio padrão só devem ser calculados usando os dados de treinamento para que os modelos não tenham acesso aos valores nos conjuntos de validação e teste.\n","\n","Também é possível argumentar que o modelo não deve ter acesso a valores futuros no conjunto de treinamento durante o treinamento e que essa normalização deve ser feita usando médias móveis.\n","\n","Esse não é o foco deste tutorial, e os conjuntos de validação e teste garantem que você obtenha métricas (de certa forma) honestas. Portanto, para simplificar, utilizaremos nesse tutorial usa uma média simples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eji6njXvHusN"},"outputs":[],"source":["train_mean = train_df.mean()\n","train_std = train_df.std()\n","\n","train_df = (train_df - train_mean) / train_std\n","val_df = (val_df - train_mean) / train_std\n","test_df = (test_df - train_mean) / train_std"]},{"cell_type":"markdown","metadata":{"id":"G6ufs8kk9JQw"},"source":["Agora, dê uma olhada na distribuição dos recursos. Alguns recursos têm caudas longas, mas não há erros óbvios como o valor `-9999` da velocidade do vento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0UYEnkwm8Fe"},"outputs":[],"source":["df_std = (df - train_mean) / train_std\n","df_std = df_std.melt(var_name='Column', value_name='Normalized')\n","plt.figure(figsize=(12, 6))\n","ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n","_ = ax.set_xticklabels(df.keys(), rotation=90)"]},{"cell_type":"markdown","metadata":{"id":"ZBBmdxZ2HgfJ"},"source":["## Janelamento de dados\n","\n","Os modelos deste tutorial farão um conjunto de previsões com base em uma janela de amostras consecutivas dos dados.\n","\n","As principais características das janelas de entrada são:\n","\n","- A largura (número de etapas de tempo) das janelas de entrada e de rótulo.\n","- O deslocamento de tempo entre elas.\n","- Quais recursos são usados como entradas, rótulos ou ambos.\n","\n","Este tutorial cria uma variedade de modelos (incluindo modelos Linear, DNN, CNN e RNN) e os utiliza para ambos:\n","\n","- Previsões de *single-output* e *multi-output*.\n","- Previsões *Single-time-step* e *multi-time-step*.\n","\n","Esta seção se concentra na implementação do janelamento de dados para que ele possa ser reutilizado em todos esses modelos.\n"]},{"cell_type":"markdown","metadata":{"id":"YAhGUVx1jtOy"},"source":["Dependendo da tarefa e do tipo de modelo, você pode querer gerar uma variedade de janelas de dados. Aqui estão alguns exemplos:\n","\n","1. Por exemplo, para fazer uma única previsão de 24 horas no futuro, considerando 24 horas de histórico, você pode definir uma janela como esta:\n","\n","  ![One prediction 24 hours into the future.](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/raw_window_24h.png?raw=1)\n","\n","2. Um modelo que faz uma previsão de uma hora no futuro, considerando seis horas de histórico, precisaria de uma janela como esta:\n","\n","  ![One prediction one hour into the future.](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/raw_window_1h.png?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"sa2BbfNZt8wy"},"source":["O restante desta seção define uma classe `WindowGenerator`. Essa classe pode:\n","\n","1. Manipular os índices e deslocamentos conforme mostrado nos diagramas acima.\n","1. Dividir janelas de recursos em pares `(recursos, rótulos)`.\n","2. Plotar o conteúdo das janelas resultantes.\n","3. Gerar com eficiência lotes dessas janelas a partir dos dados de treinamento, avaliação e teste, usando `tf.data.Dataset`."]},{"cell_type":"markdown","metadata":{"id":"rfx3jGjyziUF"},"source":["### 1. Índices e offsets\n","\n","Comece criando a classe `WindowGenerator`. O método `__init__` inclui toda a lógica necessária para os índices de entrada e de rótulo.\n","\n","Ele também recebe como entrada os DataFrames de treinamento, avaliação e teste. Eles serão convertidos em `tf.data.Dataset`s de janelas posteriormente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kem30j8QHxyW"},"outputs":[],"source":["class WindowGenerator():\n","  def __init__(self, input_width, label_width, shift,\n","               train_df=train_df, val_df=val_df, test_df=test_df,\n","               label_columns=None):\n","    # Armazene os dados brutos(raw data).\n","    self.train_df = train_df\n","    self.val_df = val_df\n","    self.test_df = test_df\n","\n","    # Calcule os índices da coluna do rótulo.\n","    self.label_columns = label_columns\n","    if label_columns is not None:\n","      self.label_columns_indices = {name: i for i, name in\n","                                    enumerate(label_columns)}\n","    self.column_indices = {name: i for i, name in\n","                           enumerate(train_df.columns)}\n","\n","    # Trabalhe com os parâmetros da janela.\n","    self.input_width = input_width\n","    self.label_width = label_width\n","    self.shift = shift\n","\n","    self.total_window_size = input_width + shift\n","\n","    self.input_slice = slice(0, input_width)\n","    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n","\n","    self.label_start = self.total_window_size - self.label_width\n","    self.labels_slice = slice(self.label_start, None)\n","    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n","\n","  def __repr__(self):\n","    return '\\n'.join([\n","        f'Tamanho total da janela: {self.total_window_size}',\n","        f'Índices de entrada: {self.input_indices}',\n","        f'Índices dos rótulos: {self.label_indices}',\n","        f'Nome(s) da coluna de rótulos: {self.label_columns}'])"]},{"cell_type":"markdown","metadata":{"id":"yVJgblsYzL1g"},"source":["Aqui está o código para criar as duas janelas mostradas nos diagramas no início desta seção:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsM5kRkz0UwK"},"outputs":[],"source":["w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n","                     label_columns=['T (degC)'])\n","w1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"viwKsYeAKFUn"},"outputs":[],"source":["w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n","                     label_columns=['T (degC)'])\n","w2"]},{"cell_type":"markdown","metadata":{"id":"kJaUyTWQJd-L"},"source":["### 2. Dividir\n","\n","Dada uma lista de entradas consecutivas, o método `split_window` as converterá em uma janela de entradas e uma janela de rótulos.\n","\n","O exemplo `w2` que você definiu anteriormente será dividido da seguinte forma:\n","\n","![A janela inicial é composta por todas as amostras consecutivas, o que a divide em pares (inputs, labels)](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/split_window.png?raw=1)\n","\n","Esse diagrama não mostra o eixo `features` dos dados, mas essa função `split_window` também manipula as `label_columns`, de modo que pode ser usada para os exemplos de saída única e saída múltipla."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4KbxfzqkXPW"},"outputs":[],"source":["def split_window(self, features):\n","  inputs = features[:, self.input_slice, :]\n","  labels = features[:, self.labels_slice, :]\n","  if self.label_columns is not None:\n","    labels = tf.stack(\n","        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n","        axis=-1)\n","\n","  # O fatiamento não preserva as informações de estáticas de formato de dados, portanto, defina as formas\n","  # manualmente. Dessa forma, os `tf.data.Datasets` são mais fáceis de inspecionar.\n","  inputs.set_shape([None, self.input_width, None])\n","  labels.set_shape([None, self.label_width, None])\n","\n","  return inputs, labels\n","\n","WindowGenerator.split_window = split_window"]},{"cell_type":"markdown","metadata":{"id":"G6U6VtVuM15s"},"source":["Experimente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YeCWbq6KLmL7"},"outputs":[],"source":["# Empilhar três fatias, o comprimento da janela total.\n","example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n","                           np.array(train_df[100:100+w2.total_window_size]),\n","                           np.array(train_df[200:200+w2.total_window_size])])\n","\n","example_inputs, example_labels = w2.split_window(example_window)\n","\n","print('Todas os formatos são: (lote, tempo, recursos)')\n","print(f'Formado da janela: {example_window.shape}')\n","print(f'Formato das entradas: {example_inputs.shape}')\n","print(f'Formato das saídas: {example_labels.shape}')"]},{"cell_type":"markdown","metadata":{"id":"xtMk1ffk2Mmd"},"source":["Normalmente, os dados no TensorFlow são empacotados em matrizes em que o índice mais externo é entre exemplos (a dimensão \"lote\"). Os índices intermediários são as dimensões de \"tempo\" ou \"espaço\" (largura, altura). Os índices mais internos são os recursos.\n","\n","O código acima pegou um lote de três janelas de 7 etapas de tempo com 19 recursos em cada etapa de tempo. Ele as divide em um lote de entradas de 19 recursos em 6 etapas de tempo e um rótulo de 1 recurso em 1 etapa de tempo. O rótulo tem apenas um recurso porque o `WindowGenerator` foi inicializado com `label_columns=['T (degC)']`. Inicialmente, este tutorial criará modelos que preveem rótulos de saída única."]},{"cell_type":"markdown","metadata":{"id":"tFZukGXrJoGo"},"source":["### 3. Plotagem\n","\n","Aqui está um método de plotagem que permite uma visualização simples da janela dividida:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmgd1qkYUWT7"},"outputs":[],"source":["w2.example = example_inputs, example_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIrYccI-Hm3B"},"outputs":[],"source":["def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n","  inputs, labels = self.example\n","  plt.figure(figsize=(12, 8))\n","  plot_col_index = self.column_indices[plot_col]\n","  max_n = min(max_subplots, len(inputs))\n","  for n in range(max_n):\n","    plt.subplot(max_n, 1, n+1)\n","    plt.ylabel(f'{plot_col} [normalizado]')\n","    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n","             label='Entradas', marker='.', zorder=-10)\n","\n","    if self.label_columns:\n","      label_col_index = self.label_columns_indices.get(plot_col, None)\n","    else:\n","      label_col_index = plot_col_index\n","\n","    if label_col_index is None:\n","      continue\n","\n","    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n","                edgecolors='k', label='Rótulos', c='#2ca02c', s=64)\n","    if model is not None:\n","      predictions = model(inputs)\n","      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n","                  marker='X', edgecolors='k', label='Predições',\n","                  c='#ff7f0e', s=64)\n","\n","    if n == 0:\n","      plt.legend()\n","\n","  plt.xlabel('Tempo [h]')\n","\n","WindowGenerator.plot = plot"]},{"cell_type":"markdown","metadata":{"id":"HXvctEuK68vX"},"source":["Esse gráfico alinha entradas, rótulos e (posteriormente) previsões com base no tempo a que o item se refere:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjTqUnglOOni"},"outputs":[],"source":["w2.plot()"]},{"cell_type":"markdown","metadata":{"id":"UqiqcPOldPG6"},"source":["Você pode plotar as outras colunas, mas a configuração da janela de exemplo `w2` só tem rótulos para a coluna `T (degC)`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBRe4wnlfCH8"},"outputs":[],"source":["w2.plot(plot_col='p (mbar)')"]},{"cell_type":"markdown","metadata":{"id":"xCvD-UaUzYMw"},"source":["### 4. Criar `tf.data.Dataset`s"]},{"cell_type":"markdown","metadata":{"id":"kLO3SFR9Osdf"},"source":["Por fim, esse método `make_dataset` pegará um DataFrame de série temporal e o converterá em um `tf.data.Dataset` de pares `(input_window, label_window)` usando a função `tf.keras.utils.timeseries_dataset_from_array`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35qoSQeRVfJg"},"outputs":[],"source":["def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.utils.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","\n","  ds = ds.map(self.split_window)\n","\n","  return ds\n","\n","WindowGenerator.make_dataset = make_dataset"]},{"cell_type":"markdown","metadata":{"id":"LvsxQwJaCift"},"source":["O objeto `WindowGenerator` contém dados de treinamento, validação e teste.\n","\n","Adicione propriedades para acessá-los como `tf.data.Dataset`s usando o método `make_dataset` que você definiu anteriormente. Além disso, adicione um lote de exemplo padrão para facilitar o acesso e a plotagem:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jZ2KkqGCfzu"},"outputs":[],"source":["@property\n","def train(self):\n","  return self.make_dataset(self.train_df)\n","\n","@property\n","def val(self):\n","  return self.make_dataset(self.val_df)\n","\n","@property\n","def test(self):\n","  return self.make_dataset(self.test_df)\n","\n","@property\n","def example(self):\n","  \"\"\"Obtenha e armazene em cache um lote de exemplo de `inputs, labels` para plotagem.\"\"\"\n","  result = getattr(self, '_example', None)\n","  if result is None:\n","    # No example batch was found, so get one from the `.train` dataset\n","    result = next(iter(self.train))\n","    # And cache it for next time\n","    self._example = result\n","  return result\n","\n","WindowGenerator.train = train\n","WindowGenerator.val = val\n","WindowGenerator.test = test\n","WindowGenerator.example = example"]},{"cell_type":"markdown","metadata":{"id":"fF_Vj6Iw3Y2w"},"source":["Agora, o objeto `WindowGenerator` lhe dá acesso aos objetos `tf.data.Dataset`, para que você possa iterar facilmente sobre os dados.\n","\n","A propriedade `Dataset.element_spec` informa a estrutura, os tipos de dados e as formas dos elementos do conjunto de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daJ0-U383YVs"},"outputs":[],"source":["# Cada elemento é um par (entradas, rótulo).\n","w2.train.element_spec"]},{"cell_type":"markdown","metadata":{"id":"XKTx3_Z7ua-n"},"source":["A iteração em um `Dataset` produz lotes concretos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gtKXEgf4Iml"},"outputs":[],"source":["for example_inputs, example_labels in w2.train.take(1):\n","  print(f'Forma das entradas (lote, tempo, recursos): {example_inputs.shape}')\n","  print(f'Labels shape (batch, time, features): {example_labels.shape}')"]},{"cell_type":"markdown","metadata":{"id":"LyuGuJUgjUK3"},"source":["## Modelos de etapa única\n","\n","O modelo mais simples que você pode criar com esse tipo de dados é aquele que prevê o valor de um único recurso em uma etapa de tempo (uma hora) no futuro com base apenas nas condições atuais.\n","\n","Portanto, comece criando modelos para prever o valor `T (degC)` em uma hora no futuro.\n","\n","![Prever o próximo passo de tempo](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/narrow_window.png?raw=1)\n","\n","Configure um objeto `WindowGenerator` para produzir esses pares `(input, label)` em uma única etapa:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5QX1G1JTPCr"},"outputs":[],"source":["single_step_window = WindowGenerator(\n","    input_width=1, label_width=1, shift=1,\n","    label_columns=['T (degC)'])\n","single_step_window"]},{"cell_type":"markdown","metadata":{"id":"RKTm8ajVGw4N"},"source":["O objeto `window` cria `tf.data.Dataset` a partir dos conjuntos de treinamento, validação e teste, permitindo que você itere facilmente sobre lotes de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Do4ILUaBF8oc"},"outputs":[],"source":["for example_inputs, example_labels in single_step_window.train.take(1):\n","  print(f'Formato da entrada (lote, tempo, recursos): {example_inputs.shape}')\n","  print(f'Formato dos rótulos (lote, tempo, recursos): {example_labels.shape}')"]},{"cell_type":"markdown","metadata":{"id":"D1bbPiR3VAm_"},"source":["### Linha de base\n","\n","Antes de criar um modelo treinável, seria bom ter uma linha de base de desempenho como ponto de comparação com os modelos posteriores mais complicados.\n","\n","Essa primeira tarefa é prever a temperatura em uma hora no futuro, considerando o valor atual de todos os recursos. Os valores atuais incluem a temperatura atual.\n","\n","Portanto, comece com um modelo que retorne apenas a temperatura atual como previsão, prevendo \"Nenhuma alteração\". Essa é uma linha de base razoável, pois a temperatura muda lentamente. É claro que essa linha de base funcionará menos bem se você fizer uma previsão mais para o futuro.\n","\n","![Send the input to the output](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/baseline.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9TybQaIsi3yg"},"outputs":[],"source":["class Baseline(tf.keras.Model):\n","  def __init__(self, label_index=None):\n","    super().__init__()\n","    self.label_index = label_index\n","\n","  def call(self, inputs):\n","    if self.label_index is None:\n","      return inputs\n","    result = inputs[:, :, self.label_index]\n","    return result[:, :, tf.newaxis]"]},{"cell_type":"markdown","metadata":{"id":"0vb3f948i8p8"},"source":["Instanciar e avaliar esse modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IS3-QKc4sX0D"},"outputs":[],"source":["baseline = Baseline(label_index=column_indices['T (degC)'])\n","\n","baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(single_step_window.val, return_dict=True)\n","performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"nhBxQcCSs7Ec"},"source":["Isso imprimiu algumas métricas de desempenho, mas elas não dão uma ideia de como o modelo está se saindo.\n","\n","O `WindowGenerator` tem um método de plotagem, mas as plotagens não serão muito interessantes com apenas uma única amostra.\n","\n","Portanto, crie um `WindowGenerator` mais amplo que gere janelas de 24 horas de entradas e rótulos consecutivos por vez.\n","\n","A nova variável `wide_window` não altera a forma como o modelo opera. O modelo ainda faz previsões de uma hora no futuro com base em uma única etapa de tempo de entrada. Aqui, o eixo `time` atua como o eixo `batch`: cada previsão é feita de forma independente, sem interação entre as etapas de tempo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8jNR5uuJ5Zp"},"outputs":[],"source":["wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1,\n","    label_columns=['T (degC)'])\n","\n","wide_window"]},{"cell_type":"markdown","metadata":{"id":"ZAnj7CFZkuYv"},"source":["Essa janela expandida pode ser passada diretamente para o mesmo modelo de \"linha de base\" sem nenhuma alteração no código. Isso é possível porque as entradas e os rótulos têm o mesmo número de etapas de tempo, e a linha de base apenas encaminha a entrada para a saída:\n","\n","![Uma previsão 1h no futuro, a cada hora.](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/last_window.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGKdvdg087qs"},"outputs":[],"source":["print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', baseline(wide_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"SKqQHX1K0JW-"},"source":["Ao plotar as previsões do modelo de linha de base, observe que ele é simplesmente os rótulos deslocados para a direita em uma hora:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQyAPVLgWTOZ"},"outputs":[],"source":["wide_window.plot(baseline)"]},{"cell_type":"markdown","metadata":{"id":"e93TLUhfAVg2"},"source":["Nos gráficos acima de três exemplos, o modelo de etapa única é executado ao longo de 24 horas. Isso merece alguma explicação:\n","\n","- A linha azul `Inputs` mostra a temperatura de entrada em cada etapa de tempo. O modelo recebe todos os recursos, mas esse gráfico mostra apenas a temperatura.\n","- Os pontos verdes `Labels` mostram o valor de previsão desejado. Esses pontos são mostrados no momento da previsão, não no momento da entrada. É por isso que o intervalo de rótulos é deslocado 1 passo em relação às entradas.\n","- As cruzes `Predictions` em laranja são as previsões do modelo para cada etapa de tempo de saída. Se o modelo estivesse fazendo uma previsão perfeita, as previsões cairiam diretamente sobre os `Rótulos`."]},{"cell_type":"markdown","metadata":{"id":"E4aOJScj52Yu"},"source":["### Modelo linear\n","\n","O modelo **treinável** mais simples que você pode aplicar a essa tarefa é inserir uma transformação linear entre a entrada e a saída. Nesse caso, a saída de uma etapa de tempo depende apenas dessa etapa:\n","\n","![Uma previsão de etapa única](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/narrow_window.png?raw=1)\n","\n","Uma camada `tf.keras.layers.Dense` sem conjunto de `ativação` é um modelo linear. A camada transforma apenas o último eixo dos dados de `(batch, time, inputs)` para `(batch, time, units)`; ela é aplicada independentemente a cada item nos eixos `batch` e `time`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6341OXuQ5xA9"},"outputs":[],"source":["linear = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=1)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KwaOM8RucUSn"},"outputs":[],"source":["print('Formato de entrada:', single_step_window.example[0].shape)\n","print('Formato de saída:', linear(single_step_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"OMZTYIj3bYLg"},"source":["Este tutorial treina muitos modelos, portanto, empacote o procedimento de treinamento em uma função:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbCL6VIrk-Gt"},"outputs":[],"source":["MAX_EPOCHS = 20\n","\n","def compile_and_fit(model, window, patience=2):\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                    patience=patience,\n","                                                    mode='min')\n","\n","  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","  history = model.fit(window.train, epochs=MAX_EPOCHS,\n","                      validation_data=window.val,\n","                      callbacks=[early_stopping])\n","  return history"]},{"cell_type":"markdown","metadata":{"id":"OobVjM-schwj"},"source":["Treine o modelo e avalie seu desempenho:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9agbz2qB9bLS"},"outputs":[],"source":["history = compile_and_fit(linear, single_step_window)\n","\n","val_performance['Linear'] = linear.evaluate(single_step_window.val, return_dict=True)\n","performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"7U9XukYh8beN"},"source":["Assim como o modelo `baseline`, o modelo linear pode ser chamado em lotes de janelas amplas. Usado dessa forma, o modelo faz um conjunto de previsões independentes em etapas de tempo consecutivas. O eixo `time` atua como outro eixo `batch`. Não há interações entre as previsões em cada etapa de tempo.\n","\n","![Uma previsão de etapa única](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/wide_window.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9UVM5Sw9KQN"},"outputs":[],"source":["print('Formato de entrada:', wide_window.example[0].shape)\n","print('Formato de saída:', linear(wide_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"X-CGj85oKaOG"},"source":["Aqui está o gráfico de suas previsões de exemplo na `wide_window`; observe como, em muitos casos, a previsão é claramente melhor do que apenas retornar a temperatura de entrada, mas em alguns casos é pior:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCC8VVo-OvwV"},"outputs":[],"source":["wide_window.plot(linear)"]},{"cell_type":"markdown","metadata":{"id":"Is51vU8EMl6c"},"source":["Uma vantagem dos modelos lineares é que eles são relativamente simples de interpretar.\n","Você pode extrair os pesos da camada e visualizar o peso atribuído a cada entrada:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4uCTbsmK8VI"},"outputs":[],"source":["plt.bar(x = range(len(train_df.columns)),\n","        height=linear.layers[0].kernel[:,0].numpy())\n","axis = plt.gca()\n","axis.set_xticks(range(len(train_df.columns)))\n","_ = axis.set_xticklabels(train_df.columns, rotation=90)"]},{"cell_type":"markdown","metadata":{"id":"Ylng7215boIY"},"source":["Às vezes, o modelo nem mesmo atribui o maior peso à entrada `T (degC)`. Esse é um dos riscos da inicialização aleatória."]},{"cell_type":"markdown","metadata":{"id":"W18e6da1cNbw"},"source":["### Densa\n","\n","Antes de aplicar modelos que realmente operam em várias etapas de tempo, vale a pena verificar o desempenho de modelos mais profundos e poderosos de etapa de entrada única.\n","\n","Aqui está um modelo semelhante ao modelo `linear`, exceto pelo fato de que ele empilha várias camadas `Dense` entre a entrada e a saída:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z86WkYp7cNAD"},"outputs":[],"source":["dense = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=1)\n","])\n","\n","history = compile_and_fit(dense, single_step_window)\n","\n","val_performance['Dense'] = dense.evaluate(single_step_window.val, return_dict=True)\n","performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"j5dv_whJdswH"},"source":["### Denso em várias etapas\n","\n","Um modelo de etapa única não tem contexto para os valores atuais de suas entradas. Ele não consegue ver como os recursos de entrada estão mudando ao longo do tempo. Para resolver esse problema, o modelo precisa ter acesso a várias etapas de tempo ao fazer previsões:\n","\n","![Três etapas de tempo são usadas para cada previsão.](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/conv_window.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"id":"Zac-ti8agbJ7"},"source":["Os modelos `baseline`, `linear` e `dense` tratavam cada etapa de tempo de forma independente. Aqui, o modelo utilizará várias etapas de tempo como entrada para produzir uma única saída.\n","\n","Crie um `WindowGenerator` que produzirá lotes de entradas de três horas e rótulos de uma hora:"]},{"cell_type":"markdown","metadata":{"id":"gtN4BwZ37niR"},"source":["Note that the `Window`'s `shift` parameter is relative to the end of the two windows.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBh0j5djUKY2"},"outputs":[],"source":["CONV_WIDTH = 3\n","conv_window = WindowGenerator(\n","    input_width=CONV_WIDTH,\n","    label_width=1,\n","    shift=1,\n","    label_columns=['T (degC)'])\n","\n","conv_window"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCQ5gvs68Xkd"},"outputs":[],"source":["conv_window.plot()\n","plt.suptitle(\"Com 3 horas de dados, preveja 1 hora no futuro.\")"]},{"cell_type":"markdown","metadata":{"id":"We0HdMxKeqB_"},"source":["Você poderia treinar um modelo `denso` em uma janela de várias etapas de entrada adicionando um `tf.keras.layers.Flatten` como a primeira camada do modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNQnUOkOnC1G"},"outputs":[],"source":["multi_step_dense = tf.keras.Sequential([\n","    # Shape: (tempo, recursos) => (tempo*recursos)\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=1),\n","    # Adicione novamente a dimensão de tempo.\n","    # Formato: (saídas) => (1, saídas)\n","    tf.keras.layers.Reshape([1, -1]),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cayD74luo4Vq"},"outputs":[],"source":["print('Formato da entrada:', conv_window.example[0].shape)\n","print('Formato da saída:', multi_step_dense(conv_window.example[0]).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fu91yEbRo9-J"},"outputs":[],"source":["history = compile_and_fit(multi_step_dense, conv_window)\n","\n","IPython.display.clear_output()\n","val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val, return_dict=True)\n","performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnqdXYT6pkEh"},"outputs":[],"source":["conv_window.plot(multi_step_dense)"]},{"cell_type":"markdown","metadata":{"id":"gWfrsP8mq8lV"},"source":["O principal aspecto negativo dessa abordagem é que o modelo resultante só pode ser executado em janelas de entrada com exatamente esse formato."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-q6tz5Yq8Jk"},"outputs":[],"source":["print('Formato da entrada:', wide_window.example[0].shape)\n","try:\n","  print('Formato da saída:', multi_step_dense(wide_window.example[0]).shape)\n","except Exception as e:\n","  print(f'\\n{type(e).__name__}:{e}')"]},{"cell_type":"markdown","metadata":{"id":"bvvajm3ip_8V"},"source":["Os modelos convolucionais da próxima seção resolvem esse problema."]},{"cell_type":"markdown","metadata":{"id":"CrpU6gwSJome"},"source":["### Rede neural de convolução\n","\n","Uma camada de convolução (`tf.keras.layers.Conv1D`) também usa várias etapas de tempo como entrada para cada previsão."]},{"cell_type":"markdown","metadata":{"id":"cdLBwoaHmsWb"},"source":["Abaixo está o **mesmo** modelo do `multi_step_dense`, reescrito com uma convolução.\n","\n","Observe as alterações:\n","* O `tf.keras.layers.Flatten` e o primeiro `tf.keras.layers.Dense` são substituídos por um `tf.keras.layers.Conv1D`.\n","* O `tf.keras.layers.Reshape` não é mais necessário, pois a convolução mantém o eixo do tempo em sua saída."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5azaMBj4ac9t"},"outputs":[],"source":["conv_model = tf.keras.Sequential([\n","    tf.keras.layers.Conv1D(filters=32,\n","                           kernel_size=(CONV_WIDTH,),\n","                           activation='relu'),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=1),\n","])"]},{"cell_type":"markdown","metadata":{"id":"ftaH6B5ECRiK"},"source":["Execute-o em um lote de exemplo para verificar se o modelo produz resultados com a forma esperada:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YNgt1-e98lH"},"outputs":[],"source":["print(\"Modelo de conv em `conv_window`\")\n","print('Formato da entrada:', conv_window.example[0].shape)\n","print('Formato da sída:', conv_model(conv_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"5m4kC-jGCY3x"},"source":["Treine-o e avalie-o na `conv_window` e ele deverá apresentar desempenho semelhante ao do modelo `multi_step_dense`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QDVWdm4paUW7"},"outputs":[],"source":["history = compile_and_fit(conv_model, conv_window)\n","\n","IPython.display.clear_output()\n","val_performance['Conv'] = conv_model.evaluate(conv_window.val, return_dict=True)\n","performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"sYRipDeXs0Kr"},"source":["A diferença entre esse modelo `conv_model` e o modelo `multi_step_dense` é que o `conv_model` pode ser executado em entradas de qualquer tamanho. A camada convolucional é aplicada a uma janela deslizante de entradas:\n","\n","![Executando um modelo convolucional em uma sequência](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/wide_conv_window.png?raw=1)\n","\n","Se você executá-lo em uma entrada mais ampla, ele produzirá uma saída mais ampla:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoqccxx9r5jF"},"outputs":[],"source":["print(\"Janela ampla\")\n","print('Formato da entrada:', wide_window.example[0].shape)\n","print('Formato de rótulos:', wide_window.example[1].shape)\n","print('Formato da saída:', conv_model(wide_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"h_WGxtLIHhRF"},"source":["Observe que a saída é mais curta que a entrada. Para que o treinamento ou a plotagem funcionem, você precisa que os rótulos e a previsão tenham o mesmo comprimento. Portanto, crie um `WindowGenerator` para produzir janelas amplas com algumas etapas extras de tempo de entrada para que os comprimentos do rótulo e da previsão coincidam:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VPvJ_VwTc0f"},"outputs":[],"source":["LABEL_WIDTH = 24\n","INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n","wide_conv_window = WindowGenerator(\n","    input_width=INPUT_WIDTH,\n","    label_width=LABEL_WIDTH,\n","    shift=1,\n","    label_columns=['T (degC)'])\n","\n","wide_conv_window"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtqlWYXeKXej"},"outputs":[],"source":["print(\"Convolução em janela ampla\")\n","print('Formato de entrada:', wide_conv_window.example[0].shape)\n","print('Formato de rótulos:', wide_conv_window.example[1].shape)\n","print('Formato de saída:', conv_model(wide_conv_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"yzxbbS56cSBV"},"source":["Agora, você pode plotar as previsões do modelo em uma janela mais ampla.\n","\n","Observe as 3 etapas de tempo de entrada antes da primeira previsão. Cada previsão aqui é baseada nas 3 etapas de tempo anteriores:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR7VyL45UuEe"},"outputs":[],"source":["wide_conv_window.plot(conv_model)"]},{"cell_type":"markdown","metadata":{"id":"H4crpOcoMlSe"},"source":["### Rede neural recorrente\n","\n","Uma Rede Neural Recorrente (RNN) é um tipo de rede neural adequada para dados de séries temporais. As RNNs processam uma série temporal passo a passo, mantendo um estado interno de etapa em etapa.\n","\n","Para saber mais, consulte o tutorial [Text generation with an RNN](https://www.tensorflow.org/text/tutorials/text_generation) e o guia [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn).\n","\n","Neste tutorial, você usará uma camada de RNN chamada Long Short-Term Memory (`tf.keras.layers.LSTM`)."]},{"cell_type":"markdown","metadata":{"id":"vfQbHSMb1ATa"},"source":["Um argumento importante do construtor para todas as camadas RNN do Keras, como `tf.keras.layers.LSTM`, é o argumento `return_sequences`. Essa definição pode configurar a camada de duas maneiras:\n","\n","1. Se for `False`, o padrão, a camada retornará apenas a saída da etapa de tempo final, dando ao modelo tempo para aquecer seu estado interno antes de fazer uma única previsão:\n","\n","![Um LSTM aquecendo-se e fazendo uma única previsão](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/lstm_1_window.png?raw=1)\n","\n","2. Se `True`, a camada retorna uma saída para cada entrada. Isso é útil para:\n","  * Empilhar camadas RNN.\n","  * Treinar um modelo em várias etapas de tempo simultaneamente.\n","\n","![Um LSTM fazendo uma previsão após cada etapa de tempo](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/lstm_many_window.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXKLCJy8nWNU"},"outputs":[],"source":["lstm_model = tf.keras.models.Sequential([\n","    # Formato [lote, tempo, recursos] => [lote, temp, unidades lstm]\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    # Formato => [lote, tempo, recursos]\n","    tf.keras.layers.Dense(units=1)\n","])"]},{"cell_type":"markdown","metadata":{"id":"F124B00KZcLC"},"source":["Com `return_sequences=True`, o modelo pode ser treinado com 24 horas de dados por vez.\n","\n","Observação: isso fornecerá uma visão pessimista do desempenho do modelo. Na primeira etapa de tempo, o modelo não tem acesso às etapas anteriores e, portanto, não pode se sair melhor do que os modelos `linear` e `dense` simples mostrados anteriormente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZEROCQVYV6q"},"outputs":[],"source":["print('Formato da entrada:', wide_window.example[0].shape)\n","print('Formato da saída:', lstm_model(wide_window.example[0]).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvdWRl1e9WJl"},"outputs":[],"source":["history = compile_and_fit(lstm_model, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['LSTM'] = lstm_model.evaluate(wide_window.val, return_dict=True)\n","performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwAOWCVgB26e"},"outputs":[],"source":["wide_window.plot(lstm_model)"]},{"cell_type":"markdown","metadata":{"id":"pYglOCKehi8F"},"source":["### Performance"]},{"cell_type":"markdown","metadata":{"id":"2pCk0_rwhi8H"},"source":["Com esse conjunto de dados, normalmente cada um dos modelos se sai um pouco melhor do que o anterior:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMPev9Nzd4mD"},"outputs":[],"source":["cm = lstm_model.metrics[1]\n","cm.metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6is3g113eIIa"},"outputs":[],"source":["val_performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjEkt488hi8I"},"outputs":[],"source":["x = np.arange(len(performance))\n","width = 0.3\n","metric_name = 'mean_absolute_error'\n","val_mae = [v[metric_name] for v in val_performance.values()]\n","test_mae = [v[metric_name] for v in performance.values()]\n","\n","plt.ylabel('erro absoluto médio [T (degC), normalizado]')\n","plt.bar(x - 0.17, val_mae, width, label='Validação')\n","plt.bar(x + 0.17, test_mae, width, label='Teste')\n","plt.xticks(ticks=x, labels=performance.keys(),\n","           rotation=45)\n","_ = plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBMCpsdphi8L"},"outputs":[],"source":["for name, value in performance.items():\n","  print(f'{name:12s}: {value[metric_name]:0.4f}')"]},{"cell_type":"markdown","metadata":{"id":"b5rUJ_2YMWzG"},"source":["### Modelos com várias saídas\n","\n","Até agora, todos os modelos previram um único recurso de saída, `T (degC)`, para uma única etapa de tempo.\n","\n","Todos esses modelos podem ser convertidos para prever vários recursos apenas alterando o número de unidades na camada de saída e ajustando as janelas de treinamento para incluir todos os recursos nos `labels` (`example_labels`):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Gk0Z91xjOwv"},"outputs":[],"source":["single_step_window = WindowGenerator(\n","    # O `WindowGenerator` retorna todos os recursos como rótulos se você\n","    # não definir o argumento `label_columns`.\n","    input_width=1, label_width=1, shift=1)\n","\n","wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1)\n","\n","for example_inputs, example_labels in wide_window.train.take(1):\n","  print(f'Formato de entrada (lote, tempo, recursos): {example_inputs.shape}')\n","  print(f'Formato de rótulos (lote, tempo, recursos): {example_labels.shape}')"]},{"cell_type":"markdown","metadata":{"id":"XmcjHfDskX1N"},"source":["Observe acima que o eixo `features` dos rótulos agora tem a mesma profundidade que as entradas, em vez de `1`."]},{"cell_type":"markdown","metadata":{"id":"9k7S5IHNhSNF"},"source":["#### Baseline\n","\n","O mesmo modelo de linha de base (`Baseline`) pode ser usado aqui, mas dessa vez repetindo todos os recursos em vez de selecionar um `label_index` específico:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqqB9W-pjr5i"},"outputs":[],"source":["baseline = Baseline()\n","baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                 metrics=[tf.keras.metrics.MeanAbsoluteError()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltQdgaqQjQWu"},"outputs":[],"source":["val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(wide_window.val, return_dict=True)\n","performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"dfbCrf5q3P6n"},"source":["#### Dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdpzH1dYjdIN"},"outputs":[],"source":["dense = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=num_features)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uHuU9Cd3PTo"},"outputs":[],"source":["history = compile_and_fit(dense, single_step_window)\n","\n","IPython.display.clear_output()\n","val_performance['Dense'] = dense.evaluate(single_step_window.val, return_dict=True)\n","performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"dsc9pur_mHsx"},"source":["#### RNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QbGLMyomXaz"},"outputs":[],"source":["%%time\n","wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1)\n","\n","lstm_model = tf.keras.models.Sequential([\n","    # Formato [lote, tempo, recursos] => [lote, tempo, unidades lstm]\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    #  Formato [lote, tempo, recursos\n","    tf.keras.layers.Dense(units=num_features)\n","])\n","\n","history = compile_and_fit(lstm_model, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['LSTM'] = lstm_model.evaluate( wide_window.val, return_dict=True)\n","performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0, return_dict=True)\n","\n","print()"]},{"cell_type":"markdown","metadata":{"id":"UwhY2f_Nn0_K"},"source":["<a id=\"residual\"></a>\n","\n","#### Avançado: Conexões Residuais\n","\n","O modelo `Baseline` de antes aproveitou o fato de que a sequência não muda drasticamente de uma etapa de tempo para outra. Todos os modelos treinados neste tutorial até agora foram inicializados aleatoriamente e, em seguida, tiveram de aprender que a saída é uma pequena alteração em relação à etapa de tempo anterior.\n","\n","Embora você possa contornar esse problema com uma inicialização cuidadosa, é mais simples incorporar isso à estrutura do modelo.\n","\n","É comum na análise de séries temporais criar modelos que, em vez de prever o próximo valor, prevejam como o valor mudará na próxima etapa de tempo. Da mesma forma,<a href=\"https://arxiv.org/abs/1512.03385\" class=\"external\">residual networks</a>—or As ResNets - na aprendizagem profunda - referem-se a arquiteturas em que cada camada é adicionada ao resultado acumulado do modelo.\n","\n","É assim que você tira proveito do conhecimento de que a mudança deve ser pequena.\n","\n","![Um modelo com uma conexão residual](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/residual.png?raw=1)\n","\n","Essencialmente, isso inicializa o modelo para corresponder à `Baseline`. Para essa tarefa, ele ajuda os modelos a convergir mais rapidamente, com desempenho ligeiramente melhor."]},{"cell_type":"markdown","metadata":{"id":"yP58A_ORx0kM"},"source":["Essa abordagem pode ser usada em conjunto com qualquer modelo discutido neste tutorial.\n","\n","Aqui, ela está sendo aplicada ao modelo LSTM. Observe o uso de `tf.initializers.zeros` para garantir que as alterações iniciais previstas sejam pequenas e não dominem a conexão residual. Não há preocupações de quebra de simetria para os gradientes aqui, uma vez que os `zeros` são usados somente na última camada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YlfnDQC22TQ"},"outputs":[],"source":["class ResidualWrapper(tf.keras.Model):\n","  def __init__(self, model):\n","    super().__init__()\n","    self.model = model\n","\n","  def call(self, inputs, *args, **kwargs):\n","    delta = self.model(inputs, *args, **kwargs)\n","\n","    # A previsão para cada etapa de tempo é a entrada\n","    # da etapa de tempo anterior mais o delta\n","    # calculado pelo modelo.\n","    return inputs + delta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNeH02pspc9B"},"outputs":[],"source":["%%time\n","residual_lstm = ResidualWrapper(\n","    tf.keras.Sequential([\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    tf.keras.layers.Dense(\n","        num_features,\n","        # Os deltas previstos devem começar pequenos.\n","        # Portanto, inicialize a camada de saída com zeros.\n","        kernel_initializer=tf.initializers.zeros())\n","]))\n","\n","history = compile_and_fit(residual_lstm, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val, return_dict=True)\n","performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0, return_dict=True)\n","print()"]},{"cell_type":"markdown","metadata":{"id":"I42Er9Du6co1"},"source":["#### Performance"]},{"cell_type":"markdown","metadata":{"id":"LZxR38P_6pUi"},"source":["Aqui está o desempenho geral desses modelos de várias saídas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XgTK9tnr7rc"},"outputs":[],"source":["x = np.arange(len(performance))\n","width = 0.3\n","\n","metric_name = 'mean_absolute_error'\n","val_mae = [v[metric_name] for v in val_performance.values()]\n","test_mae = [v[metric_name] for v in performance.values()]\n","\n","plt.bar(x - 0.17, val_mae, width, label='Validação')\n","plt.bar(x + 0.17, test_mae, width, label='Teste')\n","plt.xticks(ticks=x, labels=performance.keys(),\n","           rotation=45)\n","plt.ylabel('MAE (média sobre todas as saídas)')\n","_ = plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URz3ajCc6kBj"},"outputs":[],"source":["for name, value in performance.items():\n","  print(f'{name:15s}: {value[metric_name]:0.4f}')"]},{"cell_type":"markdown","metadata":{"id":"_Vt2MJhNxwPU"},"source":["Os desempenhos acima são a média de todos os resultados do modelo."]},{"cell_type":"markdown","metadata":{"id":"eYokb7Om2YbK"},"source":["## Modelos de várias etapas (_Multi-step models_)\n","\n","Os modelos de saída única e de saída múltipla das seções anteriores fizeram **previsões de etapa única**, uma hora no futuro.\n","\n","Esta seção analisa como expandir esses modelos para fazer **previsões de várias etapas**.\n","\n","Em uma previsão de várias etapas, o modelo precisa aprender a prever um intervalo de valores futuros. Portanto, ao contrário de um modelo de etapa única, em que apenas um único ponto futuro é previsto, um modelo de várias etapas prevê uma sequência de valores futuros.\n","\n","Há duas abordagens gerais para isso:\n","\n","1. Previsões de uma única etapa, em que toda a série temporal é prevista de uma só vez.\n","2. Previsões autorregressivas em que o modelo faz apenas previsões de etapa única e sua saída é realimentada como entrada.\n","\n","Nesta seção, todos os modelos farão a previsão de **todos os recursos em todas as etapas de tempo de saída**.\n"]},{"cell_type":"markdown","metadata":{"id":"WFsDAwVt4_rq"},"source":["Para o modelo de várias etapas, os dados de treinamento consistem novamente em amostras horárias. Entretanto, aqui, os modelos aprenderão a prever 24 horas no futuro, considerando 24 horas do passado.\n","\n","Aqui está um objeto `Window` que gera essas fatias do conjunto de dados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cFYtsz6XiGw"},"outputs":[],"source":["OUT_STEPS = 24\n","multi_window = WindowGenerator(input_width=24,\n","                               label_width=OUT_STEPS,\n","                               shift=OUT_STEPS)\n","\n","multi_window.plot()\n","multi_window"]},{"cell_type":"markdown","metadata":{"id":"5lg8SInh9Jzd"},"source":["### Baselines"]},{"cell_type":"markdown","metadata":{"id":"axwpoWYOApJL"},"source":["Uma linha de base simples para essa tarefa é repetir a última etapa de tempo de entrada para o número necessário de etapas de tempo de saída:\n","\n","![Repetir a última entrada, para cada etapa de saída](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_last.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5iaHSaJ9Rxv"},"outputs":[],"source":["class MultiStepLastBaseline(tf.keras.Model):\n","  def call(self, inputs):\n","    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n","\n","last_baseline = MultiStepLastBaseline()\n","last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                      metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","multi_val_performance = {}\n","multi_performance = {}\n","\n","multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val, return_dict=True)\n","multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(last_baseline)"]},{"cell_type":"markdown","metadata":{"id":"AvHZ93ObAfMA"},"source":["Como essa tarefa é prever 24 horas no futuro, considerando 24 horas do passado, outra abordagem simples é repetir o dia anterior, presumindo que amanhã será semelhante:\n","\n","![Repetir o dia anterior](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_repeat.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L8Y1uMhGwIRs"},"outputs":[],"source":["class RepeatBaseline(tf.keras.Model):\n","  def call(self, inputs):\n","    return inputs\n","\n","repeat_baseline = RepeatBaseline()\n","repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val, return_dict=True)\n","multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(repeat_baseline)"]},{"cell_type":"markdown","metadata":{"id":"tbndS-ct9C2Q"},"source":["### Modelos de disparo único(_Single-shot_)\n","\n","Uma abordagem de alto nível para esse problema é usar um modelo de \"disparo único\", em que o modelo faz a previsão de toda a sequência em uma única etapa.\n","\n","Isso pode ser implementado de forma eficiente como um `tf.keras.layers.Dense` com unidades de saída `OUT_STEPS*features`. O modelo só precisa remodelar essa saída para o `(OUTPUT_STEPS, features)` necessário."]},{"cell_type":"markdown","metadata":{"id":"NCKS4m1VKrDQ"},"source":["#### Linear\n","\n","Um modelo linear simples baseado na última etapa de tempo de entrada é melhor do que qualquer uma das linhas de base, mas não tem potência suficiente. O modelo precisa prever as etapas de tempo `OUTPUT_STEPS` a partir de uma única etapa de tempo de entrada com uma projeção linear. Ele só pode capturar uma fatia de baixa dimensão do comportamento, provavelmente baseada principalmente na hora do dia e na época do ano.\n","\n","![Predict all timesteps from the last time-step](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_dense.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfRz_WVhIQcd"},"outputs":[],"source":["multi_linear_model = tf.keras.Sequential([\n","    # Pegue a última etapa de tempo.\n","    # Forma [lote, tempo, recursos] => [lote, 1, recursos]\n","    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n","    # Formato => [lote, 1, passos de saída*recursos]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros()),\n","    # Formato => [lote, passos de saída, recursos]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n","\n","history = compile_and_fit(multi_linear_model, multi_window)\n","\n","IPython.display.clear_output()\n","multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val, return_dict=True)\n","multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(multi_linear_model)"]},{"cell_type":"markdown","metadata":{"id":"zi2TMHk2IRrh"},"source":["#### Dense\n","\n","A adição de um `tf.keras.layers.Dense` entre a entrada e a saída dá mais potência ao modelo linear, mas ainda se baseia apenas em uma única etapa de tempo de entrada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jezm-BKaGj91"},"outputs":[],"source":["multi_dense_model = tf.keras.Sequential([\n","    # Pegue a última etapa de tempo.\n","    # Forma [lote, tempo, recursos] => [lote, 1, recursos]\n","    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n","    # Forma => [lote, 1, dense_units]\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    # Formato => [lote, passos de saída*features]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros()),\n","    # Formato => [lote, passos de saída*features]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n","\n","history = compile_and_fit(multi_dense_model, multi_window)\n","\n","IPython.display.clear_output()\n","multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val, return_dict=True)\n","multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(multi_dense_model)"]},{"cell_type":"markdown","metadata":{"id":"icsBAjCzMaMl"},"source":["#### CNN"]},{"cell_type":"markdown","metadata":{"id":"34lCZrWYNBwd"},"source":["Um modelo convolucional faz previsões com base em um histórico de largura fixa, o que pode levar a um melhor desempenho do que o modelo denso, pois ele pode ver como as coisas estão mudando ao longo do tempo:\n","\n","![Um modelo convolucional vê como as coisas mudam ao longo do tempo](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_conv.png?raw=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xJoIP6PMWMI"},"outputs":[],"source":["CONV_WIDTH = 3\n","multi_conv_model = tf.keras.Sequential([\n","    # Formato [lote, tempo, recursos] => [lote, CONV_WIDTH, recursos]\n","    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n","    # Formato => [lote, 1, conv_units]\n","    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n","    # Shape => [lote, 1, passos de saída*recursos]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros()),\n","    # Shape => [batch, passos de saída, recursos]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n","\n","history = compile_and_fit(multi_conv_model, multi_window)\n","\n","IPython.display.clear_output()\n","\n","multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val, return_dict=True)\n","multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(multi_conv_model)"]},{"cell_type":"markdown","metadata":{"id":"weBjeZAFJOP4"},"source":["#### RNN"]},{"cell_type":"markdown","metadata":{"id":"8022xOKxOO92"},"source":["Um modelo recorrente pode aprender a usar um longo histórico de entradas, se isso for relevante para as previsões que o modelo está fazendo. Aqui, o modelo acumulará o estado interno por 24 horas, antes de fazer uma única previsão para as próximas 24 horas.\n","\n","Nesse formato de disparo único, o LSTM só precisa produzir uma saída na última etapa de tempo, portanto, defina `return_sequences=False` em `tf.keras.layers.LSTM`.\n","\n","![O LSTM acumula o estado na janela de entrada e faz uma única previsão para as próximas 24 horas](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_lstm.png?raw=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bf1ks6RTzF64"},"outputs":[],"source":["multi_lstm_model = tf.keras.Sequential([\n","    # Formato [lote, time, recursos] => [batch, lstm_units].\n","    # A adição de mais `lstm_units` apenas se sobrepõe mais rapidamente.\n","    tf.keras.layers.LSTM(32, return_sequences=False),\n","    # Formato => [lote, passos de saída*recursos].\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros()),\n","    # Formato => [lote, passos de saída, recursos].\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n","\n","history = compile_and_fit(multi_lstm_model, multi_window)\n","\n","IPython.display.clear_output()\n","\n","multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val, return_dict=True)\n","multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(multi_lstm_model)"]},{"cell_type":"markdown","metadata":{"id":"d5n-1cDW12Vo"},"source":["### Avançado: Modelo autorregressivo\n","\n","Todos os modelos acima preveem toda a sequência de saída em uma única etapa.\n","\n","Em alguns casos, pode ser útil para o modelo decompor essa previsão em etapas de tempo individuais. Em seguida, a saída de cada modelo pode ser realimentada em cada etapa e as previsões podem ser feitas com base na anterior, como no modelo  clássico <a href=\"https://arxiv.org/abs/1308.0850\" class=\"external\">Geração de sequências com redes neurais recorrentes</a>.\n","\n","Uma vantagem clara desse estilo de modelo é que ele pode ser configurado para produzir uma saída com comprimento variável.\n","\n","\n","Uma vantagem clara desse estilo de modelo é que ele pode ser configurado para produzir resultados com comprimento variável.\n","\n","Você poderia usar qualquer um dos modelos de saída múltipla de etapa única treinados na primeira parte deste tutorial e executá-los em um loop de feedback autorregressivo, mas aqui você se concentrará na criação de um modelo que tenha sido explicitamente treinado para fazer isso.\n","\n","![Realimentar um modelo com sua entrada](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_autoregressive.png?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"PKRreBbULRXY"},"source":["#### RNN\n","\n","Este tutorial constrói apenas um modelo RNN autorregressivo, mas esse padrão pode ser aplicado a qualquer modelo projetado para produzir uma única etapa de tempo.\n","\n","O modelo terá a mesma forma básica que os modelos LSTM de etapa única anteriores: uma camada `tf.keras.layers.LSTM` seguida por uma camada `tf.keras.layers.Dense` que converte as saídas da camada `LSTM` em previsões de modelo.\n","\n","Uma `tf.keras.layers.LSTM` é uma `tf.keras.layers.LSTMCell` envolvida no nível superior `tf.keras.layers.RNN` que gerencia o estado e os resultados da sequência para você (consulte o guia [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) para obter detalhes).\n","\n","Nesse caso, o modelo precisa gerenciar manualmente as entradas para cada etapa, portanto, ele usa o `tf.keras.layers.LSTMCell` diretamente para a interface de nível inferior de etapa única de tempo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5tz3Nu0R5JG"},"outputs":[],"source":["class FeedBack(tf.keras.Model):\n","  def __init__(self, units, out_steps):\n","    super().__init__()\n","    self.out_steps = out_steps\n","    self.units = units\n","    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n","    # Também envolva o LSTMCell em um RNN para simplificar o método `warmup`.\n","    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n","    self.dense = tf.keras.layers.Dense(num_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OXVM9G1U7xR"},"outputs":[],"source":["feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"]},{"cell_type":"markdown","metadata":{"id":"ph5uFSfTUNho"},"source":["O primeiro método que esse modelo precisa é um método `warmup` para inicializar seu estado interno com base nas entradas. Uma vez treinado, esse estado capturará as partes relevantes do histórico de entrada. Isso é equivalente ao modelo `LSTM` de etapa única mencionado anteriormente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vM2K_LLdRjDZ"},"outputs":[],"source":["def warmup(self, inputs):\n","  # inputs.shape => (lote, tempo, recursos)\n","  # x.shape => (lote, unidades lstm)\n","  x, *state = self.lstm_rnn(inputs)\n","\n","  # predictions.shape => (lote, recursos)\n","  prediction = self.dense(x)\n","  return prediction, state\n","\n","FeedBack.warmup = warmup"]},{"cell_type":"markdown","metadata":{"id":"6JkaSYaZ9eB7"},"source":["Esse método retorna uma previsão de uma única etapa de tempo e o estado interno do `LSTM`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9Fz6NTKXXwU"},"outputs":[],"source":["prediction, state = feedback_model.warmup(multi_window.example[0])\n","prediction.shape"]},{"cell_type":"markdown","metadata":{"id":"S_ZdvPjdX3y3"},"source":["Com o estado do `RNN` e uma previsão inicial, você pode continuar a iterar o modelo alimentando as previsões em cada etapa como entrada.\n","\n","A abordagem mais simples para coletar as previsões de saída é usar uma lista Python e um `tf.stack` após o loop."]},{"cell_type":"markdown","metadata":{"id":"yotTad3nZXQU"},"source":["Observação: o empilhamento de uma lista Python como essa só funciona com execução ansiosa, usando `Model.compile(..., run_eagerly=True)` para treinamento ou com uma saída de comprimento fixo. Para um comprimento de saída dinâmico, você precisaria usar um `tf.TensorArray` em vez de uma lista Python, e `tf.range` em vez do `range` Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1GRDu3mZtr9"},"outputs":[],"source":["def call(self, inputs, training=None):\n","  # Use um TensorArray para capturar saídas dinamicamente desenroladas.\n","  predictions = []\n","  # Inicializar o estado do LSTM.\n","  prediction, state = self.warmup(inputs)\n","\n","  # Insira a primeira previsão.\n","  predictions.append(prediction)\n","\n","  # Execute o restante das etapas de previsão.\n","  for n in range(1, self.out_steps):\n","    # Use a última previsão como entrada.\n","    x = prediction\n","    # Executar uma etapa do lstm.\n","    x, state = self.lstm_cell(x, states=state,\n","                              training=training)\n","    # Converta a saída do lstm em uma previsão.\n","    prediction = self.dense(x)\n","    # Adicione a previsão à saída.\n","    predictions.append(prediction)\n","\n","  # predictions.shape => (tempo, lote, recursos)\n","  predictions = tf.stack(predictions)\n","  # predictions.shape => (lote, tempo, recursos)\n","  predictions = tf.transpose(predictions, [1, 0, 2])\n","  return predictions\n","\n","FeedBack.call = call"]},{"cell_type":"markdown","metadata":{"id":"Ubop-YWp15XW"},"source":["Execute o teste desse modelo com as entradas de exemplo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xja83zEYaM2D"},"outputs":[],"source":["print('Forma de saída (lote, tempo, recursos):', feedback_model(multi_window.example[0]).shape)"]},{"cell_type":"markdown","metadata":{"id":"qMs0rYB8be9M"},"source":["Agora, treine o modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBRVG2hnNyrO"},"outputs":[],"source":["history = compile_and_fit(feedback_model, multi_window)\n","\n","IPython.display.clear_output()\n","\n","multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val, return_dict=True)\n","multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0, return_dict=True)\n","multi_window.plot(feedback_model)"]},{"cell_type":"markdown","metadata":{"id":"hGjcJsAQJUkI"},"source":["### Performance"]},{"cell_type":"markdown","metadata":{"id":"sODAwr2ndtDB"},"source":["Há claramente retornos decrescentes em função da complexidade do modelo nesse problema:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZwWBA8S6B3L"},"outputs":[],"source":["x = np.arange(len(multi_performance))\n","width = 0.3\n","\n","metric_name = 'mean_absolute_error'\n","val_mae = [v[metric_name] for v in multi_val_performance.values()]\n","test_mae = [v[metric_name] for v in multi_performance.values()]\n","\n","plt.bar(x - 0.17, val_mae, width, label='Validação')\n","plt.bar(x + 0.17, test_mae, width, label='Teste')\n","plt.xticks(ticks=x, labels=multi_performance.keys(),\n","           rotation=45)\n","plt.ylabel(f'MAE (média de todos os tempos e saídas)')\n","_ = plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"Zq3hUsedCEmJ"},"source":["As métricas dos modelos de várias saídas na primeira metade deste tutorial mostram o desempenho médio de todos os recursos de saída. Esses desempenhos são semelhantes, mas também são calculados pela média das etapas de tempo de saída."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKq3eAIvH4Db"},"outputs":[],"source":["for name, value in multi_performance.items():\n","  print(f'{name:8s}: {value[metric_name]:0.4f}')"]},{"cell_type":"markdown","metadata":{"id":"MpBFwfnaHP23"},"source":["Os ganhos obtidos ao passar de um modelo denso para modelos convolucionais e recorrentes são de apenas alguns por cento (se houver), e o modelo autorregressivo teve um desempenho claramente pior. Portanto, essas abordagens mais complexas podem não valer a pena para **esse** problema, mas não há como saber sem tentar, e esses modelos podem ser úteis para **seu** problema."]},{"cell_type":"markdown","metadata":{"id":"pOzaIRYBhqwg"},"source":["## Próximos passos\n","Este tutorial foi uma rápida introdução à previsão de séries temporais usando o TensorFlow.\n","\n","Para aprender mais consulte:\n","\n","- Capítulo 15 de <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" class=\"external\">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</a>, 2nd Edition.\n","- Capítulo 6 de <a href=\"https://www.manning.com/books/deep-learning-with-python\" class=\"external\">Deep Learning with Python</a>.\n","- Lição 8 de <a href=\"https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187\" class=\"external\">Udacity's intro to TensorFlow for deep learning</a>, incluindo <a href=\"https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning\" class=\"external\">cadernos de exercícios</a>.\n","\n","Além disso, lembre-se de que você pode implementar qualquer <a href=\"https://otexts.com/fpp2/index.html\" class=\"external\">modelo clássico de série temporal</a> no TensorFlow - este tutorial se concentra apenas na funcionalidade integrada do TensorFlow.\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb","timestamp":1712177388865}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"}},"nbformat":4,"nbformat_minor":0}
