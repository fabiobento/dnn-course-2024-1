{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2402e6",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_time_series/class_02/TS%20-%20W2%20-%2014%20-%20Atividade_Avaliativa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b95687",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30350af2",
   "metadata": {},
   "source": [
    "# Laboratório Prático: Previsão de séries temporais\n",
    "\n",
    "Seja bem-vindo!\n",
    "\n",
    "Na tarefa anterior, você teve alguma exposição ao trabalho com dados de séries temporais, mas não usou técnicas de aprendizado de máquina para suas previsões.\n",
    "\n",
    "Nesta semana, você usará uma rede neural profunda para criar previsões e ver como essa técnica se compara às que você já experimentou. Mais uma vez, todos os dados serão sintéticos.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea662d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjujz601HcS",
    "outputId": "21a00a04-e660-4eb1-dc6f-8ad3741dee5a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5dbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/cert_prof_time_series/class_02/images.zip\n",
    "!unzip -n -q images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00897401",
   "metadata": {},
   "source": [
    "## Gerando os dados\n",
    "\n",
    "\n",
    "A próxima célula inclui um conjunto de funções auxiliares para gerar e plotar a série temporal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Tempo\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.grid(False)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Apenas um padrão arbitrário, você pode alterá-lo se desejar\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 6 * np.pi), \n",
    "                    2 / np.exp(9 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repete o mesmo padrão em cada período\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512591c",
   "metadata": {},
   "source": [
    "Você gerará dados de séries temporais muito parecidos com os dos laboratórios passados, mas com algumas diferenças.\n",
    "\n",
    "**Observe que, desta vez, toda a geração é feita em uma função e as variáveis globais são salvas em uma classe de dados. Isso é feito para evitar o uso do escopo global, como foi feito na anteriormente.**\n",
    "\n",
    "Se você nunca usou classes de dados antes, elas são apenas classes Python que fornecem uma sintaxe conveniente para armazenar dados. Você pode ler mais sobre elas em [docs](https://docs.python.org/3/library/dataclasses.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series():\n",
    "    # A dimensão de tempo ou a coordenada x da série temporal\n",
    "    time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "\n",
    "    # A série inicial é apenas uma linha reta com uma interceptação y\n",
    "    y_intercept = 10\n",
    "    slope = 0.005\n",
    "    series = trend(time, slope) + y_intercept\n",
    "\n",
    "    # Adição de sazonalidade\n",
    "    amplitude = 50\n",
    "    series += seasonality(time, period=365, amplitude=amplitude)\n",
    "\n",
    "    # Adicionando algum ruído\n",
    "    noise_level = 3\n",
    "    series += noise(time, noise_level, seed=51)\n",
    "    \n",
    "    return time, series\n",
    "\n",
    "\n",
    "# Salve todas as variáveis \"globais\" na classe G (G significa global)\n",
    "@dataclass\n",
    "class G:\n",
    "    TIME, SERIES = generate_time_series()\n",
    "    SPLIT_TIME = 1100\n",
    "    WINDOW_SIZE = 20\n",
    "    BATCH_SIZE = 32\n",
    "    SHUFFLE_BUFFER_SIZE = 1000\n",
    "    \n",
    "# Plotar a série gerada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(G.TIME, G.SERIES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb315b",
   "metadata": {},
   "source": [
    "## Dividir os dados\n",
    "\n",
    "Como você já codificou a função `train_val_split` durante a atividade avaliativa passada, desta vez ela é fornecida para você:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dcbfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "Zswl7jRtGzkk",
    "outputId": "acfe857a-4a0f-4d41-bd45-1df7fa26f4d0"
   },
   "outputs": [],
   "source": [
    "def train_val_split(time, series, time_step=G.SPLIT_TIME):\n",
    "\n",
    "    time_train = time[:time_step]\n",
    "    series_train = series[:time_step]\n",
    "    time_valid = time[time_step:]\n",
    "    series_valid = series[time_step:]\n",
    "\n",
    "    return time_train, series_train, time_valid, series_valid\n",
    "\n",
    "\n",
    "# Dividir o conjunto de dados\n",
    "time_train, series_train, time_valid, series_valid = train_val_split(G.TIME, G.SERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0709eaf",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "Como você viu nos laboratórios, é possível alimentar os dados para treinamento criando um conjunto de dados com as etapas de processamento apropriadas, como `windowing`, `flattening`, `batching` e `shuffling`. Para isso, complete a função `windowed_dataset` abaixo.\n",
    "\n",
    "Observe que essa função recebe um `series`, `window_size`, `batch_size` e `shuffle_buffer` e os três últimos têm como padrão os valores \"globais\" definidos anteriormente.\n",
    "\n",
    "Não deixe de consultar a [docs](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) sobre o `TF Datasets` se precisar de ajuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b53b59",
   "metadata": {
    "id": "4sTTIOCbyShY"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "    \n",
    "    # Criar conjunto de dados a partir da série\n",
    "    dataset = None\n",
    "    \n",
    "    # Percorra o conjunto de dados com janela apropriada\n",
    "    dataset = None\n",
    "    \n",
    "    # Achatar o conjunto de dados\n",
    "    dataset = None\n",
    "    \n",
    "    # Embaralhe-o\n",
    "    dataset = None\n",
    "    \n",
    "    # Divida-o em recursos e rótulos\n",
    "    dataset = None\n",
    "    \n",
    "    # Definas os lotes\n",
    "    dataset = None\n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237af965",
   "metadata": {},
   "source": [
    "Para testar sua função, você usará um `window_size` de 1, o que significa que você usará cada valor para prever o próximo. Isso para 5 elementos, já que um `batch_size` de 5 é usado e nenhum embaralhamento, já que `shuffle_buffer` está definido como 1.\n",
    "\n",
    "Com isso, o lote de recursos deve ser idêntico aos primeiros 5 elementos do `series_train` e o lote de rótulos deve ser igual aos elementos 2 a 6 do `series_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste sua função com janelas de tamanho 1 e sem embaralhamento\n",
    "test_dataset = windowed_dataset(series_train, window_size=1, batch_size=5, shuffle_buffer=1)\n",
    "\n",
    "# Obter o primeiro lote do conjunto de dados de teste\n",
    "batch_of_features, batch_of_labels = next((iter(test_dataset)))\n",
    "\n",
    "print(f\"batch_of_features é do tipo: {type(batch_of_features)}\\n\")\n",
    "print(f\"batch_of_labels é do tipo: {type(batch_of_labels)}\\n\")\n",
    "print(f\"batch_of_features tem o formato: {batch_of_features.shape}\\n\")\n",
    "print(f\"batch_of_labels tem o formato: {batch_of_labels.shape}\\n\")\n",
    "print(f\"batch_of_features é igual aos cinco primeiros elementos da série: {np.allclose(batch_of_features.numpy().flatten(), series_train[:5])}\\n\")\n",
    "print(f\"batch_of_labels  é igual aos cinco primeiros rótulos: {np.allclose(batch_of_labels.numpy(), series_train[1:6])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eeebe7",
   "metadata": {},
   "source": [
    "**Saída Esperada:**\n",
    "\n",
    "```\n",
    "batch_of_features é do tipo: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "\n",
    "batch_of_labelsé do tipo: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "\n",
    "batch_of_features tem o formato: (5, 1)\n",
    "\n",
    "batch_of_labels tem o formato: (5,)\n",
    "\n",
    "batch_of_features é igual aos cinco primeiros elementos da série: True\n",
    "\n",
    "batch_of_labels é igual aos cinco primeiros rótulos: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4dc813",
   "metadata": {},
   "source": [
    "## Definição da arquitetura do modelo\n",
    "\n",
    "Agora que você tem uma função que processará os dados antes que eles sejam inseridos na rede neural para treinamento, é hora de definir a arquitetura da camada.\n",
    "\n",
    "Complete a função `create_model` abaixo. Observe que essa função recebe o `window_size`, pois esse será um parâmetro importante para a primeira camada de sua rede.\n",
    "\n",
    "Dica:\n",
    "- Você só precisará das camadas `Dense`.\n",
    "- Não inclua as camadas `Lambda`. Elas não são necessárias e são incompatíveis com o formato `HDF5` que será usado para salvar seu modelo para classificação.\n",
    "- O treinamento deve ser muito rápido, portanto, se perceber que cada época está demorando mais do que alguns segundos, considere tentar uma arquitetura diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b40dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW-vT7eLYAdb",
    "outputId": "94611183-4107-4062-cefd-c79d902d4e2f"
   },
   "outputs": [],
   "source": [
    "def create_model(window_size=G.WINDOW_SIZE):\n",
    "\n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "\n",
    "    model = tf.keras.models.Sequential([ \n",
    "        \n",
    "    ]) \n",
    "\n",
    "    model.compile(loss=None,\n",
    "                  optimizer=None)\n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f836133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o processamento a toda a série de treinamento\n",
    "dataset = windowed_dataset(series_train)\n",
    "\n",
    "# Salvar uma instância do modelo\n",
    "model = create_model()\n",
    "\n",
    "# Treine\n",
    "model.fit(dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83ea16",
   "metadata": {},
   "source": [
    "## Avaliação da previsão\n",
    "\n",
    "Agora é hora de avaliar o desempenho da previsão. Para isso, você pode usar a função `compute_metrics` que codificou na tarefa anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_series, forecast):\n",
    "    \n",
    "    mse = tf.keras.metrics.mean_squared_error(true_series, forecast).numpy()\n",
    "    mae = tf.keras.metrics.mean_absolute_error(true_series, forecast).numpy()\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff588f4",
   "metadata": {},
   "source": [
    "Neste ponto, apenas o modelo que executará a previsão está pronto, mas você ainda precisa calcular a previsão real. \n",
    "\n",
    "Para isso, execute a célula abaixo que usa a função `generate_forecast` para calcular a previsão. Essa função gera o próximo valor com base em um conjunto de pontos `window_size` anteriores para cada ponto no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608d29d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "efhco2rYyIFF",
    "outputId": "3ee47e36-7681-4d6b-9c9c-ad73883c3fda"
   },
   "outputs": [],
   "source": [
    "def generate_forecast(series=G.SERIES, split_time=G.SPLIT_TIME, window_size=G.WINDOW_SIZE):\n",
    "    forecast = []\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
    "\n",
    "    forecast = forecast[split_time-window_size:]\n",
    "    results = np.array(forecast)[:, 0, 0]\n",
    "    return results\n",
    "\n",
    "\n",
    "# Salvar a previsão\n",
    "dnn_forecast = generate_forecast()\n",
    "\n",
    "# Plote\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, series_valid)\n",
    "plot_series(time_valid, dnn_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf5678",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "Uma série semelhante a esta \n",
    "\n",
    "<div>\n",
    "<img src=\"images/forecast.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96085ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = compute_metrics(series_valid, dnn_forecast)\n",
    "\n",
    "print(f\"mse: {mse:.2f}, mae: {mae:.2f} para a previsão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275d537",
   "metadata": {},
   "source": [
    "**Para ser aprovado nesta tarefa, sua previsão deve atingir um MSE de 30 ou menos.**\n",
    "\n",
    "- Se a sua previsão não atingir esse limite, tente treinar novamente o modelo com uma arquitetura diferente ou ajustar os parâmetros do otimizador.\n",
    "\n",
    "\n",
    "- Se a previsão tiver atingido esse limite, execute a seguinte célula para salvar o modelo em um arquivo HDF5 que será usado para avaliação e, depois disso, envie a tarefa para avaliação.\n",
    "\n",
    "\n",
    "- Certifique-se de não ter usado camadas `Lambda` em seu modelo, pois elas são incompatíveis com o formato `HDF5` que será usado para salvar seu modelo para classificação.\n",
    "\n",
    "\n",
    "- Esse ambiente inclui um arquivo fictício `my_model.h5` que é apenas um modelo fictício treinado para uma época. **Para substituir esse arquivo pelo seu modelo real, é necessário executar a próxima célula antes de também enviá-lo para avaliação, junto com o notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve seu modelo no formato HDF5\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a42cdc",
   "metadata": {},
   "source": [
    "**Parabéns por ter concluído a tarefa!**\n",
    "\n",
    "Você implementou com sucesso uma rede neural capaz de prever séries temporais e, ao mesmo tempo, aprendeu a aproveitar a classe Dataset do Tensorflow para processar dados de séries temporais!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
