{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"t_iHs_wm2Mhh"},"source":["# Demonstração da segmentação de imagens com Mask R-CNN\n","\n","Neste laboratório, você verá como usar um modelo [Mask R-CNN] (https://arxiv.org/abs/1703.06870) do Tensorflow Hub para detecção de objetos e segmentação de instâncias. Isso significa que, além das caixas delimitadoras, o modelo também é capaz de prever máscaras de segmentação para cada instância de uma classe na imagem. Você já encontrou a maioria dos comandos aqui quando trabalhou com a API Object Dection e verá como pode usá-la com modelos de segmentação de instância. Vamos começar!"]},{"cell_type":"markdown","metadata":{"id":"VNlKYq2x4fa0"},"source":["*Observação: você deve usar uma TPU para esse laboratório devido aos requisitos de processamento desse modelo. Já o ativamos para você, mas se for usá-lo em outro colab, poderá alterar o tempo de execução em `Runtime --> Change runtime type` e selecionar `TPU`.*"]},{"cell_type":"markdown","metadata":{"id":"m2gVpI7s53Xr"},"source":["## Instalação\n","\n","Conforme mencionado, você usará a [API de detecção de objetos do Tensorflow 2](https://github.com/tensorflow/models/tree/master/research/object_detection). Você pode fazer isso clonando o [Tensorflow Model Garden](https://github.com/tensorflow/models) e instalando os pacotes de detecção de objetos, como fez anteriormente."]},{"cell_type":"code","metadata":{"id":"Q2yTMLA0yjpP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268442981,"user_tz":180,"elapsed":5403,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"be34dfef-60a1-46f0-b1d8-0f810078dce3"},"source":["# Clonar o repositório de modelos do Tensorflow\n","!git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3909, done.\u001b[K\n","remote: Counting objects: 100% (3909/3909), done.\u001b[K\n","remote: Compressing objects: 100% (3012/3012), done.\u001b[K\n","remote: Total 3909 (delta 1130), reused 2009 (delta 844), pack-reused 0\u001b[K\n","Receiving objects: 100% (3909/3909), 49.65 MiB | 26.80 MiB/s, done.\n","Resolving deltas: 100% (1130/1130), done.\n"]}]},{"cell_type":"code","metadata":{"id":"8pwmP93l9IAu","executionInfo":{"status":"ok","timestamp":1687268442981,"user_tz":180,"elapsed":2,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}}},"source":["# Compilar os buffers de protocolo da API de detecção de objetos\n","!cd models/research/ && protoc object_detection/protos/*.proto --python_out=."],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXiyXBAl9Icu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268445552,"user_tz":180,"elapsed":250,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"d3b8d580-ff54-4b32-cb42-0d8a0029bb69"},"source":["%%writefile models/research/setup.py\n","\n","import os\n","from setuptools import find_packages\n","from setuptools import setup\n","\n","REQUIRED_PACKAGES = [\n","    'tf-models-official==2.7.0',\n","    'tensorflow_io'\n","]\n","\n","setup(\n","    name='object_detection',\n","    version='0.1',\n","    install_requires=REQUIRED_PACKAGES,\n","    include_package_data=True,\n","    packages=(\n","        [p for p in find_packages() if p.startswith('object_detection')] +\n","        find_packages(where=os.path.join('.', 'slim'))),\n","    package_dir={\n","        'datasets': os.path.join('slim', 'datasets'),\n","        'nets': os.path.join('slim', 'nets'),\n","        'preprocessing': os.path.join('slim', 'preprocessing'),\n","        'deployment': os.path.join('slim', 'deployment'),\n","        'scripts': os.path.join('slim', 'scripts'),\n","    },\n","    description='Tensorflow Object Detection Library',\n","    python_requires='>3.6',\n",")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing models/research/setup.py\n"]}]},{"cell_type":"code","metadata":{"id":"aFcNfYuH9I4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268497503,"user_tz":180,"elapsed":43256,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"b8ecf2bb-9a07-4ad6-b77e-77fd60535f2c"},"source":["# Execute o script de configuração que você acabou de escrever\n","!python -m pip install models/research"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tf-models-official==2.7.0 (from object-detection==0.1)\n","  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n","  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.29.34)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (8.4.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (2.84.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.5.13)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (3.7.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.25.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.7.0.72)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.5.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (2.0.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (6.0)\n","Collecting sacrebleu (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.10.1)\n","Collecting sentencepiece (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.16.0)\n","Collecting tensorflow-addons (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.9.2)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.13.0)\n","Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-text>=2.7.0 (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.32.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.21.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.17.3)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.1.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.11.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (4.65.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.7.0->object-detection==0.1) (2022.7.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.3.25)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (16.0.0)\n","Collecting numpy>=1.15.4 (from tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (67.7.2)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (4.6.3)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.0->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (3.0.9)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0->object-detection==0.1) (4.9)\n","Collecting portalocker (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (2022.10.31)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (0.8.10)\n","Collecting colorama (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (4.9.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.2.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official==2.7.0->object-detection==0.1)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (8.1.3)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.40.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (5.12.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (3.15.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.59.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (5.3.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (3.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.1.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696875 sha256=d06ddedd1ffd1e83ae7e674ff0a7d72d185f1eb222ee8698eb7e3f7f10d45d65\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-tv0axbe7/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=2246cfa218e8c7ba835aa200b37ef9530d0d2a7e9aba01ab55ad0c4e660ec859\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built object-detection seqeval\n","Installing collected packages: sentencepiece, typeguard, tensorflow_io, portalocker, numpy, colorama, tensorflow-model-optimization, tensorflow-addons, sacrebleu, seqeval, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.0\n","    Uninstalling numpy-1.25.0:\n","      Successfully uninstalled numpy-1.25.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n","flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n","orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed colorama-0.4.6 numpy-1.23.5 object-detection-0.1 portalocker-2.7.0 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-addons-0.20.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.12.1 tensorflow_io-0.32.0 tf-models-official-2.7.0 typeguard-2.13.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"RPbB7s8hPHfO"},"source":["## Importar bibliotecas"]},{"cell_type":"code","metadata":{"id":"6EtGbyNc8VgS","executionInfo":{"status":"ok","timestamp":1687268553958,"user_tz":180,"elapsed":6292,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}}},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image\n","from six.moves.urllib.request import urlopen\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import ops as utils_ops\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","%matplotlib inline"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zvxMtmtE5Pro"},"source":["## Utilitários\n","\n","Por conveniência, você usará uma função para converter uma imagem em uma matriz numpy. Você pode passar um caminho relativo para uma imagem (por exemplo, para um diretório local) ou um URL. Você pode ver isso no dicionário `TEST_IMAGES` abaixo. Alguns caminhos apontam para imagens de teste que vêm com o pacote da API (por exemplo, `Beach`), enquanto outros são URLs que apontam para imagens on-line (por exemplo, `Street`)."]},{"cell_type":"code","metadata":{"id":"A-JE7Rj6ybEz","executionInfo":{"status":"ok","timestamp":1687268553958,"user_tz":180,"elapsed":1,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}}},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Carrega uma imagem de um arquivo em uma matriz numpy.\n","\n","  Coloca a imagem em uma matriz numpy para alimentar o gráfico do tensorflow.\n","  Observe que, por convenção, nós a colocamos em uma matriz numpy com a forma\n","  (altura, largura, canais), onde canais=3 para RGB.\n","\n","  Args:\n","    path: o caminho do arquivo para a imagem\n","\n","  Retorna:\n","    matriz numpy uint8 com formato (img_height, img_width, 3)\n","  \"\"\"\n","  image = None\n","  if(path.startswith('http')):\n","    response = urlopen(path)\n","    image_data = response.read()\n","    image_data = BytesIO(image_data)\n","    image = Image.open(image_data)\n","  else:\n","    image_data = tf.io.gfile.GFile(path, 'rb').read()\n","    image = Image.open(BytesIO(image_data))\n","\n","  (im_width, im_height) = (image.size)\n","  return np.array(image.getdata()).reshape(\n","      (1, im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","# dicionário com tags de imagem como chaves e caminhos de imagem como valores\n","TEST_IMAGES = {\n","  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n","  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n","  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n","  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n","  # By 663highland, Source: https://commons.wikimedia.org/wiki/File:Kitano_Street_Kobe01s5s4110.jpg\n","  'Street' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Kitano_Street_Kobe01s5s4110.jpg/2560px-Kitano_Street_Kobe01s5s4110.jpg'\n","}"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jf7jVN8N-DJP"},"source":["## Load the Model\n","\n","Tensorflow Hub provides a Mask-RCNN model that is built with the Object Detection API. You can read about the details [here](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1). Let's first load the model and see how to use it for inference in the next section."]},{"cell_type":"code","metadata":{"id":"UbVcXrMay38S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268632586,"user_tz":180,"elapsed":4,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"efe5eb20-bfcc-4cd6-d45f-a889c6a215ab"},"source":["model_display_name = 'Mask R-CNN Inception ResNet V2 1024x1024'\n","model_handle = 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n","\n","print('Selected model:'+ model_display_name)\n","print('Model Handle at TensorFlow Hub: {}'.format(model_handle))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected model:Mask R-CNN Inception ResNet V2 1024x1024\n","Model Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1\n"]}]},{"cell_type":"code","metadata":{"id":"F7nTrTOfzNsF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268681041,"user_tz":180,"elapsed":48458,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"01608796-d8db-41cb-e765-be68db4c4bc0"},"source":["# This will take 10 to 15 minutes to finish\n","print('loading model...')\n","hub_model = hub.load(model_handle)\n","print('model loaded!')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["loading model...\n","model loaded!\n"]}]},{"cell_type":"markdown","metadata":{"id":"9HS4NLZa-JmU"},"source":["## Inferência\n","\n","Você usará o modelo que acabou de carregar para fazer a segmentação de instância em uma imagem. Primeiro, escolha uma das imagens de teste que você especificou anteriormente e carregue-a em uma matriz numpy."]},{"cell_type":"code","metadata":{"id":"Jyw4ktg2zX8W","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uKwjkbHX9OxeTrWuoes0jXaUSq925PIj"},"executionInfo":{"status":"ok","timestamp":1687268691609,"user_tz":180,"elapsed":10569,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"62818e2f-7100-4fd2-ef6c-aa1b1a2c1181"},"source":["# Escolha uma e use-a como chave para TEST_IMAGES abaixo:\n","# ['Beach', 'Street', 'Dogs','Phones']\n","\n","image_path = TEST_IMAGES['Street']\n","\n","image_np = load_image_into_numpy_array(image_path)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np[0])\n","plt.show()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"XiTl--ZhAJm0"},"source":["Você pode executar a inferência simplesmente passando a matriz numpy de uma *única* imagem para o modelo. Observe que esse modelo não oferece suporte a lotes. Como você viu nos notebooks da Semana 2, isso produzirá um dicionário contendo os resultados. Eles são descritos na seção `Outputs` da [documentação](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1)"]},{"cell_type":"code","metadata":{"id":"xHHfCU-QzdLp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268792896,"user_tz":180,"elapsed":101289,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"b7a14cb0-8876-4275-d6fa-693b05b0eeb2"},"source":["# executar inferência\n","results = hub_model(image_np)\n","\n","# os valores de saída são tensores e só precisamos do parâmetro numpy()\n","# quando visualizamos os resultados\n","result = {key:value.numpy() for key,value in results.items()}\n","\n","# imprimir as chaves\n","for key in result.keys():\n","  print(key)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["num_proposals\n","rpn_box_predictor_features\n","num_detections\n","proposal_boxes_normalized\n","detection_classes\n","refined_box_encodings\n","box_classifier_features\n","raw_detection_boxes\n","rpn_features_to_crop\n","final_anchors\n","detection_boxes\n","rpn_box_encodings\n","detection_anchor_indices\n","class_predictions_with_background\n","proposal_boxes\n","raw_detection_scores\n","rpn_objectness_predictions_with_background\n","mask_predictions\n","detection_multiclass_scores\n","anchors\n","detection_masks\n","detection_scores\n","image_shape\n"]}]},{"cell_type":"markdown","metadata":{"id":"9NXwqHumEtpp"},"source":["## Visualizando os resultados\n","\n","Agora você pode plotar os resultados na imagem original. Primeiro, você precisa criar o dicionário `category_index` que conterá os IDs e nomes das classes. O modelo foi treinado no conjunto de dados [COCO2017](https://cocodataset.org/) e o pacote API tem os rótulos salvos em um formato diferente (ou seja, `mscoco_label_map.pbtxt`). Você pode usar a função de utilitário interno [create_category_index_from_labelmap](https://github.com/tensorflow/models/blob/5ee7a4627edcbbaaeb8a564d690b5f1bc498a0d7/research/object_detection/utils/label_map_util.py#L313) para converter isso no formato de dicionário necessário."]},{"cell_type":"code","metadata":{"id":"B4ibUChhyujW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687268792896,"user_tz":180,"elapsed":3,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"fdd4ace1-4e59-43f7-a1ff-7ad3d7f14b4e"},"source":["PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","# sample output\n","print(category_index[1])\n","print(category_index[2])\n","print(category_index[4])"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': 1, 'name': 'person'}\n","{'id': 2, 'name': 'bicycle'}\n","{'id': 4, 'name': 'motorcycle'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"hd1Nhy9bIK-M"},"source":["Em seguida, você pré-processará as máscaras e, finalmente, plotará os resultados.\n","\n","* O dicionário de resultados contém uma chave `detection_masks` que contém máscaras de segmentação para cada caixa. Isso será convertido primeiro em máscaras que serão sobrepostas ao tamanho total da imagem.\n","* Você também selecionará os valores de pixel da máscara que estão acima de um determinado limite. Escolhemos um valor de `0,6`, mas sinta-se à vontade para modificá-lo e ver quais resultados você obterá. Se você escolher um valor mais baixo, provavelmente notará pixels de máscara que estão fora do objeto.\n","* Como você já viu anteriormente, é possível usar `visualize_boxes_and_labels_on_image_array()` para plotar os resultados na imagem. A diferença desta vez é o parâmetro `instance_masks` e você passará as caixas de detecção reenquadradas para ver as máscaras de segmentação na imagem.\n","\n","Você pode ver como tudo isso é tratado no código abaixo."]},{"cell_type":"code","metadata":{"id":"Y-e89eLPzjF2","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1luhlm5BEBZMTivZQLO5xIIRiL0Zq0Z1I"},"executionInfo":{"status":"ok","timestamp":1687268809755,"user_tz":180,"elapsed":16860,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"}},"outputId":"b22e9f0b-5e1b-434c-f23e-4a815ba2ad62"},"source":["# Manipular modelos com máscaras:\n","label_id_offset = 0\n","image_np_with_mask = image_np.copy()\n","\n","if 'detection_masks' in result:\n","\n","  # converter np.arrays em tensores\n","  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n","  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n","\n","  # Reenquadre a máscara da caixa delimitadora de acordo com o tamanho da imagem.\n","  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes,\n","              image_np.shape[1], image_np.shape[2])\n","\n","  # valores de pixel da máscara de filtro que estão acima de um limite especificado\n","  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.6,\n","                                      tf.uint8)\n","\n","  # obter a matriz numérica\n","  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","\n","# Sobrepor caixas rotuladas e máscaras de segmentação na imagem\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_mask[0],\n","      result['detection_boxes'][0],\n","      (result['detection_classes'][0] + label_id_offset).astype(int),\n","      result['detection_scores'][0],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=100,\n","      min_score_thresh=.70,\n","      agnostic_mode=False,\n","      instance_masks=result.get('detection_masks_reframed', None),\n","      line_thickness=8)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np_with_mask[0])\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}