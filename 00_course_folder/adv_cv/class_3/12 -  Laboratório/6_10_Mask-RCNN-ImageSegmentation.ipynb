{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/adv_cv/class_3/12%20-%20%20Laborat%C3%B3rio/6_10_Mask-RCNN-ImageSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["adaptado de [Visão computacional avançada com TensorFlow](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow?specialization=tensorflow-advanced-techniques) de [Laurence Moroney](https://laurencemoroney.com/) e [Andrew Ng](https://www.coursera.org/instructor/andrewng) , [DeepLearning.AI](https://www.deeplearning.ai/)"]},{"cell_type":"markdown","metadata":{"id":"t_iHs_wm2Mhh"},"source":["# Demonstração da segmentação de imagens com Mask R-CNN\n","\n","Neste laboratório, você verá como usar um modelo [Mask R-CNN] (https://arxiv.org/abs/1703.06870) do Tensorflow Hub para detecção de objetos e segmentação de instâncias. Isso significa que, além das caixas delimitadoras, o modelo também é capaz de prever máscaras de segmentação para cada instância de uma classe na imagem. Você já encontrou a maioria dos comandos aqui quando trabalhou com a API Object Dection e verá como pode usá-la com modelos de segmentação de instância. Vamos começar!"]},{"cell_type":"markdown","metadata":{"id":"VNlKYq2x4fa0"},"source":["*Observação: você deve usar uma TPU para esse laboratório devido aos requisitos de processamento desse modelo. Já o ativamos para você, mas se for usá-lo em outro colab, poderá alterar o tempo de execução em `Runtime --> Change runtime type` e selecionar `TPU`.*"]},{"cell_type":"markdown","metadata":{"id":"m2gVpI7s53Xr"},"source":["## Instalação\n","\n","Conforme mencionado, você usará a [API de detecção de objetos do Tensorflow 2](https://github.com/tensorflow/models/tree/master/research/object_detection). Você pode fazer isso clonando o [Tensorflow Model Garden](https://github.com/tensorflow/models) e instalando os pacotes de detecção de objetos, como fez anteriormente."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5403,"status":"ok","timestamp":1687268442981,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"Q2yTMLA0yjpP","outputId":"be34dfef-60a1-46f0-b1d8-0f810078dce3"},"outputs":[],"source":["# Clone the tensorflow models repository\n","!git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1687268442981,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"8pwmP93l9IAu"},"outputs":[],"source":["# Compile the Object Detection API protocol buffers and install the necessary packages\n","!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."]},{"cell_type":"markdown","metadata":{"id":"RPbB7s8hPHfO"},"source":["## Importar bibliotecas"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6292,"status":"ok","timestamp":1687268553958,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"6EtGbyNc8VgS"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image\n","from six.moves.urllib.request import urlopen\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import ops as utils_ops\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"zvxMtmtE5Pro"},"source":["## Utilitários\n","\n","Por conveniência, você usará uma função para converter uma imagem em uma matriz numpy. Você pode passar um caminho relativo para uma imagem (por exemplo, para um diretório local) ou um URL. Você pode ver isso no dicionário `TEST_IMAGES` abaixo. Alguns caminhos apontam para imagens de teste que vêm com o pacote da API (por exemplo, `Beach`), enquanto outros são URLs que apontam para imagens on-line (por exemplo, `Street`)."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1687268553958,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"A-JE7Rj6ybEz"},"outputs":[],"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Carrega uma imagem de um arquivo em uma matriz numpy.\n","\n","  Coloca a imagem em uma matriz numpy para alimentar o gráfico do tensorflow.\n","  Observe que, por convenção, nós a colocamos em uma matriz numpy com a forma\n","  (altura, largura, canais), onde canais=3 para RGB.\n","\n","  Args:\n","    path: o caminho do arquivo para a imagem\n","\n","  Retorna:\n","    matriz numpy uint8 com formato (img_height, img_width, 3)\n","  \"\"\"\n","  image = None\n","  if(path.startswith('http')):\n","    response = urlopen(path)\n","    image_data = response.read()\n","    image_data = BytesIO(image_data)\n","    image = Image.open(image_data)\n","  else:\n","    image_data = tf.io.gfile.GFile(path, 'rb').read()\n","    image = Image.open(BytesIO(image_data))\n","\n","  (im_width, im_height) = (image.size)\n","  return np.array(image.getdata()).reshape(\n","      (1, im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","# dicionário com tags de imagem como chaves e caminhos de imagem como valores\n","TEST_IMAGES = {\n","  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n","  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n","  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n","  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n","  # By 663highland, Source: https://commons.wikimedia.org/wiki/File:Kitano_Street_Kobe01s5s4110.jpg\n","  'Street' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Kitano_Street_Kobe01s5s4110.jpg/2560px-Kitano_Street_Kobe01s5s4110.jpg'\n","}"]},{"cell_type":"markdown","metadata":{"id":"Jf7jVN8N-DJP"},"source":["## Carrregar o modelo\n","\n","O Tensorflow Hub fornece um modelo Mask-RCNN que é construído com a API de detecção de objetos. Você pode ler sobre os detalhes [aqui](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1).\n","\n","Vamos primeiro carregar o modelo e ver como usá-lo para inferência na próxima seção."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687268632586,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"UbVcXrMay38S","outputId":"efe5eb20-bfcc-4cd6-d45f-a889c6a215ab"},"outputs":[],"source":["model_display_name = 'Mask R-CNN Inception ResNet V2 1024x1024'\n","model_handle = 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n","\n","print('Modelo selecionado:'+ model_display_name)\n","print('Manuseio de modelos no TensorFlow Hub: {}'.format(model_handle))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48458,"status":"ok","timestamp":1687268681041,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"F7nTrTOfzNsF","outputId":"01608796-d8db-41cb-e765-be68db4c4bc0"},"outputs":[],"source":["# Isso levará de 10 a 15 minutos para ser concluído\n","print('Carregando o modelo...')\n","hub_model = hub.load(model_handle)\n","print('Modelo Carregado!')"]},{"cell_type":"markdown","metadata":{"id":"9HS4NLZa-JmU"},"source":["## Inferência\n","\n","Você usará o modelo que acabou de carregar para fazer a segmentação de instância em uma imagem. Primeiro, escolha uma das imagens de teste que você especificou anteriormente e carregue-a em uma matriz numpy."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uKwjkbHX9OxeTrWuoes0jXaUSq925PIj"},"executionInfo":{"elapsed":10569,"status":"ok","timestamp":1687268691609,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"Jyw4ktg2zX8W","outputId":"62818e2f-7100-4fd2-ef6c-aa1b1a2c1181"},"outputs":[],"source":["# Escolha uma e use-a como chave para TEST_IMAGES abaixo:\n","# ['Beach', 'Street', 'Dogs','Phones']\n","\n","image_path = TEST_IMAGES['Street']\n","\n","image_np = load_image_into_numpy_array(image_path)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XiTl--ZhAJm0"},"source":["Você pode executar a inferência simplesmente passando a matriz numpy de uma *única* imagem para o modelo. Observe que esse modelo não oferece suporte a lotes. Como você viu nos notebooks da Semana 2, isso produzirá um dicionário contendo os resultados. Eles são descritos na seção `Outputs` da [documentação](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101289,"status":"ok","timestamp":1687268792896,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"xHHfCU-QzdLp","outputId":"b7a14cb0-8876-4275-d6fa-693b05b0eeb2"},"outputs":[],"source":["# executar inferência\n","results = hub_model(image_np)\n","\n","# os valores de saída são tensores e só precisamos do parâmetro numpy()\n","# quando visualizamos os resultados\n","result = {key:value.numpy() for key,value in results.items()}\n","\n","# imprimir as chaves\n","for key in result.keys():\n","  print(key)"]},{"cell_type":"markdown","metadata":{"id":"9NXwqHumEtpp"},"source":["## Visualizando os resultados\n","\n","Agora você pode plotar os resultados na imagem original. Primeiro, você precisa criar o dicionário `category_index` que conterá os IDs e nomes das classes. O modelo foi treinado no conjunto de dados [COCO2017](https://cocodataset.org/) e o pacote API tem os rótulos salvos em um formato diferente (ou seja, `mscoco_label_map.pbtxt`). Você pode usar a função de utilitário interno [create_category_index_from_labelmap](https://github.com/tensorflow/models/blob/5ee7a4627edcbbaaeb8a564d690b5f1bc498a0d7/research/object_detection/utils/label_map_util.py#L313) para converter isso no formato de dicionário necessário."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687268792896,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"B4ibUChhyujW","outputId":"fdd4ace1-4e59-43f7-a1ff-7ad3d7f14b4e"},"outputs":[],"source":["PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","# sample output\n","print(category_index[1])\n","print(category_index[2])\n","print(category_index[4])"]},{"cell_type":"markdown","metadata":{"id":"hd1Nhy9bIK-M"},"source":["Em seguida, você pré-processará as máscaras e, finalmente, plotará os resultados.\n","\n","* O dicionário de resultados contém uma chave `detection_masks` que contém máscaras de segmentação para cada caixa. Isso será convertido primeiro em máscaras que serão sobrepostas ao tamanho total da imagem.\n","* Você também selecionará os valores de pixel da máscara que estão acima de um determinado limite. Escolhemos um valor de `0,6`, mas sinta-se à vontade para modificá-lo e ver quais resultados você obterá. Se você escolher um valor mais baixo, provavelmente notará pixels de máscara que estão fora do objeto.\n","* Como você já viu anteriormente, é possível usar `visualize_boxes_and_labels_on_image_array()` para plotar os resultados na imagem. A diferença desta vez é o parâmetro `instance_masks` e você passará as caixas de detecção reenquadradas para ver as máscaras de segmentação na imagem.\n","\n","Você pode ver como tudo isso é tratado no código abaixo."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1luhlm5BEBZMTivZQLO5xIIRiL0Zq0Z1I"},"executionInfo":{"elapsed":16860,"status":"ok","timestamp":1687268809755,"user":{"displayName":"Fabio Bento","userId":"11144591974393529742"},"user_tz":180},"id":"Y-e89eLPzjF2","outputId":"b22e9f0b-5e1b-434c-f23e-4a815ba2ad62"},"outputs":[],"source":["# Manipular modelos com máscaras:\n","label_id_offset = 0\n","image_np_with_mask = image_np.copy()\n","\n","if 'detection_masks' in result:\n","\n","  # converter np.arrays em tensores\n","  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n","  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n","\n","  # Reenquadre a máscara da caixa delimitadora de acordo com o tamanho da imagem.\n","  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes,\n","              image_np.shape[1], image_np.shape[2])\n","\n","  # valores de pixel da máscara de filtro que estão acima de um limite especificado\n","  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.6,\n","                                      tf.uint8)\n","\n","  # obter a matriz numérica\n","  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","\n","# Sobrepor caixas rotuladas e máscaras de segmentação na imagem\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_mask[0],\n","      result['detection_boxes'][0],\n","      (result['detection_classes'][0] + label_id_offset).astype(int),\n","      result['detection_scores'][0],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=100,\n","      min_score_thresh=.70,\n","      agnostic_mode=False,\n","      instance_masks=result.get('detection_masks_reframed', None),\n","      line_thickness=8)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np_with_mask[0])\n","plt.show()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
