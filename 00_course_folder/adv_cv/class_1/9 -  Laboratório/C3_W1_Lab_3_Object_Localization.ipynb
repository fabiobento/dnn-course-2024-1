{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/adv_cv/class_1/9%20-%20%20Laborat%C3%B3rio/C3_W1_Lab_3_Object_Localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["adaptado de [Visão computacional avançada com TensorFlow](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow?specialization=tensorflow-advanced-techniques) de [Laurence Moroney](https://laurencemoroney.com/) e [Andrew Ng](https://www.coursera.org/instructor/andrewng) , [DeepLearning.AI](https://www.deeplearning.ai/)"]},{"cell_type":"markdown","metadata":{"id":"KsjDCIat6_UK"},"source":["# Classificação de imagens e localização de objetos\n","\n","Neste laboratório, você criará uma CNN do zero para:\n","- classificar o objeto principal em uma imagem\n","- localizá-lo desenhando caixas delimitadoras ao redor dele.\n","\n","Você usará o conjunto de dados [MNIST](http://yann.lecun.com/exdb/mnist/) para sintetizar um conjunto de dados personalizado para a tarefa:\n","- Coloque cada imagem de \"dígito\" em uma tela preta de largura 75 x 75 em locais aleatórios.\n","- Calcule as caixas delimitadoras correspondentes para esses \"dígitos\".\n","\n","A previsão da caixa delimitadora pode ser modelada como uma tarefa de \"regressão\", o que significa que o modelo preverá um valor numérico (em vez de uma categoria)."]},{"cell_type":"markdown","metadata":{"id":"qpiJj8ym0v0-"},"source":["## Importações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AoilhmYe1b5t"},"outputs":[],"source":["import os, re, time, json\n","import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n","import numpy as np\n","\n","# Testar se estamos no Google Colab\n","try:\n","  import google.colab\n","  IN_COLAB = True\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except:\n","  IN_COLAB = False\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","print(\"Tensorflow version \" + tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"xmoFKEd98MP3"},"source":["# Utilitários de visualização\n","\n","Essas funções são usadas para desenhar caixas delimitadoras ao redor dos dígitos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBjj1Fg-i_lc"},"outputs":[],"source":["#@title Utilitários de plotagem para caixas delimitadoras [RUN ME]\n","\n","im_width = 75\n","im_height = 75\n","use_normalized_coordinates = True\n","\n","def draw_bounding_boxes_on_image_array(image,\n","                                       boxes,\n","                                       color=[],\n","                                       thickness=1,\n","                                       display_str_list=()):\n","  \"\"\"Desenha caixas delimitadoras na imagem (matriz numpy).\n","  Args:\n","    image: um objeto de matriz numpy.\n","    boxes: uma matriz numpy bidimensional de [N, 4]: (ymin, xmin, ymax, xmax).\n","           As coordenadas estão no formato normalizado entre [0, 1].\n","    color: cor para desenhar a caixa delimitadora. O padrão é vermelho.\n","    thickness: espessura da linha. O valor padrão é 4.\n","    display_str_list_list: uma lista de cadeias de caracteres para cada caixa delimitadora.\n","  Raises:\n","    ValueError: se boxes não for uma matriz [N, 4]\n","  \"\"\"\n","  image_pil = PIL.Image.fromarray(image)\n","  rgbimg = PIL.Image.new(\"RGBA\", image_pil.size)\n","  rgbimg.paste(image_pil)\n","  draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness,\n","                               display_str_list)\n","  return np.array(rgbimg)\n","  \n","\n","def draw_bounding_boxes_on_image(image,\n","                                 boxes,\n","                                 color=[],\n","                                 thickness=1,\n","                                 display_str_list=()):\n","  \"\"\"Desenha caixas delimitadoras na imagem.\n","  Args:\n","    image: um objeto PIL.Image.\n","    boxes: uma matriz numérica bidimensional de [N, 4]: (ymin, xmin, ymax, xmax).\n","           As coordenadas estão no formato normalizado entre [0, 1].\n","    color: cor para desenhar a caixa delimitadora. O padrão é vermelho.\n","    thickness: espessura da linha. O valor padrão é 4.\n","    display_str_list: uma lista de cadeias de caracteres para cada caixa delimitadora.\n","                           \n","  Raises:\n","    ValueError: se boxes não for uma matriz [N, 4]\n","  \"\"\"\n","  boxes_shape = boxes.shape\n","  if not boxes_shape:\n","    return\n","  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n","    raise ValueError('A entrada deve ser do tamanho [N, 4]')\n","  for i in range(boxes_shape[0]):\n","    draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3],\n","                               boxes[i, 2], color[i], thickness, display_str_list[i])\n","        \n","def draw_bounding_box_on_image(image,\n","                               ymin,\n","                               xmin,\n","                               ymax,\n","                               xmax,\n","                               color='red',\n","                               thickness=1,\n","                               display_str=None,\n","                               use_normalized_coordinates=True):\n","  \"\"\"Adiciona uma caixa delimitadora a uma imagem.\n","  As coordenadas da caixa delimitadora podem ser especificadas em coordenadas absolutas (pixel) ou\n","  coordenadas normalizadas, definindo o argumento use_normalized_coordinates.\n","  Args:\n","    image: um objeto PIL.Image.\n","    ymin: ymin da caixa delimitadora.\n","    xmin: xmin da caixa delimitadora.\n","    ymax: ymax da caixa delimitadora.\n","    xmax: xmax da caixa delimitadora.\n","    color: cor para desenhar a caixa delimitadora. O padrão é vermelho.\n","    thickness: espessura da linha. O valor padrão é 4.\n","    display_str_list: string a ser exibida na caixa\n","    use_normalized_coordinates: Se for True (padrão), tratar as coordenadas\n","      ymin, xmin, ymax, xmax como relativas à imagem.  Caso contrário, trate as coordenadas\n","      as coordenadas como absolutas.\n","  \"\"\"\n","  draw = PIL.ImageDraw.Draw(image)\n","  im_width, im_height = image.size\n","  if use_normalized_coordinates:\n","    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n","                                  ymin * im_height, ymax * im_height)\n","  else:\n","    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n","  draw.line([(left, top), (left, bottom), (right, bottom),\n","             (right, top), (left, top)], width=thickness, fill=color)\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"USx9tRBF8hWy"},"source":["Esses utilitários são usados para visualizar os dados e as previsões."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhdz68Xm3Z4Z"},"outputs":[],"source":["#@title Utilitários de visualização [RUN ME]\n","\"\"\"\n","Esta célula contém funções auxiliares usadas somente para visualização\n","e downloads apenas. \n","\n","Você pode pular a leitura, pois há muito pouco código relacionado ao Keras ou ao Tensorflow aqui.\n","\"\"\"\n","\n","# Configuração do Matplotlib\n","plt.rc('image', cmap='gray')\n","plt.rc('grid', linewidth=0)\n","plt.rc('xtick', top=False, bottom=False, labelsize='large')\n","plt.rc('ytick', left=False, right=False, labelsize='large')\n","plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n","plt.rc('text', color='a8151a')\n","plt.rc('figure', facecolor='F0F0F0')# Fontes Matplotlib\n","MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n","\n","# extrair um lote dos conjuntos de dados. Esse código não é muito bom, ele fica muito melhor no modo eager (TODO)\n","def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n","  \n","  # Obter um lote de cada: 10000 dígitos de validação, N dígitos de treinamento\n","  batch_train_ds = training_dataset.unbatch().batch(N)\n","  \n","  # Execução ansiosa: percorre os conjuntos de dados normalmente\n","  if tf.executing_eagerly():\n","    for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:\n","      validation_digits = validation_digits.numpy()\n","      validation_labels = validation_labels.numpy()\n","      validation_bboxes = validation_bboxes.numpy()\n","      break\n","    for training_digits, (training_labels, training_bboxes) in batch_train_ds:\n","      training_digits = training_digits.numpy()\n","      training_labels = training_labels.numpy()\n","      training_bboxes = training_bboxes.numpy()\n","      break\n","  \n","  # esses foram codificados na forma one-hot no conjunto de dados\n","  validation_labels = np.argmax(validation_labels, axis=1)\n","  training_labels = np.argmax(training_labels, axis=1)\n","  \n","  return (training_digits, training_labels, training_bboxes,\n","          validation_digits, validation_labels, validation_bboxes)\n","\n","# criar dígitos de fontes locais para teste\n","def create_digits_from_local_fonts(n):\n","  font_labels = []\n","  img = PIL.Image.new('LA', (75*n, 75), color = (0,255)) # Formato 'LA': preto no canal 0, alfa no canal 1\n","  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n","  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n","  d = PIL.ImageDraw.Draw(img)\n","  for i in range(n):\n","    font_labels.append(i%10)\n","    d.text((7+i*75,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n","  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # preto no canal 0, alfa no canal 1 (descartado)\n","  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [75, 75*n]), n, axis=1), axis=0), [n, 75*75])\n","  return font_digits, font_labels\n","\n","# Utilitário para exibir uma linha de dígitos com suas previsões\n","def display_digits_with_boxes(digits, predictions, labels, pred_bboxes, bboxes, iou, title):\n","\n","  n = 10\n","\n","  indexes = np.random.choice(len(predictions), size=n)\n","  n_digits = digits[indexes]\n","  n_predictions = predictions[indexes]\n","  n_labels = labels[indexes]\n","\n","  n_iou = []\n","  if len(iou) > 0:\n","    n_iou = iou[indexes]\n","\n","  if (len(pred_bboxes) > 0):\n","    n_pred_bboxes = pred_bboxes[indexes,:]\n","\n","  if (len(bboxes) > 0):\n","    n_bboxes = bboxes[indexes,:]\n","\n","\n","  n_digits = n_digits * 255.0\n","  n_digits = n_digits.reshape(n, 75, 75)\n","  fig = plt.figure(figsize=(20, 4))\n","  plt.title(title)\n","  plt.yticks([])\n","  plt.xticks([])\n","  \n","  for i in range(10):\n","    ax = fig.add_subplot(1, 10, i+1)\n","    bboxes_to_plot = []\n","    if (len(pred_bboxes) > i):\n","      bboxes_to_plot.append(n_pred_bboxes[i])\n","    \n","    if (len(bboxes) > i):\n","      bboxes_to_plot.append(n_bboxes[i])\n","\n","    img_to_draw = draw_bounding_boxes_on_image_array(image=n_digits[i], boxes=np.asarray(bboxes_to_plot), color=['red', 'green'], display_str_list=[\"true\", \"pred\"])\n","    plt.xlabel(n_predictions[i])\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","    if n_predictions[i] != n_labels[i]:\n","      ax.xaxis.label.set_color('red')\n","\n","    \n","    \n","    plt.imshow(img_to_draw)\n","\n","    if len(iou) > i :\n","      color = \"black\"\n","      if (n_iou[i][0] < iou_threshold):\n","        color = \"red\"\n","      ax.text(0.2, -0.3, \"iou: %s\" %(n_iou[i][0]), color=color, transform=ax.transAxes)\n","\n","\n","# Utilitário para exibir curvas de treinamento e validação\n","def plot_metrics(metric_name, title, ylim=5):\n","  plt.title(title)\n","  plt.ylim(0,ylim)\n","  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n","  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"]},{"cell_type":"markdown","metadata":{"id":"_Ok__0RB-M8S"},"source":["## Seleção de estratégias"]},{"cell_type":"markdown","metadata":{"id":"R4jujVYWY9-6"},"source":["### Detecção de TPU ou GPU\n","\n","Dependendo do hardware disponível, você usará diferentes estratégias de distribuição.  Para uma conhecer as estratégias de distribuição de processamento, consulte o curso [\"Custom and Distributed Training with TensorFlow\"](https://www.coursera.org/learn/custom-distributed-training-with-tensorflow), semana 4, \"_Distributed Training_\".\n","\n","- Se a TPU estiver disponível, você usará a estratégia TPU.\n","Caso contrário:\n","- Se houver mais de uma GPU disponível, você usará a estratégia Mirrored\n","- Se uma GPU estiver disponível ou se apenas a CPU estiver disponível, você usará a estratégia padrão."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hd5zB1G7Y9-7"},"outputs":[],"source":["# Detectar hardware\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n","except ValueError:\n","  tpu = None\n","  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n","    \n","# Selecionar a estratégia de distribuição apropriada\n","if tpu:\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu) # A ida e volta entre a TPU e o host é cara. É melhor executar 128 lotes na TPU antes de reportar.\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","elif len(gpus) > 1:\n","  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n","  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n","elif len(gpus) == 1:\n","  strategy = tf.distribute.get_strategy() # Estratégia padrão que funciona na CPU e em uma única GPU\n","  print('Running on single GPU ', gpus[0].name)\n","else:\n","  strategy = tf.distribute.get_strategy() # Estratégia padrão que funciona na CPU e em uma única GPU\n","  print('Running on CPU')\n","print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{"id":"Lvo0t7XVIkWZ"},"source":["### Parâmetros\n","\n","O tamanho do lote global é o tamanho do lote por réplica (64 neste caso) vezes o número de réplicas na estratégia de distribuição."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCpkS9C_H7Tl"},"outputs":[],"source":["BATCH_SIZE = 64 * strategy.num_replicas_in_sync  # Tamanho do lote global.\n","# O tamanho do lote global será automaticamente fragmentado em todas as\n","# réplicas pela API tf.data.Dataset. Uma única TPU tem 8 núcleos.\n","# A prática recomendada é dimensionar o tamanho do lote de acordo com o número de\n","# réplicas (núcleos). A taxa de aprendizado também deve ser aumentada."]},{"cell_type":"markdown","metadata":{"id":"JVkc7nzg-WUy"},"source":["## Carregando e pré-processando o conjunto de dados\n","\n","Defina algumas funções auxiliares que farão o pré-processamento dos dados:\n","- `read_image_tfds`: sobrepõe aleatoriamente a imagem do \"dígito\" em uma tela maior.\n","- `get_training_dataset`: carrega os dados e os divide para obter o conjunto de treinamento.\n","- `get_validation_dataset`: carrega e divide os dados para obter o conjunto de validação."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZE8dgyPC1_6m"},"outputs":[],"source":["'''\n","Transforma cada imagem do conjunto de dados, colando-a em uma tela de 75x75 em locais aleatórios.\n","'''\n","def read_image_tfds(image, label):\n","    xmin = tf.random.uniform((), 0 , 48, dtype=tf.int32)\n","    ymin = tf.random.uniform((), 0 , 48, dtype=tf.int32)\n","    image = tf.reshape(image, (28,28,1,))\n","    image = tf.image.pad_to_bounding_box(image, ymin, xmin, 75, 75)\n","    image = tf.cast(image, tf.float32)/255.0\n","    xmin = tf.cast(xmin, tf.float32)\n","    ymin = tf.cast(ymin, tf.float32)\n","   \n","    xmax = (xmin + 28) / 75\n","    ymax = (ymin + 28) / 75\n","    xmin = xmin / 75\n","    ymin = ymin / 75\n","    return image, (tf.one_hot(label, 10), [xmin, ymin, xmax, ymax])\n","  \n","'''\n","Carrega e mapeia a divisão de treinamento do conjunto de dados usando a função map.\n","Observe que tentamos carregar a versão gcs, pois a TPU só pode trabalhar com conjuntos de dados no Google Cloud Storage.\n","'''\n","def get_training_dataset():\n","      \n","      with  strategy.scope():\n","        dataset = tfds.load(\"mnist\", split=\"train\", as_supervised=True, try_gcs=True)\n","        dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n","        dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n","        dataset = dataset.repeat() # Obrigatório para o Keras por enquanto\n","        dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) # drop_remainder é importante na TPU, o tamanho do lote deve ser fixo\n","        dataset = dataset.prefetch(-1)  # Busque os próximos lotes enquanto treina no lote atual (-1: ajuste automático do tamanho do buffer de pré-busca)\n","      return dataset\n","\n","'''\n","Carrega e mapeia a divisão de validação do conjunto de dados usando a função map.\n","Observe que tentamos carregar a versão gcs, pois a TPU só pode trabalhar com conjuntos de dados no Google Cloud Storage.\n","''' \n","def get_validation_dataset():\n","    dataset = tfds.load(\"mnist\", split=\"test\", as_supervised=True, try_gcs=True)\n","    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n","\n","    #dataset = dataset.cache() esse pequeno conjunto de dados pode ser totalmente armazenado em cache na RAM\n","    dataset = dataset.batch(10000, drop_remainder=True) # 10000 itens no conjunto de dados de avaliação, todos em um lote\n","    dataset = dataset.repeat() # Obrigatório para o Keras por enquanto\n","    return dataset\n","\n","# instanciar os conjuntos de dados\n","with strategy.scope():\n","  training_dataset = get_training_dataset()\n","  validation_dataset = get_validation_dataset()"]},{"cell_type":"markdown","metadata":{"id":"_fXo6GuvL3EB"},"source":["### Visualizar dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZ4tjPKvL2eh"},"outputs":[],"source":["(training_digits, training_labels, training_bboxes,\n"," validation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(training_dataset, validation_dataset, 10)\n","\n","display_digits_with_boxes(training_digits, training_labels, training_labels, np.array([]), training_bboxes, np.array([]), \"dígitos de treinamento e seus rótulos\")\n","display_digits_with_boxes(validation_digits, validation_labels, validation_labels, np.array([]), validation_bboxes, np.array([]), \"dígitos de validação e seus rótulos\")\n"]},{"cell_type":"markdown","metadata":{"id":"f8nHWWkS_eeZ"},"source":["## Definir a rede\n","\n","Aqui, você definirá sua CNN personalizada. \n","- `feature_extractor`: essas camadas convolucionais extraem as características da imagem.\n","- `classifier`:  define a camada de saída que prevê entre 10 categorias (dígitos de 0 a 9)\n","- `bounding_box_regression`: define a camada de saída que prevê 4 valores numéricos, que definem as coordenadas da caixa delimitadora (xmin, ymin, xmax, ymax)\n","- `final_model`: Combina as camadas de extração de recursos, classificação e previsão de caixa delimitadora.  \n","  - Observe que esse é outro exemplo de um modelo de ramificação, pois o modelo se divide para produzir dois tipos de saída (uma categoria e um conjunto de números).  \n","  - Como você aprendeu a usar a API funcional anteriormente, você tem a flexibilidade de definir esse tipo de modelo de ramificação!\n","- `define_and_compile_model`: escolha o otimizador e as métricas e, em seguida, compile o modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56y8UNFQIVwj"},"outputs":[],"source":["'''\n","O extrator de características é a CNN, que é composta de camadas de convolução e agrupamento(pooling).\n","'''\n","def feature_extractor(inputs):\n","    x = tf.keras.layers.Conv2D(16, activation='relu', kernel_size=3, input_shape=(75, 75, 1))(inputs)\n","    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","\n","    x = tf.keras.layers.Conv2D(32,kernel_size=3,activation='relu')(x)\n","    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","\n","    x = tf.keras.layers.Conv2D(64,kernel_size=3,activation='relu')(x)\n","    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","\n","    return x\n","\n","'''\n","dense_layers adiciona uma camada achatada e densa.\n","Isso seguirá as camadas de extração de recursos\n","'''\n","def dense_layers(inputs):\n","  x = tf.keras.layers.Flatten()(inputs)\n","  x = tf.keras.layers.Dense(128, activation='relu')(x)\n","  return x\n","\n","\n","'''\n","O classificador define a saída da classificação.\n","Ele tem um conjunto de camadas totalmente conectadas e uma camada softmax.\n","'''\n","def classifier(inputs):\n","\n","  classification_output = tf.keras.layers.Dense(10, activation='softmax', name = 'classification')(inputs)\n","  return classification_output\n","\n","\n","'''\n","Essa função define o resultado da regressão para a previsão da caixa delimitadora. \n","Observe que temos quatro saídas correspondentes a (xmin, ymin, xmax, ymax)\n","'''\n","def bounding_box_regression(inputs):\n","    bounding_box_regression_output = tf.keras.layers.Dense(units = '4', name = 'bounding_box')(inputs)\n","    return bounding_box_regression_output\n","\n","\n","def final_model(inputs):\n","    feature_cnn = feature_extractor(inputs)\n","    dense_output = dense_layers(feature_cnn)\n","\n","    '''\n","    O modelo se ramifica aqui.  \n","    A saída da camada densa é alimentada em duas ramificações:\n","    classification_output e bounding_box_output\n","    '''\n","    classification_output = classifier(dense_output)\n","    bounding_box_output = bounding_box_regression(dense_output)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = [classification_output, bounding_box_output])\n","\n","    return model\n","  \n","\n","def define_and_compile_model(inputs):\n","  model = final_model(inputs)\n","  \n","  model.compile(optimizer='adam', \n","              loss = {'classification' : 'categorical_crossentropy',\n","                      'bounding_box' : 'mse'\n","                     },\n","              metrics = {'classification' : 'accuracy',\n","                         'bounding_box' : 'mse'\n","                        })\n","  return model\n","\n","    \n","with strategy.scope():\n","  inputs = tf.keras.layers.Input(shape=(75, 75, 1,))\n","  model = define_and_compile_model(inputs)\n","\n","# imprimir camadas do modelo\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"CuhDh8ao8VyB"},"source":["### Treinar e validar o modelo"]},{"cell_type":"markdown","metadata":{"id":"kv0BQTPsKrkt"},"source":["Treine o modelo.  \n","- Você pode escolher o número de épocas, dependendo do nível de desempenho que deseja e do tempo de que dispõe.\n","- Cada época levará apenas alguns segundos se você estiver usando a TPU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTwH_P-ZJ_xx"},"outputs":[],"source":["EPOCHS = 10 # 45\n","steps_per_epoch = 60000//BATCH_SIZE  # 60.000 itens nesse conjunto de dados\n","validation_steps = 1\n","\n","history = model.fit(training_dataset,\n","                    steps_per_epoch=steps_per_epoch, validation_data=validation_dataset, validation_steps=validation_steps, epochs=EPOCHS)\n","\n","loss, classification_loss, bounding_box_loss, classification_accuracy, bounding_box_mse = model.evaluate(validation_dataset, steps=1)\n","print(\"Validation accuracy: \", classification_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cz-b8TxU6EDj"},"outputs":[],"source":["plot_metrics(\"classification_loss\", \"Perda de Classificação\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_metrics(\"bounding_box_loss\", \"Perda de Bounding Box\")"]},{"cell_type":"markdown","metadata":{"id":"3FBn4V5-Krkt"},"source":["## Intersecção sobre união\n","\n","Calcule a métrica I-O-U para avaliar o desempenho do modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFqJxt3_VrCm"},"outputs":[],"source":["def intersection_over_union(pred_box, true_box):\n","    xmin_pred, ymin_pred, xmax_pred, ymax_pred =  np.split(pred_box, 4, axis = 1)\n","    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n","\n","    smoothing_factor = 1e-10\n","\n","    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n","    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n","    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n","    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n","\n","    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n","    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n","\n","    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n","    union_area = (pred_box_area + true_box_area) - overlap_area\n","    \n","    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)\n","\n","    return iou"]},{"cell_type":"markdown","metadata":{"id":"9jFVovcUUVs1"},"source":["### Visualizar previsões\n","O código a seguir fará previsões e visualizará a classificação e as caixas delimitadoras previstas.\n","- Os rótulos das caixas delimitadoras verdadeiras estarão em verde, e as caixas delimitadoras previstas pelo modelo estarão em vermelho.\n","- O número previsto é mostrado abaixo da imagem."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w12OId8Mz7dF"},"outputs":[],"source":["# reconhecer os dígitos de validação\n","predictions = model.predict(validation_digits, batch_size=64)\n","predicted_labels = np.argmax(predictions[0], axis=1)\n","\n","predicted_bboxes = predictions[1]\n","\n","iou = intersection_over_union(predicted_bboxes, validation_bboxes)\n","\n","iou_threshold = 0.6\n","\n","print(\"Número de previsões em que iou > limite(%s): %s\" % (iou_threshold, (iou >= iou_threshold).sum()))\n","print(\"Número de previsões em que iou < limite(%s): %s\" % (iou_threshold, (iou < iou_threshold).sum()))\n","\n","\n","display_digits_with_boxes(validation_digits, predicted_labels, validation_labels, predicted_bboxes, validation_bboxes, iou, \"Valores reais e previstos\")"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"C3_W1_Lab_3_Object_Localization.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"}},"nbformat":4,"nbformat_minor":0}
