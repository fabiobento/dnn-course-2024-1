{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/adv_cv/class_2/10%20-%20%20Laborat%C3%B3rio/C3_W2_Lab_1_Simple_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["adaptado de [Visão computacional avançada com TensorFlow](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow?specialization=tensorflow-advanced-techniques) de [Laurence Moroney](https://laurencemoroney.com/) e [Andrew Ng](https://www.coursera.org/instructor/andrewng) , [DeepLearning.AI](https://www.deeplearning.ai/)"]},{"cell_type":"markdown","metadata":{"id":"mmANPR2jhCR6"},"source":["# Detecção simples de objetos no Tensorflow\n","\n","Neste laboratório, você aprenderá a usar os modelos de detecção de objetos disponíveis no [Tensorflow Hub](https://www.tensorflow.org/hub).\n","\n","Nas seções a seguir, você vai:\n","* explorar o Tensorflow Hub para modelos de detecção de objetos\n","* carregar os modelos em seu espaço de trabalho\n","* pré-processar uma imagem para inferência \n","* executar a inferência nos modelos e inspecionar a saída"]},{"cell_type":"markdown","metadata":{"id":"8DkMLuGDhCR6"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OEoRKdmByrb0"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-26 19:42:32.606990: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-04-26 19:42:32.607350: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-26 19:42:32.609574: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-26 19:42:32.636245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from PIL import Image\n","from PIL import ImageOps\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO"]},{"cell_type":"markdown","metadata":{"id":"nb8MBgTOhCR6"},"source":["### Baixar o modelo do Tensorflow Hub\n","\n","O Tensorflow Hub é um repositório de modelos de aprendizado de máquina treinados que você pode reutilizar em seus próprios projetos. \n","- Você pode ver os domínios cobertos [aqui](https://tfhub.dev/) e suas subcategorias. \n","- Para este laboratório, você deverá examinar a subcategoria[`image-object-detection`](https://tfhub.dev/s?module-type=image-object-detection). \n","- Você pode selecionar um modelo para ver mais informações sobre ele e copiar o URL para fazer o download em seu espaço de trabalho. \n","- Utilizaremos um [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n","- Você também pode modificar a célula a seguir para escolher o outro modelo: [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"C9pCzz4uy20U"},"outputs":[],"source":["# você pode trocar as linhas comentadas aqui para escolher o outro modelo\n","\n","# Início da versão 2 do resnet\n","module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n","\n","# Em vez disso, você pode escolher a versão 2 do ssd mobilenet e comparar os resultados\n","#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""]},{"cell_type":"markdown","metadata":{"id":"W3trj5FbhCR6"},"source":["#### Carregar o modelo\n","\n","Em seguida, você carregará o modelo especificado pelo `module_handle`.\n","- Isso levará alguns minutos para carregar o modelo."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0WHkGDHfhCR6"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","2024-04-26 19:43:25.643865: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-04-26 19:43:25.646051: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["model = hub.load(module_handle)"]},{"cell_type":"markdown","metadata":{"id":"1Ey0FpHGhCR6"},"source":["#### Escolha a assinatura padrão\n","\n","Alguns modelos no hub do Tensorflow podem ser usados para diferentes tarefas.\n","\n","Portanto, a documentação de cada modelo deve mostrar qual *assinatura* usar ao executar o modelo. \n","- Se quiser ver se um modelo tem mais de uma assinatura, você pode fazer algo como `print(hub.load(module_handle).signatures.keys())`.\n","\n","Aqui os modelos que você usará têm apenas a assinatura `default`, portanto, você não precisa se preocupar com outros tipos."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"X1BU7AGthCR6"},"outputs":[{"data":{"text/plain":["KeysView(_SignatureMap({'default': <ConcreteFunction () -> Dict[['detection_class_labels', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)], ['detection_scores', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)], ['detection_boxes', TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)], ['detection_class_entities', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)], ['detection_class_names', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)]] at 0x7FCC9848FE90>}))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Dê uma olhada nas assinaturas disponíveis para esse modelo específico\n","model.signatures.keys()"]},{"cell_type":"markdown","metadata":{"id":"nfc9ax9hhCR6"},"source":["Escolha a assinatura \"padrão\" para seu detector de objetos.\n","\n","- Para modelos de detecção de objetos, sua assinatura \"padrão\" aceitará um lote de tensores de imagem e produzirá um dicionário que descreve os objetos detectados, que é o que você deseja aqui."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pzwR5zE_hCR7"},"outputs":[],"source":["detector = model.signatures['default']"]},{"cell_type":"markdown","metadata":{"id":"Wvb-3r3thCR7"},"source":["### download_and_resize_image\n","\n","Essa função faz o download de uma imagem especificada por uma determinada \"url\", pré-processa-a e, em seguida, salva-a no disco."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ucsxak_qhCR7"},"outputs":[],"source":["def download_and_resize_image(url, new_width=256, new_height=256):\n","    '''\n","    Obtém uma imagem on-line, redimensiona-a e salva-a localmente.\n","    \n","    Args:\n","        url (string) -- link para a imagem\n","        new_width (int) -- tamanho em pixels usado para redimensionar a largura da imagem\n","        new_height (int) -- tamanho em pixels usado para redimensionar o comprimento da imagem\n","        \n","    Retorna:\n","        (string) -- caminho para a imagem salva\n","    '''\n","    \n","    \n","    # cria um arquivo temporário que termina com \".jpg\"\n","    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","    \n","    # abre o URL fornecido\n","    response = urlopen(url)\n","    \n","    # lê a imagem obtida do URL\n","    image_data = response.read()\n","    \n","    # Coloca os dados da imagem no buffer de memória\n","    image_data = BytesIO(image_data)\n","    \n","    # abre a imagem\n","    pil_image = Image.open(image_data)\n","    \n","    # Redimensiona a imagem. Será cortada se a proporção for diferente.\n","    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n","    \n","    # converte para o espaço de cores RGB\n","    pil_image_rgb = pil_image.convert(\"RGB\")\n","    \n","   # salva a imagem no arquivo temporário criado anteriormente\n","    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","    \n","    print(\"Imagem baixada para %s.\" % filename)\n","    \n","    return filename"]},{"cell_type":"markdown","metadata":{"id":"r7qodEJHhCR7"},"source":["### Baixar e pré-processar uma imagem\n","\n","Agora, usando `download_and_resize_image`, você pode obter uma imagem de amostra on-line e salvá-la localmente. \n","- Forneci uma URL para você, mas fique à vontade para escolher outra imagem para passar pelo detector de objetos.\n","- Você pode usar a largura e a altura originais da imagem, mas fique à vontade para modificá-la e ver os resultados obtidos."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"xHTDalVrhCR7"},"outputs":[{"ename":"AttributeError","evalue":"module 'PIL.Image' has no attribute 'ANTIALIAS'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Faça o download da imagem e use a altura e a largura originais\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m downloaded_image_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_resize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3872\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2592\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mdownload_and_resize_image\u001b[0;34m(url, new_width, new_height)\u001b[0m\n\u001b[1;32m     28\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_data)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Redimensiona a imagem. Será cortada se a proporção for diferente.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m ImageOps\u001b[38;5;241m.\u001b[39mfit(pil_image, (new_width, new_height), \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# converte para o espaço de cores RGB\u001b[39;00m\n\u001b[1;32m     34\u001b[0m pil_image_rgb \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"]}],"source":["# Você pode escolher um URL diferente que aponte para uma imagem de sua escolha\n","image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n","\n","# Faça o download da imagem e use a altura e a largura originais\n","downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"]},{"cell_type":"markdown","metadata":{"id":"IVNXUKMIhCR7"},"source":["### run_detector\n","\n","This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n","- run_detector uses `load_image` to convert the image into a tensor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkkiQzKlhCR7"},"outputs":[],"source":["def load_img(path):\n","    '''\n","    Loads a JPEG image and converts it to a tensor.\n","    \n","    Args:\n","        path (string) -- path to a locally saved JPEG image\n","    \n","    Returns:\n","        (tensor) -- an image tensor\n","    '''\n","    \n","    # read the file\n","    img = tf.io.read_file(path)\n","    \n","    # convert to a tensor\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    \n","    return img\n","\n","\n","def run_detector(detector, path):\n","    '''\n","    Runs inference on a local file using an object detection model.\n","    \n","    Args:\n","        detector (model) -- an object detection model loaded from TF Hub\n","        path (string) -- path to an image saved locally\n","    '''\n","    \n","    # load an image tensor from a local file path\n","    img = load_img(path)\n","\n","    # add a batch dimension in front of the tensor\n","    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","    \n","    # run inference using the model\n","    result = detector(converted_img)\n","\n","    # save the results in a dictionary\n","    result = {key:value.numpy() for key,value in result.items()}\n","\n","    # print results\n","    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n","\n","    print(result[\"detection_scores\"])\n","    print(result[\"detection_class_entities\"])\n","    print(result[\"detection_boxes\"])\n"]},{"cell_type":"markdown","metadata":{"id":"DSEeJSkxhCR7"},"source":["### Run inference on the image\n","\n","You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists: \n","\n","* The detection scores of each object found (i.e. how confident the model is), \n","* The classes of each object found, \n","* The bounding boxes of each object\n","\n","You will see how to overlay this information on the original image in the next sections and in this week's assignment!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csanHvDIz4_t"},"outputs":[],"source":["# runs the object detection model and prints information about the objects found\n","run_detector(detector, downloaded_image_path)"]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"}},"nbformat":4,"nbformat_minor":0}
