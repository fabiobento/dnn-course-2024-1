{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/adv_cv/class_2/10%20-%20%20Laborat%C3%B3rio/C3_W2_Lab_1_Simple_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["adaptado de [Visão computacional avançada com TensorFlow](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow?specialization=tensorflow-advanced-techniques) de [Laurence Moroney](https://laurencemoroney.com/) e [Andrew Ng](https://www.coursera.org/instructor/andrewng) , [DeepLearning.AI](https://www.deeplearning.ai/)"]},{"cell_type":"markdown","metadata":{"id":"mmANPR2jhCR6"},"source":["# Detecção simples de objetos no Tensorflow\n","\n","Neste laboratório, você aprenderá a usar os modelos de detecção de objetos disponíveis no [Tensorflow Hub](https://www.tensorflow.org/hub).\n","\n","Nas seções a seguir, você vai:\n","* explorar o Tensorflow Hub para modelos de detecção de objetos\n","* carregar os modelos em seu espaço de trabalho\n","* pré-processar uma imagem para inferência \n","* executar a inferência nos modelos e inspecionar a saída"]},{"cell_type":"markdown","metadata":{"id":"8DkMLuGDhCR6"},"source":["## Importações"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OEoRKdmByrb0"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-29 09:49:17.637757: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-04-29 09:49:17.668609: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-29 09:49:17.817483: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-29 09:49:17.817519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-29 09:49:17.847670: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-29 09:49:17.911259: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-29 09:49:17.912146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from PIL import Image\n","from PIL import ImageOps\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO"]},{"cell_type":"markdown","metadata":{"id":"nb8MBgTOhCR6"},"source":["### Baixar o modelo do Tensorflow Hub\n","\n","O Tensorflow Hub é um repositório de modelos de aprendizado de máquina treinados que você pode reutilizar em seus próprios projetos. \n","- Você pode ver os domínios cobertos [aqui](https://www.kaggle.com/models?framework=tensorFlow2&publisher=tensorflow) e suas subcategorias. \n","- Para este laboratório, você deverá examinar a subcategoria[`image-object-detection`](https://www.kaggle.com/models?task=17074&framework=tensorFlow2&publisher=tensorflow). \n","- Você pode selecionar um modelo para ver mais informações sobre ele e copiar o URL para fazer o download em seu espaço de trabalho. \n","- Utilizaremos um [inception resnet version 2](https://www.kaggle.com/models/tensorflow/faster-rcnn-inception-resnet-v2)\n","- Você também pode modificar a célula a seguir para escolher o outro modelo: [ssd mobilenet version 2](https://www.kaggle.com/models/tensorflow/ssd-mobilenet-v2)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"C9pCzz4uy20U"},"outputs":[],"source":["# você pode trocar as linhas comentadas aqui para escolher o outro modelo\n","\n","# Início da versão 2 do resnet\n","module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n","\n","\n","# Em vez disso, você pode escolher a versão 2 do ssd mobilenet e comparar os resultados\n","#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""]},{"cell_type":"markdown","metadata":{"id":"W3trj5FbhCR6"},"source":["#### Carregar o modelo\n","\n","Em seguida, você carregará o modelo especificado pelo `module_handle`.\n","- Pode levar alguns minutos para carregar o modelo."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0WHkGDHfhCR6"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","2024-04-29 09:49:52.289082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-04-29 09:49:52.291285: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["model = hub.load(module_handle)"]},{"cell_type":"markdown","metadata":{"id":"1Ey0FpHGhCR6"},"source":["#### Escolha a assinatura padrão\n","\n","Alguns modelos no hub do Tensorflow podem ser usados para diferentes tarefas.\n","\n","Portanto, a documentação de cada modelo deve mostrar qual *assinatura* usar ao executar o modelo. \n","- Se quiser ver se um modelo tem mais de uma assinatura, você pode fazer algo como `print(hub.load(module_handle).signatures.keys())`.\n","\n","Aqui os modelos que você usará têm apenas a assinatura `default`, portanto, você não precisa se preocupar com outros tipos."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"X1BU7AGthCR6"},"outputs":[{"data":{"text/plain":["KeysView(_SignatureMap({'default': <ConcreteFunction () -> Dict[['detection_class_labels', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)], ['detection_scores', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)], ['detection_boxes', TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)], ['detection_class_entities', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)], ['detection_class_names', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)]] at 0x73EF1A79A450>}))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Dê uma olhada nas assinaturas disponíveis para esse modelo específico\n","model.signatures.keys()"]},{"cell_type":"markdown","metadata":{"id":"nfc9ax9hhCR6"},"source":["Escolha a assinatura \"padrão\" para seu detector de objetos.\n","\n","- Para modelos de detecção de objetos, sua assinatura \"padrão\" aceitará um lote de tensores de imagem e produzirá um dicionário que descreve os objetos detectados, que é o que você deseja aqui."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pzwR5zE_hCR7"},"outputs":[],"source":["detector = model.signatures['default']"]},{"cell_type":"markdown","metadata":{"id":"Wvb-3r3thCR7"},"source":["### download_and_resize_image\n","\n","Essa função faz o download de uma imagem especificada por uma determinada \"url\", pré-processa-a e, em seguida, salva-a no disco."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Ucsxak_qhCR7"},"outputs":[],"source":["def download_and_resize_image(url, new_width=256, new_height=256):\n","    '''\n","    Obtém uma imagem on-line, redimensiona-a e salva-a localmente.\n","    \n","    Args:\n","        url (string) -- link para a imagem\n","        new_width (int) -- tamanho em pixels usado para redimensionar a largura da imagem\n","        new_height (int) -- tamanho em pixels usado para redimensionar o comprimento da imagem\n","        \n","    Retorna:\n","        (string) -- caminho para a imagem salva\n","    '''\n","    \n","    \n","    # cria um arquivo temporário que termina com \".jpg\"\n","    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","    \n","    # abre o URL fornecido\n","    response = urlopen(url)\n","    \n","    # lê a imagem obtida do URL\n","    image_data = response.read()\n","    \n","    # Coloca os dados da imagem no buffer de memória\n","    image_data = BytesIO(image_data)\n","    \n","    # abre a imagem\n","    pil_image = Image.open(image_data)\n","\n","    # Redimensiona a imagem. Será cortada se a proporção for diferente.\n","    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.Resampling.LANCZOS)\n","    \n","    # converte para o espaço de cores RGB\n","    pil_image_rgb = pil_image.convert(\"RGB\")\n","    \n","   # salva a imagem no arquivo temporário criado anteriormente\n","    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","    \n","    print(\"Imagem baixada para %s.\" % filename)\n","    \n","    return filename"]},{"cell_type":"markdown","metadata":{"id":"r7qodEJHhCR7"},"source":["### Baixar e pré-processar uma imagem\n","\n","Agora, usando `download_and_resize_image`, você pode obter uma imagem de amostra on-line e salvá-la localmente. \n","- Forneci uma URL para você, mas fique à vontade para escolher outra imagem para passar pelo detector de objetos.\n","- Você pode usar a largura e a altura originais da imagem, mas fique à vontade para modificá-la e ver os resultados obtidos."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"xHTDalVrhCR7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Imagem baixada para /tmp/tmptwviu7k4.jpg.\n"]}],"source":["# Você pode escolher um URL diferente que aponte para uma imagem de sua escolha\n","image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n","\n","# Faça o download da imagem e use a altura e a largura originais\n","downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"]},{"cell_type":"markdown","metadata":{"id":"IVNXUKMIhCR7"},"source":["### run_detector\n","\n","Essa função receberá o modelo de detecção de objetos `detector` e o caminho para uma imagem de amostra e, em seguida, usará esse modelo para detectar objetos e exibir suas categorias de classe previstas e caixas de detecção.\n","- run_detector usa `load_image` para converter a imagem em um tensor."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"wkkiQzKlhCR7"},"outputs":[],"source":["def load_img(path):\n","\n","    img = tf.io.read_file(path)\n","    \n","    # convert to a tensor\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    \n","    return img\n","\n","\n","def run_detector(detector, path):\n","    '''\n","    Carrega uma imagem JPEG e a converte em um tensor.\n","    \n","    Args:\n","        path (string) -- caminho para uma imagem JPEG salva localmente\n","    \n","    Retorna:\n","        (tensor) -- um tensor de imagem\n","    '''\n","    \n","    # lê o arquivo\n","    img = load_img(path)\n","\n","    # Adicionar uma dimensão de lote na frente do tensor\n","    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","    \n","    # Executar a inferência usando o modelo\n","    result = detector(converted_img)\n","\n","   # Salvar os resultados em um dicionário\n","    result = {key:value.numpy() for key,value in result.items()}\n","\n","    # imprimir resultados\n","    print(\"Encontrados %d objetos.\" % len(result[\"detection_scores\"]))\n","\n","    print(result[\"detection_scores\"])\n","    print(result[\"detection_class_entities\"])\n","    print(result[\"detection_boxes\"])\n"]},{"cell_type":"markdown","metadata":{"id":"DSEeJSkxhCR7"},"source":["### Executar inferência na imagem\n","\n","Você pode executar seu detector chamando a função `run_detector`. Isso imprimirá o número de objetos encontrados seguido de três listas: \n","\n","* As pontuações de detecção de cada objeto encontrado (ou seja, o grau de confiança do modelo), \n","* As classes de cada objeto encontrado, \n","* As caixas delimitadoras de cada objeto\n","\n","Você verá como sobrepor essas informações à imagem original nas próximas seções e na atividade avaliativa!"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"csanHvDIz4_t"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","W0000 00:00:1714384263.948904     751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -2484 } dim { size: -2485 } dim { size: -2486 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -105 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2496 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 1310720 l3_cache_size: 20971520 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n"]},{"name":"stdout","output_type":"stream","text":["Encontrados 100 objetos.\n","[0.6544857  0.61145216 0.6042279  0.59263206 0.5921869  0.5804905\n"," 0.5514051  0.4946694  0.47515717 0.47342193 0.4399597  0.4148504\n"," 0.4062956  0.3982892  0.3976523  0.37621033 0.3727929  0.36574817\n"," 0.35260627 0.33274764 0.30428666 0.2727669  0.26864883 0.25777176\n"," 0.25290748 0.24612032 0.23403813 0.20342915 0.18229356 0.18045719\n"," 0.17571236 0.16435125 0.15849988 0.15666044 0.15470858 0.15452752\n"," 0.1492493  0.13340679 0.12948358 0.12649727 0.12044238 0.11767314\n"," 0.1135606  0.11114759 0.11100309 0.10914911 0.10604025 0.08940552\n"," 0.08598208 0.08280208 0.08104547 0.07806066 0.07760316 0.07628672\n"," 0.07546848 0.07444185 0.0742717  0.07204849 0.07177564 0.07102229\n"," 0.07032698 0.06809634 0.06304505 0.06285914 0.06270956 0.06223947\n"," 0.05882098 0.05814969 0.05795737 0.05787598 0.05462348 0.05274333\n"," 0.05133707 0.04826561 0.04708421 0.04682778 0.04495209 0.04405119\n"," 0.04360714 0.04113463 0.04109957 0.03968599 0.03934993 0.03912783\n"," 0.03879511 0.03878588 0.03739639 0.03606927 0.03367106 0.03366852\n"," 0.03260185 0.03253514 0.03201491 0.029831   0.02877991 0.0286764\n"," 0.02803961 0.02783171 0.0273437  0.02668236]\n","[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n"," b'Bicycle' b'Building' b'Window' b'Person' b'Bicycle' b'Wheel'\n"," b'Building' b'Building' b'Building' b'Person' b'Wheel' b'Window'\n"," b'Window' b'Building' b'Person' b'Van' b'Person' b'Bicycle wheel'\n"," b'Person' b'Window' b'Window' b'Building' b'Window' b'Window' b'Man'\n"," b'Person' b'Woman' b'Person' b'Clothing' b'Bicycle wheel' b'Window'\n"," b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing' b'Window'\n"," b'Bicycle' b'Land vehicle' b'House' b'House' b'Man' b'Window' b'Clothing'\n"," b'Window' b'Footwear' b'Person' b'Man' b'Man' b'House' b'Building'\n"," b'Person' b'Clothing' b'Window' b'Person' b'Man' b'Person' b'Furniture'\n"," b'Jeans' b'Person' b'Person' b'Person' b'Land vehicle' b'Window' b'House'\n"," b'Woman' b'Man' b'Window' b'Person' b'Person' b'Clothing' b'Man' b'Man'\n"," b'Window' b'Car' b'Person' b'Man' b'Chair' b'Car' b'House' b'Window'\n"," b'Tire' b'Clothing' b'Window' b'Clothing' b'Land vehicle' b'Window'\n"," b'Window' b'Man' b'Van' b'Bus' b'Clothing' b'Car']\n","[[5.12794435e-01 5.29270947e-01 6.01662338e-01 5.52094460e-01]\n"," [5.19746006e-01 6.01507127e-01 6.46124184e-01 6.34682894e-01]\n"," [5.05745947e-01 5.00440776e-01 6.01349175e-01 5.23089707e-01]\n"," [4.86308813e-01 4.12762225e-01 6.78550422e-01 4.59905624e-01]\n"," [8.15190852e-01 9.56118345e-01 8.42701733e-01 9.87144649e-01]\n"," [4.95466530e-01 9.23534274e-01 8.35634887e-01 9.99056876e-01]\n"," [1.10985823e-02 1.19120395e-02 7.39750326e-01 4.24907267e-01]\n"," [5.77825963e-01 3.66453201e-01 7.12805629e-01 4.83338177e-01]\n"," [7.74935186e-02 4.13054079e-01 5.79458833e-01 5.60309231e-01]\n"," [0.00000000e+00 1.19292580e-01 2.23897174e-01 1.83949068e-01]\n"," [5.14069736e-01 7.48097837e-01 5.91962218e-01 7.66569197e-01]\n"," [5.70777833e-01 3.61820370e-01 7.07328439e-01 4.29666817e-01]\n"," [6.32094145e-01 3.59869897e-01 7.03841686e-01 4.11815584e-01]\n"," [1.59085337e-02 6.84961617e-01 5.59388876e-01 8.11146796e-01]\n"," [0.00000000e+00 7.97109365e-01 6.73735976e-01 1.00000000e+00]\n"," [0.00000000e+00 2.17026874e-01 6.50973141e-01 4.32000875e-01]\n"," [5.00372708e-01 3.77004474e-01 6.33350432e-01 4.14514393e-01]\n"," [6.40339971e-01 4.45023417e-01 7.03034759e-01 4.83457506e-01]\n"," [1.94403972e-03 0.00000000e+00 1.39331967e-01 2.62884218e-02]\n"," [2.55186716e-03 9.66625512e-01 1.53752610e-01 1.00000000e+00]\n"," [1.41545618e-03 1.41050993e-03 7.64848173e-01 2.69351840e-01]\n"," [5.04901052e-01 3.60784888e-01 6.37663364e-01 3.85480136e-01]\n"," [4.83383805e-01 6.19484127e-01 5.62658012e-01 6.61572099e-01]\n"," [4.98201460e-01 3.64614099e-01 6.61157489e-01 4.04896408e-01]\n"," [6.31229341e-01 3.60322863e-01 7.04147041e-01 4.11499411e-01]\n"," [5.21806777e-01 5.77694893e-01 5.87613106e-01 6.00717843e-01]\n"," [2.19603732e-01 3.48738879e-01 3.38255525e-01 3.77067655e-01]\n"," [1.24826737e-01 2.50923932e-01 2.79914767e-01 2.81625867e-01]\n"," [2.57318467e-01 5.67493618e-01 5.30910015e-01 6.87876582e-01]\n"," [4.21753637e-02 8.74765277e-01 2.52863377e-01 9.13046181e-01]\n"," [1.56401619e-01 4.43365514e-01 2.22233847e-01 4.75784540e-01]\n"," [5.01994431e-01 9.21467483e-01 8.36361706e-01 1.00000000e+00]\n"," [5.23673594e-01 5.70347011e-01 5.84506094e-01 5.91607034e-01]\n"," [5.19169092e-01 5.99965990e-01 6.46330178e-01 6.34094715e-01]\n"," [5.13154805e-01 6.79228544e-01 5.50981283e-01 6.92548096e-01]\n"," [5.24344563e-01 9.24945474e-01 8.10528219e-01 9.97979462e-01]\n"," [6.38063252e-01 4.42797333e-01 7.01729059e-01 4.84131962e-01]\n"," [3.41055244e-02 3.55657607e-01 1.62304893e-01 3.74908745e-01]\n"," [4.88090217e-01 4.53366905e-01 6.22257113e-01 4.79664892e-01]\n"," [9.66507592e-04 3.07707369e-01 1.06515862e-01 3.32070321e-01]\n"," [4.82970089e-01 6.19791687e-01 5.64778984e-01 6.60652637e-01]\n"," [5.82391143e-01 3.64923388e-01 7.13891625e-01 4.84685332e-01]\n"," [5.23790002e-01 7.49292731e-01 5.85470319e-01 7.65311480e-01]\n"," [3.51464242e-01 9.74868834e-01 5.53043723e-01 9.98887122e-01]\n"," [6.09076917e-01 4.26833510e-01 7.05196321e-01 4.87107515e-01]\n"," [5.69254696e-01 3.59783024e-01 7.08566308e-01 4.28438723e-01]\n"," [0.00000000e+00 8.11187208e-01 6.93582773e-01 9.93253589e-01]\n"," [1.04295602e-02 2.29470227e-02 7.27312446e-01 4.22287554e-01]\n"," [4.84632283e-01 4.10697758e-01 6.94742858e-01 4.63139951e-01]\n"," [8.11544582e-02 3.84775937e-01 2.07952142e-01 4.11755383e-01]\n"," [5.38567245e-01 6.03585005e-01 6.34740889e-01 6.34476542e-01]\n"," [0.00000000e+00 1.24075906e-02 1.40296489e-01 2.47341208e-02]\n"," [6.29779994e-01 6.14883423e-01 6.44907951e-01 6.25335038e-01]\n"," [5.02842903e-01 3.82420689e-01 5.96016288e-01 4.12718713e-01]\n"," [5.14681399e-01 7.47871041e-01 5.91947734e-01 7.66782522e-01]\n"," [5.06433249e-01 5.00402689e-01 6.00716949e-01 5.23319721e-01]\n"," [0.00000000e+00 2.11128622e-01 6.50825918e-01 4.34384257e-01]\n"," [0.00000000e+00 7.06320822e-01 6.17161632e-01 8.65940571e-01]\n"," [4.89298165e-01 4.54274893e-01 5.72620332e-01 4.76397544e-01]\n"," [5.09207368e-01 4.16264892e-01 6.69016659e-01 4.59577173e-01]\n"," [4.67803981e-03 8.03107023e-01 1.59582227e-01 8.40365171e-01]\n"," [5.26175678e-01 5.68375826e-01 5.79436243e-01 5.82803011e-01]\n"," [5.02847552e-01 3.73985887e-01 6.47126019e-01 4.12972569e-01]\n"," [4.85917509e-01 4.44437206e-01 6.24690235e-01 4.73519862e-01]\n"," [5.74168622e-01 2.67251372e-01 6.57761574e-01 3.20314020e-01]\n"," [6.71982288e-01 9.40317750e-01 8.21177125e-01 9.89214003e-01]\n"," [5.24104714e-01 5.61555982e-01 5.78347087e-01 5.80502510e-01]\n"," [5.17589748e-01 7.57220685e-01 5.88313937e-01 7.71545827e-01]\n"," [5.23328543e-01 5.57813823e-01 5.79028904e-01 5.73553503e-01]\n"," [6.12360060e-01 4.27401572e-01 7.06096232e-01 4.88300264e-01]\n"," [0.00000000e+00 2.44237080e-01 6.08887747e-02 2.93773860e-01]\n"," [1.54843908e-02 1.94189383e-03 7.45163262e-01 2.59336442e-01]\n"," [4.93266404e-01 9.23959553e-01 8.36913168e-01 9.97706771e-01]\n"," [5.05292952e-01 3.60166430e-01 6.43362343e-01 3.91438514e-01]\n"," [8.43422953e-03 2.42121428e-01 4.97449487e-02 2.83145577e-01]\n"," [5.22109210e-01 5.36088109e-01 5.97674787e-01 5.53133130e-01]\n"," [5.13126016e-01 5.23810089e-01 6.00540400e-01 5.42965055e-01]\n"," [5.18315673e-01 5.03453434e-01 5.97545326e-01 5.22752881e-01]\n"," [5.20455718e-01 6.00931644e-01 6.45991087e-01 6.34363830e-01]\n"," [5.13168335e-01 6.79253876e-01 5.50486147e-01 6.92442954e-01]\n"," [4.29723203e-01 8.28743577e-01 5.90048730e-01 8.64375412e-01]\n"," [5.26593328e-01 6.27190769e-01 5.63289881e-01 6.53785050e-01]\n"," [5.04781127e-01 3.89410645e-01 6.15231395e-01 4.19951588e-01]\n"," [5.01325011e-01 3.64236265e-01 6.59752846e-01 4.03719962e-01]\n"," [5.73110282e-01 2.66732723e-01 6.66223586e-01 3.18649948e-01]\n"," [5.15103340e-01 6.24091804e-01 5.63832283e-01 6.58031821e-01]\n"," [8.32031295e-02 4.07568008e-01 5.84344029e-01 5.58310509e-01]\n"," [2.88201898e-01 4.62542695e-04 4.14279878e-01 3.67076769e-02]\n"," [6.27132773e-01 3.60995114e-01 7.05960691e-01 4.09780383e-01]\n"," [4.97159481e-01 4.55211073e-01 5.84271312e-01 4.77872074e-01]\n"," [1.17194150e-02 3.08072537e-01 9.73200500e-02 3.25075477e-01]\n"," [5.15893996e-01 3.80090386e-01 5.96972346e-01 4.11767155e-01]\n"," [5.12429059e-01 6.23649299e-01 5.62436581e-01 6.57682240e-01]\n"," [4.00773793e-01 8.84974301e-01 5.81656516e-01 9.39130187e-01]\n"," [0.00000000e+00 9.94759426e-03 1.36253998e-01 3.15974467e-02]\n"," [5.13905644e-01 5.29502392e-01 6.02055967e-01 5.52376091e-01]\n"," [5.10691524e-01 6.24039650e-01 5.63410044e-01 6.58179879e-01]\n"," [4.80379969e-01 6.20327830e-01 5.65284133e-01 6.60123467e-01]\n"," [5.38407385e-01 9.28024292e-01 7.13617265e-01 9.99452710e-01]\n"," [4.86337841e-01 6.20247364e-01 5.63528717e-01 6.60217762e-01]]\n"]}],"source":["# Executa o modelo de detecção de objetos e imprime informações sobre os objetos encontrados\n","run_detector(detector, downloaded_image_path)"]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
