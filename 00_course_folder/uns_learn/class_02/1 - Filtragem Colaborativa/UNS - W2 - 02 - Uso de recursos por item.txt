Então, vamos dar uma olhada em como podemos desenvolver um sistema recomendado se tivéssemos características de cada item ou características de cada filme. Então, aqui está o mesmo conjunto de dados que tínhamos anteriormente, com os quatro usuários avaliando alguns, mas não todos os cinco filmes. E se, além disso, tivermos características dos filmes? Então, aqui eu adicionei dois recursos X1 e X2, que nos dizem o quanto cada um deles é um filme de romance e o quanto cada um deles é um filme de ação. Então, por exemplo, Love at Last é um filme muito romântico, então esse filme assume 0,9, mas não é um filme de ação. Portanto, esse recurso assume 0. Mas acontece que as perseguições de carros sem parar contêm um pouco de romance. Então é 0,1, mas tem muita ação. Portanto, esse recurso assume o valor de 1,0. Então você lembra que eu usei a notação nu para indicar o número de usuários, que é 4 e m para indicar o número de filmes, que é 5. Também vou introduzir n para indicar o número de recursos que temos aqui. E então n = 2, porque temos dois recursos X1 e X2 para cada filme. Com esses recursos, temos, por exemplo, que os recursos do primeiro filme, ou seja, o filme Love at Last, seriam 0,90. E as características do terceiro filme Cute Puppies of Love seriam 0,99 e 0. E vamos começar dando uma olhada em como podemos fazer previsões sobre a audiência de filmes de Alice. Então, para o usuário um, que é Alice, digamos que predizemos a classificação do filme i como W.x (i) +b. Então, isso é muito parecido com regressão linear. Por exemplo, se acabarmos escolhendo o parâmetro w (1) = [5,0] e digamos b (1) =0, então a previsão para o terceiro filme em que os recursos são 0,99 e 0, que é apenas copiada daqui, primeiro recurso 0,99, segundo recurso 0. Nossa previsão seria W.x (3) +b=0,99 vezes 5 mais 0 vezes zero, o que acaba sendo igual a 4,95. E essa classificação parece bastante plausível. Parece que Alice deu altas classificações a Love at Last e Romance Forever, a dois filmes altamente românticos, mas deu baixa audiência aos filmes de ação, Nonstop Car Chases e Swords vs Karate. Então, se olharmos para Cute Puppies of Love, predizer que ela poderia avaliar isso em 4,95 parece bastante plausível. Portanto, esses parâmetros w e b para Alice parecem um modelo razoável para prever a audiência de seus filmes. Basta adicionar um pouco da notação porque não temos apenas um usuário, mas vários usuários, ou na verdade, nu é igual a 4 usuários. Vou adicionar um sobrescrito 1 aqui para indicar que esse é o parâmetro w (1) para o usuário 1 e adicionar uma superfaixa 1 lá também. E da mesma forma, aqui e aqui, para que na verdade tivéssemos parâmetros diferentes para cada um dos 4 usuários no conjunto de dados. E, de forma mais geral, neste modelo , podemos prever a classificação do usuário j para o filme i como w (j) .X (i) +b (j) .X (i) +b (j). Então, aqui, os parâmetros w (j) e b (j) são os parâmetros usados para prever a classificação do usuário j para o filme i, que é uma função de X (i), que são as características do filme i. E isso é muito parecido com a regressão linear, exceto que estamos ajustando um modelo de regressão linear diferente para cada um dos 4 usuários no conjunto de dados. Então, vamos dar uma olhada em como podemos formular a função de custo para esse algoritmo. Como lembrete de notação, r (i., j) =1 se o usuário j classificou o filme i ou 0 caso contrário. E y (i, j) = classificação dada pelo usuário j no filme i. E no lado anterior definimos w (j), b (j) como os parâmetros para o usuário j. E X (i) como o vetor de características do filme i. Então, o modelo que temos é para o usuário j e o filme i prevêem que a classificação seja w (j) .X (i) +b (j). Vou apresentar apenas uma nova notação, que é usar m (j) para indicar o número de filmes classificados pelo usuário j. Então, se o usuário classificou 4 filmes, então m (j) seria igual a 4. E se o usuário classificou 3 filmes, m (j) seria igual a 3. Então, o que gostaríamos de fazer é aprender os parâmetros w (j) e b (j), dados os dados que temos. Isso é dado pelas avaliações que um usuário deu a um conjunto de filmes. Portanto, a média que vamos usar é muito semelhante à regressão linear. Então, vamos escrever a função de custo para aprender os parâmetros w (j) e b (j) para um determinado usuário j. E vamos focar apenas em um usuário no usuário j por enquanto. Vou usar os critérios de erro quadrático médio. Portanto, o custo será a previsão, que é w (j) .X (i) +b (j) menos a classificação real que o usuário deu. Então, menos y (i, j) ao quadrado. E estamos tentando escolher os parâmetros w e b para minimizar o erro quadrado entre a classificação prevista e a classificação real que foi observada. Mas o usuário não avaliou todos os filmes, então, se formos somar isso, somaremos apenas os valores de i, onde r (i, j) =1. Então, vamos somar apenas os filmes i que o usuário j realmente avaliou. Então é isso que isso denota, soma de todos os valores de i onde r (i, j) =1. Isso significa que o usuário j classificou o filme i. E, finalmente, podemos usar a normalização usual 1 sobre m (j). E isso é muito parecido com a função de custo que temos para regressão linear com exemplos de treinamento m ou realmente m (j). Onde você está somando os filmes m (j) para os quais você tem uma classificação, tomando um erro quadrado e normalizando por esse 1 sobre 2m (j). E isso vai ser uma função de custo J de w (j), b (j). E se minimizarmos isso como uma função de w (j) e b (j), então você deve encontrar uma boa escolha de parâmetros w (i) e b (j). Para fazer previsões para as avaliações do usuário j. Deixe-me ter apenas mais um termo para essa função de custo, que é o termo de regularização para evitar sobreajuste. Então, aqui está nosso parâmetro de regularização usual, lambda dividido por 2m (j) e depois multiplicado pela soma dos valores quadrados dos parâmetros w. Então n é um número de números em X (i) e isso é o mesmo que um número de números em w (j). Se você minimizasse essa função de custo J em função de w e b, você deveria obter um bom conjunto de parâmetros para prever as avaliações do usuário j para outros filmes. Agora, antes de prosseguir, verifica-se que, para sistemas recomendados, seria conveniente realmente eliminar essa divisão pelo termo m (j), m (j) é apenas uma constante nessa expressão. Então, mesmo se você retirá-la, você deve acabar com o mesmo valor de w e b. Agora, deixe-me pegar essa função de custo até o final e copiá-la para o próximo slide. Portanto, temos isso para aprender os parâmetros w (j), b (j) para o usuário j. Minimizaríamos essa função de custo em função de w (j) e b (j). Mas, em vez de focar em um único usuário, vamos ver como aprendemos os parâmetros para todos os usuários. Para aprender os parâmetros w (1), b (1), w (2), b (2),... , w (nu), b (nu), tomaríamos essa função de custo em cima e a somaríamos a todos os usuários do nu. Portanto, teríamos a soma de j=1 um a nu da mesma função de custo que escrevemos acima. E isso se torna o custo de aprender todos os parâmetros para todos os usuários. E se usarmos gradiente descendente ou qualquer outro algoritmo de otimização para minimizar isso em função de w (1), b (1) até w (nu), b (nu), então você tem um bom conjunto de parâmetros para prever as classificações de filmes para todos os usuários. E você pode notar que esse algoritmo é muito parecido com a regressão linear, onde ela desempenha um papel semelhante à saída f (x) da regressão linear. Só que agora estamos treinando um modelo de regressão linear diferente para cada um dos usuários do nu. Então é assim que você pode aprender parâmetros e prever classificações de filmes, se tiver acesso a esses recursos X1 e X2. Isso mostra quanto custa cada um dos filmes, um filme de romance, e quanto cada um dos filmes é um filme de ação? Mas de onde vêm esses recursos? E se você não tiver acesso a esses recursos que fornecem detalhes suficientes sobre os filmes para fazer essas previsões? No próximo vídeo, veremos a modificação desse algoritmo. Eles permitem que você faça previsões e faça recomendações. Mesmo que você não tenha recursos avançados que descrevam os itens dos filmes com detalhes suficientes para executar o algoritmo que acabamos de ver. Vamos dar uma olhada nisso no próximo vídeo
Obrigatória
pt-BR
​

