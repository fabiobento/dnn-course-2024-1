Neste vídeo, veremos como você pode usar o TensorFlow para implementar o algoritmo de filtragem colaborativa. Você pode estar acostumado a pensar no TensorFlow como uma ferramenta para criar redes neurais. E é. É uma ótima ferramenta para construir redes neurais. E acontece que o TensorFlow também pode ser muito promissor para criar outros tipos de algoritmos de aprendizado. Como o algoritmo de filtragem colaborativa. Uma das razões pelas quais eu gosto de usar o TensorFlow para palestras como essas é que, para muitos aplicativos, para implementar o gradiente descendente, você precisa encontrar os derivados da função de custo, mas o TensorFlow pode descobrir automaticamente quais são os derivados da função de custo. Tudo o que você precisa fazer é implementar a função de custo e, sem precisar conhecer nenhum cálculo, sem precisar usar derivadas sozinho, você pode obter o TensorFlow com apenas algumas linhas de código para calcular esse termo derivado, que pode ser usado para otimizar a função de custo. Vamos dar uma olhada em como tudo isso funciona. Você deve se lembrar desse diagrama aqui à direita do primeiro curso. Esse é exatamente o diagrama que examinamos quando falamos sobre a otimização de w. Quando estávamos trabalhando em nosso primeiro exemplo de regressão linear. E naquela época tínhamos definido b=0. Então, o modelo estava apenas prevendo f (x) =w.x. E queríamos encontrar o valor de w que minimizasse a função de custo J. Então, a maneira como estávamos fazendo isso era por meio de uma atualização de gradiente descendente, parecida com esta, em que w é atualizado repetidamente como w menos a taxa de aprendizado alfa vezes o termo derivado. Se você também estiver atualizando b, essa é a expressão que você usará. Mas se você disse b=0, você simplesmente renuncia à segunda atualização e continua realizando essa atualização de gradiente descendente até a convergência. Às vezes, calcular esse termo derivado ou derivado parcial pode ser difícil. E acontece que o TensorFlow pode ajudar com isso. Vamos ver como. Vou usar uma função de custo muito simples J =( wx-1) ao quadrado. Então wx é nosso f w simplificado de x e y é igual a 1.
Reproduza o vídeo começando em :2:35 e siga a transcrição2:35
Então essa seria a função de custo se tivéssemos f (x) igual a wx, y igual a 1 para o único exemplo de treinamento que temos, e se não estivéssemos otimizando isso em relação a b. Então, o algoritmo de gradiente descendente se repetirá até a convergência desta atualização aqui. Acontece que, se você implementar a função de custo J aqui, o TensorFlow pode calcular automaticamente para você esse termo derivado e, assim, fazer com que o gradiente descendente funcione. Vou te dar uma visão geral de alto nível do que esse código faz, w=tf.variable (3.0). Pega o parâmetro w e o inicializa com o valor de 3,0. Dizer ao TensorFlow que w é uma variável é como dizemos que w é um parâmetro que queremos otimizar. Vou definir x = 1,0, y = 1,0 e a taxa de aprendizado alfa como igual a 0,01. E vamos executar a dissidência de gradiente por 30 iterações. Portanto, neste código ainda funcionará para iterações de intervalo, ou seja, para 30 iterações.
Reproduza o vídeo começando em :3:45 e siga a transcrição3:45
E essa é a sintaxe para fazer com que o TensorFlow calcule automaticamente os rotores para você. O TensorFlow tem um recurso chamado fita gradiente. E se você escrever isso com tf, nossa fita gradiente como fita f. Isso é computar f (x) como w*x e computar J como f (x) -y ao quadrado. Em seguida, informando ao TensorFlow como calcular para CostJ e fazendo isso com a sintaxe gravada em gradiente da seguinte forma, o TensorFlow registrará automaticamente a sequência de etapas. A sequência de operações necessárias para calcular o CostJ. E isso é necessário para permitir a diferenciação automática. Em seguida, o TensorFlow salvará a sequência de operações em fita, na fita gradiente. E com essa sintaxe, o TensorFlow computará automaticamente esse termo derivado, que chamarei de djDW.
Reproduza o vídeo começando em :4:47 e siga a transcrição4:47
E o TensorFlow sabe que você quer usar a derivada respeitada w. Que w é o parâmetro que você deseja otimizar porque você disse isso aqui. E porque também estamos especificando isso aqui embaixo. Agora, os derivados do computador, finalmente, você pode realizar essa atualização pegando w e subtraindo dela a taxa de aprendizado alfa vezes o termo derivado que acabamos de obter de cima. Variáveis do TensorFlow, variáveis de nível, requerem tratamento especial. É por isso que, em vez de definir w como w menos alfa vezes a derivada da maneira usual, usamos essa função de adição atribuída. Mas quando você chegar ao laboratório prático, não se preocupe com isso. Forneceremos toda a sintaxe necessária para implementar o algoritmo de filtragem colateral corretamente. Portanto, observe que, com o recurso de fita gradiente do TensorFlow, o principal trabalho que você precisa fazer é dizer a ele como calcular a função de custo J. E o resto da sintaxe faz com que o TensorFlow descubra automaticamente para você qual é essa derivada? E com esse TensorFlow, começaremos encontrando a inclinação disso, em 3 mostrada por essa linha tracejada. Faça uma etapa de gradiente e atualize w e calcule a derivada novamente e atualize w repetidamente até que finalmente chegue ao valor ideal de w, que está em w igual a 1. Portanto, esse procedimento permite que você implemente o gradiente descendente sem nunca ter que descobrir como calcular esse termo derivado. Esse é um recurso muito poderoso do TensorFlow chamado Auto Diff. E alguns outros pacotes de aprendizado de máquina, como o pytorch, também oferecem suporte ao Auto Diff. Às vezes você ouve as pessoas chamarem isso de Auto Grad. O termo tecnicamente correto é Auto Diff, e Auto Grad é na verdade o nome do pacote de software específico para fazer a diferenciação automática, para obter derivadas automaticamente. Mas às vezes, se você ouvir alguém se referir ao Auto Grad, essa pessoa está apenas se referindo ao mesmo conceito de obter derivativos automaticamente. Então, vamos ver como você pode implementar o algoritmo de filtragem colaborativa usando o Auto Diff. E, de fato, uma vez que você pode calcular derivadas automaticamente, você não está limitado apenas à descida do gradiente. Você também pode usar um algoritmo de otimização mais poderoso, como o algoritmo de otimização adam. Para implementar o algoritmo de filtragem colaborativa TensorFlow, essa é a sintaxe que você pode usar. Vamos começar especificando que o otimizador é keras optimizers adam com a taxa de aprendizado especificada aqui. E então, por exemplo, 200 iterações, aqui está a sintaxe de antes: com tf gradient tape, s tape, você precisa fornecer código para calcular o valor da função de custo J. Então, lembre-se de que, na filtragem colaborativa, a função de custo J usa são os parâmetros de entrada x, w e b, bem como a média de classificação normalizada. É por isso que estou escrevendo a norma y, r (i, j) especificando quais valores têm uma classificação, número de usuários ou nu em nossa notação, número de filmes ou nm em nossa notação ou apenas num, bem como o parâmetro de regularização lambda. E se você puder implementar essa função de custo J, essa sintaxe fará com que o TensorFlow descubra os derivados para você. Então, essa sintaxe fará com que o TensorFlow registre a sequência de operações usada para calcular o custo.
Reproduza o vídeo começando em :8:29 e siga a transcrição8:29
E então, ao pedir que ele forneça notas iguais a tape.gradient, isso lhe dará a derivada da função de custo em relação a x, w e b. E, finalmente, com o otimizador que especificamos na parte superior, como o otimizador adam. Você pode usar o otimizador com os gradientes que acabamos de calcular. E sua função em python é apenas uma função que reorganiza os números em uma ordem apropriada para a função de gradientes aplicada.
Reproduza o vídeo começando em :9: e siga a transcrição9:00
Se você estiver usando gradiente descendente para filtragem colateral, lembre-se de que a função de custo J seria uma função de w, b e também de x. E se você estiver aplicando gradiente descendente, considere a derivada parcial em relação ao w. E, em seguida, atualize w da seguinte forma. E você também tomaria a derivada parcial desse respeito para b. E atualizaria b da seguinte forma. E, da mesma forma, atualize os recursos x da seguinte forma. E você repete até a convergência. Mas, como mencionei anteriormente, com o TensorFlow e o Auto Diff, você não está limitado apenas à descida do gradiente. Você também pode usar um algoritmo de otimização mais poderoso, como o otimizador adam. O conjunto de dados que você usa no laboratório prático é um conjunto de dados real composto por filmes reais avaliados por pessoas reais. Este é o conjunto de dados da lente do filme e é devido a Harper e Konstan. E espero que você goste de executar esse algoritmo em um conjunto de dados reais de filmes e classificações e veja por si mesmo os resultados que esse algoritmo pode obter. Então é isso.
Reproduza o vídeo começando em :10:3 e siga a transcrição10:03
É assim que você pode implementar o algoritmo de filtragem colaborativa no TensorFlow. Se você está se perguntando por que temos que fazer isso dessa maneira? Por que não poderíamos usar uma camada densa e, em seguida, o compilador de modelos e o ajuste do modelo? O motivo pelo qual não pudemos usar essa receita antiga é que o algoritmo de filtragem colateral e a função de custo não se encaixam perfeitamente na camada densa ou em outros tipos de camada de rede neural padrão do TensorFlow. É por isso que tivemos que implementá-lo de outra forma, onde nós mesmos implementaríamos a função de custo. Mas então use as ferramentas do TensorFlow para diferenciação automática, também chamadas de Auto Diff. E use a implementação do algoritmo de otimização adam pelo TensorFlow para permitir que ele faça grande parte do trabalho para nós de otimizar a função de custo. Se o modelo que você tem é uma sequência de camadas densas de rede neural ou outros tipos de camadas suportadas pelo TensorFlow, e a antiga receita de implementação do modelo composto, o ajuste do modelo funciona. Mas mesmo quando não estão, essas ferramentas TensoFlow também oferecem uma maneira muito eficaz de implementar outros algoritmos de aprendizado. Então, espero que você goste de jogar mais com o exercício de filtragem colateral no laboratório prático desta semana. E parece que há muito código e muita sintaxe, não se preocupe com isso. Verifique se você tem o que precisa para concluir esse exercício com sucesso. E no próximo vídeo, eu também gostaria de discutir mais sobre as nuances da filtragem colateral e, especificamente, a questão de como você encontra itens relacionados, dado um filme, ou outros filmes semelhantes a este. Vamos para o próximo vídeo
