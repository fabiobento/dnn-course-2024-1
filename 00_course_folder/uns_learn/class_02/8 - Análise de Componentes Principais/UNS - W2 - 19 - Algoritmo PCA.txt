Como funciona o PCA? Se você tiver um conjunto de dados com dois recursos, x_1 e x_2. Inicialmente, seus dados são plotados ou representados usando os eixos x_1 e x_2. Mas você quer substituir esses dois recursos por apenas um recurso. Como você pode escolher um novo eixo, vamos chamá-lo de eixo z, que é de alguma forma um bom recurso para capturar e representar os dados? Vamos dar uma olhada em como o PCA faz isso. Aqui estão os conjuntos de dados com cinco exemplos de treinamento.
Reproduza o vídeo começando em ::42 e siga a transcrição0:42
Lembre-se de que este é um algoritmo de aprendizado não supervisionado, então temos apenas x_1 e x_2, não há rótulo y. Um exemplo aqui como esse pode ter coordenadas x_1 igual a 10 e x_2 igual a 8. Se não quisermos usar os eixos x_1, x_2, como podemos escolher algum eixo diferente com o qual capturar o que está nos dados ou com o qual representar os dados? Uma observação sobre o pré-processamento: antes de aplicar as próximas etapas do PCA, os recursos devem primeiro ser normalizados para ter média zero e eu já fiz isso aqui.
Reproduza o vídeo começando em :1:33 e siga a transcrição1:33
Se as características x_1 e x_2 assumirem escalas muito diferentes, por exemplo, se você se lembrar do nosso exemplo de habitação, se x_1 fosse o tamanho de uma casa em pés quadrados e x_2 fosse o número de quartos, então x_1 poderia ser 1.000 ou alguns milhares, enquanto x_2 é um número pequeno. Se os recursos assumirem escalas muito diferentes , você primeiro executará o escalonamento de recursos antes de aplicar as próximas etapas do PCA. Supondo que os recursos tenham sido normalizados para ter média zero, subtraia a média de cada recurso e, em seguida, talvez aplique também a escala do recurso para que os intervalos não fiquem muito distantes. O que o PCA faz a seguir? Para examinar o que o PCA faz, deixe-me remover os eixos x_1 e x_2 para que fiquemos com os cinco exemplos de treinamento. Este ponto aqui representa a origem. A posição zero neste gráfico ainda. O que temos que fazer agora com o PCA é escolher um eixo em vez dos dois eixos que tínhamos anteriormente para capturar o que é importante nesses cinco exemplos. Se escolhermos esse eixo como nosso novo eixo z, na verdade ele é o mesmo que o eixo x_1, apenas neste exemplo. Então, o que estamos dizendo é que, para este exemplo, vamos apenas capturar esse valor, essa coordenada no eixo z. Para o segundo exemplo, vamos capturar esse valor e, em seguida, ele capturará esse valor e assim por diante em todos os cinco exemplos. Outra forma de dizer isso é pegar cada um desses exemplos e projetá-lo até um ponto no eixo z. A palavra projeto se refere ao fato de você pegar esse exemplo e trazê-lo para o eixo z usando esse segmento de linha que está em um ângulo de 90 graus em relação ao eixo z. Essa pequena caixa aqui é usada para indicar que esse segmento de linha está a 90 graus em relação ao eixo z. O termo projeto significa apenas que você está pegando um ponto e encontrando esse ponto correspondente no eixo z usando esse segmento de linha que está a 90 graus. Escolher essa direção como eixo z não é uma escolha ruim, mas há algumas opções ainda melhores. Essa escolha não é tão ruim porque quando você projeta seus exemplos no eixo z, você ainda captura grande parte da distribuição dos dados. Esses cinco pontos aqui estão bem separados, então você ainda está capturando grande parte da variação ou grande parte da variação no conjunto de dados original. Com isso, quero dizer que esses cinco pontos estão bastante separados e, portanto, a variância ou variação entre esses cinco pontos, as projeções dos dados no eixo z, são decentemente grandes. O que isso significa é que ainda estamos capturando muitas das informações nos cinco exemplos originais. Vamos ver algumas outras opções possíveis para o eixo z. Aqui está outra opção. Na verdade, essa não é uma boa escolha. Mas se eu escolhesse isso como meu eixo z , se eu pegar esses mesmos cinco exemplos e projetá-los até o eixo z, acabaria com esses cinco pontos. Você percebe que, em comparação com a escolha anterior, esses cinco pontos estão bem agrupados. A quantidade em que eles diferem um do outro, ou sua variância ou variação é muito menor. O que isso significa é que, com essa opção de z, você está capturando muito menos informações no conjunto de dados original porque juntou parcialmente todos os cinco exemplos. Vejamos uma última opção, que é se eu escolher esse como o eixo z. Na verdade, essa é uma escolha melhor do que as duas anteriores que vimos, porque se colocarmos as projeções dos dados no eixo z, descobrimos que esses pontos aqui estão, na verdade, bem distantes um do outro. Estamos capturando grande parte da variação, muitas informações no conjunto de dados original, embora agora estejamos usando apenas uma coordenada ou um número para representar ou capturar cada um dos exemplos de treinamento em vez de dois números ou duas coordenadas, X_1 e X_2. No algoritmo PCA, esse eixo é chamado de componente principal. No eixo z, quando você projeta os dados nele, você acaba com a maior quantidade possível de variação. Se você fosse reduzir os dados a um eixo ou a um recurso, esse componente principal é, na verdade, uma boa escolha, e é isso que o PCA fará. Se você quiser reduzir os dados para um recurso unidimensional , ele escolherá esse componente principal. Deixe-me mostrar uma visualização de como as diferentes escolhas do eixo afetam a projeção. Aqui temos 10 exemplos de treinamento e, ao deslizar esse controle deslizante aqui, você mesmo pode jogar com ele em um dos laboratórios opcionais. Quando você desliza o controle deslizante aqui, o ângulo do eixo z muda. O que você está vendo à esquerda é cada um dos exemplos projetados por meio desse segmento de linha curta a 90 graus em relação ao eixo z. Aqui à direita está a projeção dos dados, ou seja, o valor desses 10 exemplos, coordenada z. Você percebe que quando eu coloco o eixo mais ou menos aqui, os pontos ficam bem comprimidos. Portanto, isso representa menos automação dos dados originais. Por outro lado, se eu definir o eixo z, digamos assim, esses pontos variam muito mais. Isso está capturando muito mais informações no conjunto de dados original. É por isso que o componente principal corresponde à configuração do eixo z em aproximadamente aqui. Essa é a escolha que o PCA faria se você pedisse que reduzisse os dados a uma dimensão. Uma biblioteca de aprendizado de máquina, como o scikit-learn, sobre a qual você ouvirá mais no próximo vídeo, pode ajudá-lo a encontrar automaticamente o componente principal. Mas vamos nos aprofundar um pouco mais em como isso funciona. Aqui estão meus eixos x_1 e x_2. Aqui está um exemplo de treinamento com coordenadas 2 no eixo x_1 e três no eixo x_2. Digamos que o PCA tenha encontrado essa direção para o eixo z. O que estou desenhando aqui, essa pequena seta é um vetor de comprimento 1 apontando na direção desse eixo z que o PCA escolherá ou que escolhemos. Acontece que esse vetor de comprimento 1 é o vetor 0,710, 0,71 arredondado um pouco. Na verdade, é 0,707 e depois vários outros dígitos. Dado esse exemplo com coordenadas 2,3 no eixo x_1, x_2, como projetamos esse exemplo no eixo z? Acontece que a fórmula para fazer isso é pegar um produto pontual entre o vetor 2,3 e esse vetor 0,71, 0,71. Se você fizer isso, o produto de 2,3 pontos com 0,71, 0,71 será 2 vezes 0,71 mais 3 vezes 0,71, o que é igual a 3,55. O que isso significa é que a distância da origem desse ponto aqui é 3,55, o que significa que se representássemos ou usássemos um número para tentar capturar esse exemplo, esse número seria 3,55. Até agora, falamos sobre como usar o PCA para reduzir os dados para uma dimensão ou para um número. Fizemos isso encontrando o componente principal, também chamado às vezes de primeiro componente principal. Neste exemplo, descobrimos que esse é o primeiro eixo. Acontece que, se você escolher um segundo eixo, o segundo eixo estará sempre a 90 graus em relação ao primeiro eixo. Se você escolher até mesmo um terceiro eixo , o terceiro eixo estará a 90 graus em relação ao primeiro e ao segundo eixo. A propósito, em matemática, 90 graus às vezes são chamados de perpendiculares. O termo perpendicular significa apenas 90 graus. Os matemáticos às vezes dizem que o segundo eixo, z_2, está a 90 graus ou é perpendicular ao primeiro eixo, z_1. Se você escolher eixos adicionais, eles também estarão em 90 graus ou perpendiculares a z_1 e z_2 e a qualquer outro eixo que o PCA escolher. Se você tivesse 50 características e quisesse encontrar três componentes principais, se esse for o primeiro eixo, o segundo eixo estará a 90 graus em relação a ele. Então, o terceiro eixo também estará a 90 graus em relação ao primeiro e ao segundo eixo. Agora, uma pergunta que sempre me fazem é: como o PCA é diferente da regressão linear? Acontece que o PCA não é uma regressão linear, é um algoritmo totalmente diferente. Deixe-me explicar o porquê. Com a regressão linear, que é um algoritmo de aprendizado supervisionado, você tem dados x e y. Aqui está um conjunto de dados em que o eixo horizontal é a característica x e o eixo vertical aqui é o rótulo y. Com a regressão linear, você está tentando ajustar uma linha reta para que o valor previsto seja o mais próximo possível do rótulo verdadeiro y. Em outras palavras, você está tentando minimizar o comprimento desses pequenos segmentos de linha que estão na direção vertical. Eles apenas se alinharam com o eixo y. Em contraste, no PCA, não existe um rótulo de verdade fundamental y. Você só tem dados não rotulados, X1 e X2 e, além disso, não está tentando ajustar uma linha para usar X1 para prever X2. Em vez disso, a média trata X1 e X2 igualmente. Estamos tentando encontrar esse eixo Z, mas acontece que acabamos tornando esses pequenos segmentos de linha pequenos quando você projeta os dados em Z. Na regressão linear, há um número Y, que recebe um tratamento muito especial. Estamos sempre tentando medir a distância entre a linha ajustada e Y, e é por isso que essas distâncias são medidas apenas na direção do eixo y. Já no PCA, você pode ter muitos recursos, X1, X2, talvez até X50, se tiver 50 recursos. Todos os 50 recursos são tratados da mesma forma. Estamos apenas tentando encontrar um eixo Z para que, quando os dados forem projetados no eixo Z usando esses segmentos de linha, você ainda retenha o máximo possível da variância dos dados originais. Eu sei que quando eu ploto essas coisas em duas dimensões, temos apenas duas características, ou seja, eu posso desenhar em um monitor de computador plano. Essas flechas parecem um pouco parecidas. Mas quando você tem mais de dois recursos, o que é a maioria dos casos, a diferença entre regressão linear e PCA e o que os algoritmos fazem é muito grande. Esses algoritmos são usados para propósitos totalmente diferentes e fornecem respostas muito diferentes. Quando a regressão linear é usada para prever uma saída alvo, Y e o PCA estão tentando pegar muitos recursos e tratá-los todos igualmente e reduzir o número de eixos necessários para representar bem os dados.
Reproduza o vídeo começando em :14:32 e siga a transcrição14:32
Acontece que maximizar a dispersão dessas projeções corresponderá a minimizar as distâncias desses segmentos de linha, as distâncias até os pontos precisam se mover para serem projetadas até Z. Para ilustrar a diferença entre regressão linear e PCA de outra forma, se você tiver um conjunto de dados parecido com este, regressão linear, tudo o que ele pode fazer é ajustar uma linha com essa aparência. Por outro lado, se seu conjunto de dados tiver essa aparência, o PCA escolherá esse como o componente principal. Portanto, você deve usar a regressão linear se estiver tentando prever o valor de y e usar o PCA se estiver tentando reduzir o número de recursos em seu conjunto de dados, por exemplo, para visualizá-lo. Finalmente, antes de encerrarmos este vídeo, há mais uma coisa que você pode fazer com o PCA, que é lembrar este exemplo que estava nas coordenadas 2,3. Descobrimos que se você projetou no eixo z, você acaba com 3,55. Uma coisa que você pode fazer é se você tiver um exemplo em que Z é igual a 3,55, dado apenas esse número Z, 3,55, podemos tentar descobrir qual foi o exemplo original? Acontece que há uma etapa no PCA chamada reconstrução, que é tentar ir desse número Z igual a 3,55 para os dois números originais, X1 e X2. Acontece que você não tem informações suficientes para recuperar exatamente X1 e X2, mas pode tentar aproximá-las. Em particular, a fórmula é: você pegaria esse número 3,55, que é Z, e o multiplicaria pelo comprimento de um vetor que acabamos de ter, que é 0,71, 0,71. Isso acaba sendo 2,52, 2,52, que é esse ponto aqui. Podemos aproximar o exemplo de treinamento original, que era uma coordenada 2, 3 com este novo ponto aqui, que está em 2,52, 2,52. A diferença entre o ponto original e o ponto projetado é esse pequeno segmento de linha aqui. Neste caso não é uma má aproximação 2,52, 2,52 não está muito longe de 2, 3. Com apenas um número, poderíamos obter uma aproximação razoável das coordenadas do exemplo de treinamento original. Isso é chamado de etapa de reconstrução do PCA. Resumindo, o algoritmo PCA analisa seus dados originais e escolhe um ou mais novos eixos, Z ou talvez Z1 e Z2, para representar seus dados, pegando seu conjunto de dados original e projetando-o em seu novo eixo ou eixo. Isso fornece um conjunto menor de números para que você possa plotar, se desejar visualizar seus dados. Você está vendo a matemática. Vamos agora dar uma olhada em como você pode implementar isso no código. No próximo vídeo, veremos como você mesmo pode usar o PCA usando a biblioteca scikit-learn. Vamos para o próximo vídeo.
Obrigatória
pt-BR
​

