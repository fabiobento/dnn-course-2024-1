Gostaria de compartilhar com vocês algumas dicas práticas para desenvolver um sistema de detecção de anomalias. Uma das ideias-chave é que, se você puder avaliar um sistema, mesmo enquanto ele está sendo desenvolvido, você poderá tomar decisões, mudar o sistema e melhorá-lo muito mais rapidamente. Vamos dar uma olhada no que isso significa. Quando você está desenvolvendo um algoritmo de aprendizado, por exemplo, escolhendo recursos diferentes ou testando valores diferentes dos parâmetros, como épsilon, tomando decisões sobre alterar ou não um recurso de uma determinada maneira ou aumentar ou diminuir o épsilon ou outros parâmetros, tomar essas decisões é muito mais fácil se você tiver uma maneira de avaliar o algoritmo de aprendizado. Às vezes, isso é chamado de avaliação de número real,
Reproduza o vídeo começando em ::49 e siga a transcrição0:49
o que significa que, se você puder alterar rapidamente o algoritmo de alguma forma, como alterar um recurso ou alterar um parâmetro, e tiver uma forma de calcular um número que informe se o algoritmo melhorou ou piorou, será muito mais fácil decidir se deve ou não continuar com essa alteração no algoritmo. É assim que geralmente é feito na detecção de anomalias. Ou seja, embora estejamos falando principalmente sobre dados não rotulados, vou mudar um pouco essa suposição e presumir que temos alguns dados rotulados, incluindo apenas um pequeno número geralmente de anomalias observadas anteriormente. Talvez depois de fabricar motores de avião por alguns anos, você tenha acabado de ver alguns motores de avião que eram anômalos e, por exemplos que você sabe que são anômalos, vou associar um rótulo y igual a 1 para indicar que isso é anômalo e, por exemplos que achamos normais, vou associar o rótulo y igual a 0.
Reproduza o vídeo começando em :1:56 e siga a transcrição1:56
O conjunto de treinamento com o qual o algoritmo de detecção de anomalias aprenderá ainda é esse conjunto de treinamento não rotulado de x1 a xm, e vou pensar em todos esses exemplos como aqueles que simplesmente assumiremos que são normais e não anômalos, então y é igual a 0. Na prática, você tem alguns exemplos anômalos em que inserir esse conjunto de treinamento; seu algoritmo geralmente ainda funciona bem.
Reproduza o vídeo começando em :2:27 e siga a transcrição2:27
Para avaliar seu algoritmo, encontre uma maneira de avaliar um número real. É muito útil se você tiver um pequeno número de exemplos anômalos para poder criar um conjunto de validação cruzada, que vou denotar x_cv^1, y_cv^1 a x_cv^1 a x_cv^mcv, y_cv^mcv. Essa é uma notação semelhante à que você viu no segundo curso dessa especialização. Da mesma forma, tenha um conjunto de testes com alguns exemplos em que espera-se que tanto a validação cruzada quanto os conjuntos de teste incluam alguns exemplos anômalos. Em outras palavras, os conjuntos de validação cruzada e teste terão alguns exemplos de y igual a 1, mas também muitos exemplos em que y é igual a 0. Novamente, na prática, o algoritmo de detecção de anomalias funcionará bem se houver alguns exemplos que sejam realmente anômalos, mas que tenham sido acidentalmente rotulados com y igual a 0. Vamos ilustrar isso com o exemplo do motor da aeronave. Digamos que você fabrica motores de aeronaves há anos e, portanto, coletou dados de 10.000 motores bons ou normais, mas ao longo dos anos você também coletou dados de 20 motores defeituosos ou anômalos. Normalmente, o número de motores anômalos, ou seja, y é igual a 1, será muito menor. Não será comum aplicar esse tipo de algoritmo com, digamos, de 2 a 50 anomalias conhecidas. Vamos pegar esse conjunto de dados e dividi-lo em um conjunto de treinamento, um conjunto de validação cruzada e o conjunto de teste. Aqui está um exemplo. Vou colocar 6.000 bons motores no conjunto de treinamento. Novamente, se alguns motores anômalos inseridos neste conjunto estão realmente bem, eu não me preocuparia muito com isso. Em seguida, vamos colocar 2.000 motores bons e 10 das anomalias conhecidas no conjunto de validação cruzada e mais 2.000 motores bons e 10 anômalos no conjunto de teste. O que você pode fazer então é treinar o algoritmo no conjunto de treinamento, ajustar as distribuições gaussianas a esses 6.000 exemplos e, em seguida, no conjunto de validação cruzada, você pode ver quantos motores anômalos ele sinaliza corretamente. Por exemplo, você pode usar o conjunto de validação cruzada para ajustar o parâmetro épsilon e defini-lo para cima ou para baixo, dependendo se o algoritmo parece estar detectando essas 10 anomalias de forma confiável sem usar muitos desses 2.000 bons motores e sinalizá-los como anomalias.
Reproduza o vídeo começando em :5:37 e siga a transcrição5:37
Depois de ajustar o parâmetro épsilon e talvez também adicionar, subtrair ou ajustar os recursos X_J, você pode então pegar o algoritmo e avaliá-lo em seu conjunto de testes para ver quantos desses 10 motores anômalos ele encontra, bem como quantos erros ele comete ao sinalizar os bons motores como anômalos.
Reproduza o vídeo começando em :6: e siga a transcrição6:00
Observe que esse ainda é basicamente um algoritmo de aprendizado não supervisionado porque os conjuntos de treinamento realmente não têm rótulos ou todos têm rótulos que presumimos que sejam y igual a 0. Por isso, aprendemos com o conjunto de treinamento ajustando as distribuições gaussianas, como você viu no vídeo anterior. Mas acontece que, se você está construindo um sistema prático de detecção de anomalias, com um pequeno número de anomalias para usar para avaliar o algoritmo, seus conjuntos de validação cruzada e teste são muito úteis para ajustar o algoritmo. Como o número de motores defeituosos é muito pequeno, há uma outra alternativa que eu costumo ver as pessoas usarem para detectar anomalias, que é não usar um conjunto de teste, como ter apenas um conjunto de treinamento e um conjunto de validação cruzada. Neste exemplo, você configurará o treinamento em 6.000 motores bons, mas pegará o restante dos dados, os 4.000 motores restantes em boas condições, bem como todas as anomalias, e os colocará no conjunto de validação cruzada. Em seguida, você ajustaria os parâmetros Epsilon e adicionaria ou subtrairia x_j fictício para tentar fazer com que ele funcionasse da melhor maneira possível, conforme avaliado no conjunto de validação cruzada. Se você tem muito poucos motores com defeito, então se você tinha apenas dois motores com defeito, então realmente faz sentido colocar tudo isso no conjunto de validação cruzada. Você simplesmente não tem dados suficientes para criar um conjunto de testes totalmente separado que seja diferente do seu conjunto de validação cruzada. A desvantagem dessa alternativa aqui é que, depois de ajustar seu algoritmo, você não tem uma maneira justa de dizer o quão bem isso realmente funcionará em exemplos futuros, porque você não tem o conjunto de testes. Mas quando seu conjunto de dados é pequeno, especialmente quando o número de anomalias que você tem, seu conjunto de dados é pequeno, essa pode ser a melhor alternativa que você tem. Também vejo isso feito com bastante frequência quando você simplesmente não tem dados suficientes para criar um conjunto de testes separado. Se for esse o caso, esteja ciente de que há um risco maior de você ter sobrecarregado algumas de suas decisões sobre o Epsilon e a escolha de recursos e assim por diante ao conjunto de validação cruzada. Portanto, seu desempenho em dados reais no futuro pode não ser tão bom quanto você esperava. Agora, vamos examinar mais de perto como realmente avaliar o algoritmo em seus conjuntos de validação cruzada ou no conjunto de testes. Aqui está o que você faria. Você primeiro encaixaria o modelo p de x no conjunto de treinamento. Foram 6.000 exemplos de motores de mercadorias. Então, em qualquer validação cruzada ou exemplo de teste x, você calcularia p de x e prediria que y é igual a 1. Isso é anômalo se p de x for menor que Epsilon e você predizer que y é 0, se p de x for maior ou igual a Epsilon. Com base nisso, agora você pode ver com que precisão as previsões desse algoritmo na validação cruzada ou no conjunto de testes correspondem aos rótulos que você tem na validação cruzada ou nos conjuntos de teste. Na terceira semana do segundo curso, tivemos alguns vídeos opcionais sobre como lidar com distribuições de dados altamente distorcidas, nas quais o número de exemplos positivos, y igual a 1, pode ser muito menor do que o número de exemplos negativos em que y é igual a 0. Esse também é o caso de muitas detecções de anomalias em aplicativos em que o número de anomalias em seu conjunto de validação cruzada é muito menor. Em nosso exemplo anterior, tivemos talvez 10 exemplos positivos e 2.000 exemplos negativos porque tínhamos 10 anomalias e 2.000 exemplos normais. Se você viu esses vídeos opcionais, deve se lembrar que vimos que pode ser útil calcular coisas como o verdadeiro positivo, falso positivo, falso negativo e verdadeiro negativo [inaudível]. Além disso, calcule a recuperação de precisão ou a pontuação F_1 e diga que essas são métricas alternativas e a precisão de classificação que podem funcionar melhor quando a distribuição de dados é muito distorcida. Se você viu esse vídeo, considere aplicar esses tipos de métricas de avaliação também para dizer o quão bem seu algoritmo de aprendizado está se saindo em encontrar um pequeno punhado de anomalias ou exemplos positivos em meio a esse conjunto muito maior de exemplos negativos de motores de avião normais. Se você não assistiu ao vídeo, não se preocupe. Está tudo bem. A intuição que espero que você tenha é usar o conjunto de validação cruzada para ver quantas anomalias estão sendo encontradas e também quantos motores normais estão sendo sinalizados incorretamente como uma anomalia. Em seguida, basta usar isso para tentar escolher uma boa opção para o parâmetro Epsilon. Você descobre que o processo prático de construir um sistema de detecção de anomalias é muito mais fácil se você realmente tiver apenas um pequeno número de exemplos rotulados de anomalias conhecidas. Agora, isso levanta a questão: se você tiver alguns exemplos rotulados, já que ainda estará usando um algoritmo de aprendizado não supervisionado, por que não pegar esses exemplos rotulados e usar um algoritmo de aprendizado supervisionado? No próximo vídeo, vamos dar uma olhada em uma comparação entre detecção de anomalias e aprendizado supervisionado e quando você pode preferir um em vez do outro. Vamos para o próximo vídeo.
