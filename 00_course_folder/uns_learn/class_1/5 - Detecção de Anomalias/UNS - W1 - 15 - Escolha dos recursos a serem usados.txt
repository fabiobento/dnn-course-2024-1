Ao criar um algoritmo de detecção de anomalias, descobri que escolher uma boa escolha de recursos acabou sendo muito importante. No aprendizado supervisionado, se você não tiver os recursos corretos ou se tiver alguns recursos extras que não são relevantes para o problema, geralmente não há problema. Como o algoritmo precisa de um sinal supervisionado, isso é suficiente para identificar o motivo para que o algoritmo descubra quais recursos ignoram ou como redimensionar o recurso e tirar o melhor proveito dos recursos que você fornece a ele. Mas para a detecção de anomalias que é executada ou aprendida apenas com dados não rotulados, é mais difícil para a anomalia descobrir quais recursos ignorar. Então, descobri que escolher cuidadosamente os recursos é ainda mais importante para a detecção de anomalias do que para abordagens de aprendizado supervisionado. Vamos dar uma olhada neste vídeo com algumas dicas práticas sobre como ajustar os recursos de detecção de anomalias para tentar obter o melhor desempenho possível. Uma etapa que pode ajudar seu algoritmo de detecção de anomalias é tentar garantir que os recursos fornecidos sejam mais ou menos gaussianos. E se suas características não forem gaussianas, às vezes você pode alterá-las para torná-las um pouco mais gaussianas. Deixe-me mostrar o que quero dizer. Se você tiver um recurso X, geralmente traço até sibilar um grama do recurso, o que você pode fazer usando o comando python PLT. Embora você também veja isso no laboratório prático, para analisar a história dos dados. Essa distribuição aqui parece bem gaussiana. Portanto, esse seria um bom recurso de candidato. Se você acha que esse é um recurso que espera distinguir entre anomalias e exemplos normais. Mas, muitas vezes, quando você traça um sibilar de seus recursos, você pode descobrir que o recurso tem uma distribuição como essa. Isso não se parece em nada com aquela curva simétrica em forma de sino. Nesse caso, eu consideraria se você pode pegar esse recurso X e transformá-lo para torná-lo mais gaussiano. Por exemplo, talvez se você fosse calcular o log de X e traçar um sibilo de um grama de log de X, fique assim, e isso parecesse muito mais gaussiano. Então, se esse recurso fosse o recurso X um, em vez de usar o recurso X original, que se parece com este à esquerda, você pode substituir esse recurso pelo log do X um, para obter essa distribuição aqui. Porque quando X um se torna mais gaussiano. Quando a detecção de anomalias modela P de X, um usando uma distribuição gaussiana como essa, é mais provável que seja um bom ajuste aos dados. Além da função de log, outras coisas que você pode fazer é, dado um recurso diferente X dois, você pode substituí-lo por X dois, log de X dois mais um. Essa seria uma maneira diferente de transformar X dois. E, de forma mais geral, log de X dois mais C, seria um exemplo de uma fórmula que você pode usar para alterar X e tentar torná-la mais gaussiana. Ou, para uma característica diferente, você pode tentar obter a raiz quadrada ou, na verdade, o quadrado teria executado essa derivação X à potência da metade, e você pode alterar esse termo exponencialmente. Portanto, para um recurso diferente X quatro, você pode usar X quatro à potência de um terço, por exemplo. Então, quando estou construindo um sistema de detecção de anomalias, às vezes dou uma olhada em minhas características, e se vejo algo altamente não gaussiano ao traçar um grama sibilado, posso escolher transformações como essas ou outras, para tentar torná-lo mais gaussiano. Acontece que um valor maior de C acabará transformando menos essa distribuição. Mas, na prática, eu apenas tento vários valores diferentes de C e, em seguida, tento escolher um que pareça melhor em termos de tornar a distribuição mais gaussiana. Agora, deixe-me ilustrar como eu realmente faço isso e como você coloca um caderno. Então, é assim que pode ser o processo de explorar diferentes transformações nos recursos.
Reproduza o vídeo começando em :4:33 e siga a transcrição4:33
Quando você tem um recurso X, você pode representar graficamente um grama sibilado da seguinte forma. Na verdade, parece que há uma boa causa de assobiar um grama. Deixe-me aumentar o número de compartimentos em minha grama de histórico para 50. Então, compartimentos são iguais a 50 lá. Isso é o que assobiou uma caixa de grama. E, a propósito, se você quiser mudar a cor, você também pode fazer isso da seguinte maneira. E se você quiser tentar uma transformação diferente, você pode tentar, por exemplo, traçar X raiz quadrada de X. Então X na potência de 0,5 com novamente 50 compartimentos sibilados por grama. Nesse caso, pode ficar assim. E isso realmente parece um pouco mais gaussiano. Mas não perfeitamente, e vamos tentar um parâmetro diferente. Então, deixe-me tentar a potência de 4,25. Talvez eu esteja um pouco longe demais. É o antigo 0.4 que parece bem gaussiano. Então, uma coisa que você pode fazer é substituir X por uma potência excelente de 0,4. E então você definiria X como igual a X à potência de 0,4. Em vez disso, use o valor de X em seu processo de treinamento. Ou deixe-me mostrar outra transformação. Aqui, vou tentar pegar o registro de X. Então, o registro de X localizado com 50 compartimentos, vou usar a função de registro numpy da seguinte forma. E acontece que você comete um erro, porque é excelente. Este exemplo tem alguns valores que são iguais a zero, e logaremos se zero for negativo, o infinito não está definido. Então, o truque comum é adicionar apenas um número muito pequeno lá.
Reproduza o vídeo começando em :6:28 e siga a transcrição6:28
Então, exporta 0,001, torna-se não negativa. E então você obtém a grama sibilada que se parece com isso. Mas se você quiser que a distribuição pareça mais gaussiana, você também pode brincar com esse parâmetro, para tentar ver se há um valor nisso. Faça com que os dados do usuário pareçam mais simétricos e talvez mais gaussianos da seguinte forma. E, assim como estou fazendo agora em tempo real, você pode alterar rapidamente esses parâmetros e traçar o grama sibilado. Para tentar dar uma olhada e tentar obter algo um pouco mais gaussiano do que os dados originais que você viu a seguir neste grama sibilado acima. Se você ler a literatura sobre aprendizado de máquina, existem algumas maneiras de medir automaticamente a proximidade dessas distribuições com o gaussiano. Mas descobri que, na prática, não faz grande diferença. Se você tentar alguns valores e escolher algo que pareça certo para você, que funcionará bem para todos os fins práticos. Então, ao testar coisas no notebook Jupiter, você pode tentar escolher uma transformação que torne seus dados mais gaussianos. E, como lembrete, qualquer que seja a transformação aplicada ao conjunto de treinamento, lembre-se de aplicar a mesma transformação também aos dados da validação cruzada e do conjunto de testes. Além de garantir que seus dados sejam aproximadamente gaussianos, depois de treinar seu algoritmo de detecção de anomalias, se ele não funcionar muito bem em seu conjunto de validação de confiança, você também pode realizar um processo de análise de erros para detecção de anomalias. Em outras palavras, você pode tentar verificar onde o algoritmo ainda não está funcionando bem enquanto comete erros e, em seguida, usar isso para tentar fazer melhorias. Então, como um lembrete, o que queremos é que P de X seja grande. Para exemplos normais X, então maior que igual a épsilon, e p f X sendo pequeno ou menor que épsilon, para os exemplos anômalos X. Quando você aprendeu o modelo P de X com seus dados não rotulados, o problema mais comum que você pode encontrar é que P de X é comparável em valor, digamos, grande para exemplos normais e anômalos. Como um exemplo concreto, se esse for o seu conjunto de dados, você pode encaixar essa galáxia nele. E se você tem um exemplo em seu conjunto de validação cruzada ou conjunto de teste, que está aqui, que é anômalo, então isso tem uma probabilidade muito alta. E, de fato, é bem parecido com os outros exemplos em seu conjunto de treinamento. Então, mesmo que isso seja uma anomalia, P de X é na verdade muito grande. Portanto, o algoritmo falhará em sinalizar esse exemplo específico como uma anomalia. Nesse caso, o que eu normalmente faria é tentar ver esse exemplo e tentar descobrir o que me fez pensar que é uma anomalia, mesmo que esse recurso X um assumisse valores semelhantes a outros exemplos de treinamento. E se eu puder identificar algum novo recurso, digamos X dois, isso ajuda a distinguir esse exemplo dos exemplos normais. Em seguida, adicionar esse recurso pode ajudar a melhorar o desempenho do algoritmo. Aqui está uma foto mostrando o que quero dizer. Se eu conseguir criar um novo recurso X dois, digamos, estou tentando detectar comportamento fraudulento, e se X um é o número de transações que eles fazem, talvez esse usuário pareça estar fazendo algumas das transações como todo mundo. Mas se eu descobrir que esse usuário tem uma velocidade de digitação incrivelmente rápida, e se eu adicionasse um novo recurso X dois, essa é a velocidade de digitação desse usuário. E se descobrir que quando eu ploto esses dados usando o antigo recurso X um e esse novo recurso X dois, faz com que X dois se destaque aqui. Então, fica muito mais fácil para o algoritmo de detecção de anomalias reconhecer que um X dois é um usuário anômalo. Porque quando você tem esse novo recurso X dois, a anomalia de aprendizado pode se ajustar a uma distribuição gaussiana que atribui alta probabilidade a pontos nessa região, um pouco menor nessa região e um pouco menor nessa região. E assim, esse exemplo, devido ao valor muito anômalo de X dois, se torna mais fácil de detectar como uma anomalia. Então, para resumir, o processo de desenvolvimento geralmente percorrido é treinar o modelo e, em seguida, ver quais anomalias no conjunto de validação cruzada o algoritmo não consegue detectar. E depois analisar esses exemplos para ver se isso pode inspirar a criação de novos recursos que permitiriam ao algoritmo identificar. Esse exemplo assume valores inusitadamente grandes ou incomumente pequenos nos novos recursos, de modo que agora você pode sinalizar esses exemplos como anomalias com sucesso. Apenas como mais um exemplo, digamos que você esteja construindo um sistema de detecção de anomalias para monitorar computadores no data center. Para tentar descobrir se um computador pode estar se comportando de maneira estranha e merece uma análise mais detalhada, talvez por causa de uma falha de hardware, ou porque foi invadido ou algo assim. Então, o que você gostaria de fazer é escolher recursos que possam assumir valores excepcionalmente grandes ou pequenos no caso de uma anomalia. Você pode começar com recursos como X um é o uso da memória, X dois é o número de acessos ao disco por segundo, depois a carga da CPU e o volume do tráfego da rede. E se você treinar o algoritmo, poderá descobrir que ele detecta algumas anomalias, mas não consegue detectar outras anomalias. Nesse caso, não é incomum criar novos recursos combinando recursos antigos. Então, por exemplo, se você descobrir que há um computador que está se comportando de maneira muito estranha, mas nem a carga da CPU nem o tráfego de rede, isso é incomum. Mas o que é incomum é que ele tem uma carga de CPU muito alta e um volume de tráfego de rede muito baixo. Se você estiver administrando o data center que transmite vídeos, os computadores podem ter alta carga de CPU e alto tráfego de rede, ou baixa carga de CPU e nenhum tráfego de rede. Mas o que é incomum nessa máquina é uma carga de CPU muito alta, apesar de um volume de tráfego muito baixo. Nesse caso, você pode criar um novo recurso X cinco, que é uma proporção entre a carga da CPU e o tráfego da rede. E esse novo recurso, com esperança, o algoritmo de detecção de anomalias, sinalizou exemplos futuros, como a máquina específica que você pode estar vendo, como anômala. Ou você também pode considerar outros recursos, como o quadrado da carga da CPU, dividido pelo volume de tráfego da rede. E você pode brincar com diferentes opções desses recursos. Para tentar fazer com que P de X ainda seja grande para os exemplos normais, mas se torne pequeno nas anomalias em seu conjunto de validação cruzada. Então é isso. Obrigado por ficar comigo até o final desta semana. Espero que você goste de ouvir sobre algoritmos de agrupamento e algoritmos de detecção de anomalias. E que você também gosta de brincar com essas ideias nos laboratórios práticos.
Reproduza o vídeo começando em :14:15 e siga a transcrição14:15
Na próxima semana, falaremos sobre sistemas de recomendação. Quando você acessa um site e recomenda produtos, filmes ou outras coisas para você. Como esse algoritmo realmente funciona? Esse é um dos algoritmos comercialmente mais importantes em aprendizado de máquina, que é surpreendentemente pouco comentado, mas na próxima semana veremos como esses algoritmos funcionam para que você entenda na próxima vez que acessar o site e recomendar algo para você. Talvez como isso tenha surgido. Da mesma forma, você também poderá criar outros algoritmos como esse para si mesmo. Então, divirta-se com os laboratórios e eles esperam ver você na próxima semana.
Obrigatória
pt-BR
​

