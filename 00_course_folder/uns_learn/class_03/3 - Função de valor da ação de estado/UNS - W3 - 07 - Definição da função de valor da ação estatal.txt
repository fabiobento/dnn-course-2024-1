quando começarmos a desenvolver horas de aprendizado por reforço no final desta semana, você verá que há uma quantidade chave que as setas de aprendizado por reforço tentarão calcular, chamada de função de valor da ação estadual. Vamos dar uma olhada no que é essa função. A função de valor da ação de estado é uma função normalmente indicada pela letra maiúscula Q. E é uma função de um estado em que você pode estar, bem como da ação que você pode escolher realizar nesse estado e no QFSA. Dará um número igual ao retorno. Se você começar nesse estado. S e execute a ação A apenas uma vez e depois de realizar a ação A uma vez, você se comporta de maneira ideal depois disso. Então, depois disso, você toma todas as ações que resultarão no maior retorno possível. Agora você pode estar pensando que há algo um pouco estranho nessa definição, porque como sabemos qual é o comportamento ideal? E se soubéssemos qual é o comportamento automático, se já sabíamos qual é a melhor ação a ser tomada em cada estado, por que ainda precisamos calcular Q de SA. Porque já temos a política de automóveis. Então, eu quero reconhecer que há algo um pouco estranho nessa definição. Há quase algo um pouco circular nessa definição, mas fique tranquilo. Quando analisarmos os resultados específicos do aprendizado por reforço, mais tarde resolveremos essa definição ligeiramente circular e encontraremos uma maneira de calcular a função Q antes mesmo de criarmos a política ideal. Mas você vê isso em um vídeo posterior. Portanto, não se preocupe com isso por enquanto. Vejamos um exemplo que vimos anteriormente de que essa é uma política muito boa. Vá para a esquerda dos estágios 2, 3 e quatro e vá para a direita do Estado cinco. Acontece que essa é, na verdade, a política ideal para a aplicação do Mars Rover. Quando o fator de desconto gama é 0,5, então Q de S. A será igual ao retorno total. Se você começar, digamos, tome a ação A e depois se comporte de maneira ideal. Ou seja, tomar medidas de acordo com esta política. Mostrado aqui, vamos descobrir o que Q de s, a. é para alguns estados diferentes. Vamos ver, digamos, Q do estado também. E se tomarmos a decisão de ir bem, se você estiver no estado dois e for para a direita, acabará no estado três? E depois disso, você se comportará de maneira ideal, você vai para a esquerda do ST três e depois para a esquerda do estado para e, eventualmente, você receberá a recompensa de 100. Nesse caso, as recompensas que você recebe seriam zero do estado a zero quando você ficasse três, zero ao voltar ao estado dois e depois 100 quando finalmente chegasse ao estado terminal um e, portanto, o retorno será zero mais 0,5 vezes isso mais 0,5 vezes ao quadrado vezes ac mais 0,5 cúbico vezes 100. E isso resulta em 12,5. Então Q de ST dois de ir para a direita é igual a 12,5. Observe que isso passa, sem julgamento sobre se ir para a direita é uma boa ideia ou não. Na verdade, não é uma boa ideia do estado ir para a direita, mas ele apenas relata fielmente o retorno se você realizar a ação A e depois se comportar de maneira ideal. Aqui está outro exemplo. Se você estiver no estado a e for para a esquerda, a sequência de recompensas que você receberá será zero quando estiver no estado dois, seguida por 100. E então o retorno é zero mais 0,5 vezes 100, que é igual a 50, a fim de anotar os valores de QSA. Neste diagrama, vou escrever 12,5 aqui à direita para indicar que isso é Q do estado para ir para a direita. E então, quando escrevo um pouco de 50 aqui à esquerda para indicar que isso é Q de ST dois e vou para a esquerda apenas para dar mais um exemplo. E se estivermos no ST quatro e decidirmos ir para a esquerda. Bem, se você estiver no estágio quatro, você vai para a esquerda, recebe recompensas zero e depois age aqui. Então, ganho zero, aja aqui, zero e depois 100. Então, Q de quatro à esquerda resulta em recompensa zero porque resta a primeira ação e , em seguida, porque seguimos a política ideal. Você pode recompensar 00 100. E então o retorno é zero mais 0,05 vezes isso. Mais 4,5 vezes ao quadrado mais 0,5 Q vezes isso. O que, portanto, é igual a 12,5. Então, o quarto trimestre restante é 12,5. Eu vou escrever este ano como 12,5. E acontece que se você realizasse esse exercício para todos os outros estados e todas as outras ações, acabaria com isso sendo o Q de s, a. Para diferentes estados e ações diferentes e, finalmente, no Estado Terminal. Bem, não importa o que você faça, você apenas recebe aquela recompensa terminal de 100 ou 40. Então, basta anotar os prêmios do terminal aqui. Então, isso é Q de s, a. Para cada estado de um a seis e para as duas ações, ação esquerda e ação direita. Porque a função de valor da ação de estado é quase sempre indicada pela letra Q. Isso também é freqüentemente chamado de função Q. Então, os termos Função Q. e função de valor da ação de estado são usados indistintamente e dizem quais são seus retornos ou realmente qual é o valor? Quão bom é? Basta executar as ações A e ST S e, em seguida, se comportar de maneira ideal depois disso. Agora, acontece que, uma vez que você possa calcular a função Q, isso também lhe dará uma maneira de escolher ações. Aqui está a política e a devolução. E aqui estão os valores dois de s, a. do slide anterior. Você percebe uma coisa interessante quando olha para os diferentes estados, que é que, se você considerar a ação à esquerda, resulta em um valor de a, q. ou valor da ação estadual de 50, que é, na verdade, o melhor retorno possível que você pode obter desse estado. No estado três dois de s, a. para a ação à esquerda também indica que maior retorno é, portanto, a ação à esquerda fornece o retorno desejado. E no estado cinco, na verdade, é a ação que vai para a direita que lhe dá um retorno maior de 20. Então, acontece que o melhor retorno possível de qualquer estado S. É o maior valor de Q, F, S. A maximizando sobre A. Só para ter certeza de que está claro, o que estou dizendo é que, digamos, permaneça por Há dois do estado quatro restantes que são 12,5 e q. do estado quatro à direita, o que acaba sendo 10. E o maior desses dois valores, que é 12,5, é o melhor retorno possível desse estado quatro. Em outras palavras, o maior retorno que você pode esperar obter do estado quatro é 12,5. E na verdade é o maior desses dois números 12,5 e 10. Além disso, se você quiser que seu Mars Rover desfrute de um retorno de 12,5 em vez de, digamos, 10, a ação que você deve realizar é a ação A. Isso lhe dá o maior valor de Q de s, a. Então, o melhor status de ação possível é a ação A. Isso realmente maximiza Q, de s, a. Então, isso pode lhe dar uma dica de por que calcular Q, de s, a. É uma parte importante do algoritmo de aprendizado por reforço que construa mais tarde. Ou seja, se você tem uma maneira de calcular Q de s, a. Para cada estado e para cada ação, quando você está em algum estado s, tudo o que você precisa fazer é observar as diferentes ações A. E escolher a ação A. Isso maximiza Q de s, a. E então pi F. S pode simplesmente escolher a ação A. Isso dá o maior valor de Q de s, a. E isso acabará sendo uma boa ação. Na verdade, acabou sendo a ação ideal. Outra intuição sobre por que isso faz sentido é que Qof s, a. É retornado se você repentinamente fizer um status e realizar a ação A. E então se comportar de maneira ideal depois disso. Então, para obter o maior retorno possível, o que você realmente quer é realizar a ação A. Isso resulta no maior retorno total. É por isso que, se ao menos tivéssemos uma maneira de calcular Q f s, a. Para cada estado que toma a ação, o auxílio que maximiza o retorno nessas circunstâncias parece ser a melhor ação a ser tomada nesse estado. Embora isso não seja algo que você precise saber para isso. Porque eu quero mencionar também que, se você pesquisar on-line ou consultar a literatura de aprendizado por reforço, às vezes você também verá essa função Q escrita como Q. Star em vez de Q. E essa função Q às vezes também é chamada de função Q ideal. Esses termos se referem apenas à função Q exatamente como a definimos. Então, se você ler a literatura de aprendizado por reforço e ler sobre Q. Star ou a função Q, isso significa apenas a função de valor da ação de estado sobre a qual falamos. Mas, para os propósitos deste curso, você não precisa se preocupar com isso. Então, para resumir, se você pode calcular Q de s, a. Para cada estado e cada ação, isso nos dá uma boa maneira de calcular a política automática pi de S. Então essa é a função de valor da ação estadual ou a função Q. Falaremos mais tarde sobre como criar um algoritmo para computá-los, apesar do aspecto ligeiramente circular da definição da função Q. Mas primeiro, vamos dar uma olhada no próximo vídeo, com alguns exemplos específicos de como esses valores Q de s, a. Na verdade se parecem
