Nos cursos anteriores, cursos um e dois da especialização, você viu muitos algoritmos de aprendizado supervisionado como um conjunto de treinamento representando uma função de custo. E, em seguida, usar a gradação descendente ou outros algoritmos para otimizar essa função de custo. Acontece que o algoritmo de chave significa que você viu no último vídeo também está otimizando uma função de custo específica. Embora o algoritmo de otimização usado para otimizar e que não esteja criando dissidência seja, na verdade, o algoritmo que você já viu no último vídeo. Vamos dar uma olhada no que tudo isso significa. Vamos dar uma olhada em qual é a função de custo de um meio. Para começar como um lembrete, essa é uma notação que estamos usando, enquanto CI é o índice do cluster. Portanto, CI é algum número de um Su K do índice do cluster ao qual o exemplo de treinamento XI está atualmente atribuído e o novo K é a localização do centróide do cluster k. Deixe-me apresentar mais uma notação, que é quando K minúsculo é igual a CI. Portanto, mu subscript CI é o centróide do cluster ao qual o exemplo XI foi atribuído. Então, por exemplo, se eu olhasse algum exemplo de treinamento C, exemplo 10, do trem C e perguntasse: Qual é a localização do século constante ao qual o décimo exemplo de treinamento foi atribuído? Bem, eu procuraria então o C10. Isso me dará um número de um a K. Isso me diz que o exemplo 10 foi atribuído ao centróide vermelho ou azul ou a algum outro cluster, e então o símbolo mu C-10 é a localização do centróide do agrupamento em que a extensão foi atribuída. Então, munido dessa notação, deixe-me agora escrever a função de custo que K significa que está sendo minimizadora. A função de custo J, que é uma função de C1 a CM.
Reproduza o vídeo começando em :2:23 e siga a transcrição2:23
Essas são todas as atribuições de pontos para clusters de Androids, bem como uma nova por meio da cápsula Mu K. Essas são as localizações de todos os clusters. O centróide é definido como esta expressão à direita. É a média, então um sobre M, um pouco do de Michael até ele, da distância quadrada entre cada exemplo de treinamento XI quando eu vou de um a M, é uma distância quadrada entre X I. E Nu subscrito C alto. Então, essa quantidade aqui em cima, em outras palavras, a função de custo boa para os quenianos é a distância quadrada média entre cada exemplo de treinamento XI.
Reproduza o vídeo começando em :3:11 e siga a transcrição3:11
E a localização do centróide do cluster ao qual o exemplo de treinamento de exílio foi atribuído. Então, neste exemplo aqui, estamos medindo a distância entre X10 e mu subscrito C10. O centróide do agrupamento, cuja extensão foi atribuída, tomando o quadrado dessa distância, seria um dos termos aqui sobre os quais estamos calculando a média. E acontece que o que o álbum K significa que está fazendo é tentar encontrar atribuições de pontos do centróide dos aglomerados, bem como encontrar localizações do centróide dos aglomerados que minimizem a distância quadrada. Visualmente, aqui está o que você viu no início da série K significa no vídeo anterior. E nesta etapa, a função de custo. Se você fosse ao computador, seria olhar para todos os pontos azuis e medir essas distâncias e o quadrado do computador. E então, da mesma forma, observe cada um dos pontos vermelhos, calcule essas distâncias e calcule o quadrado. E então, a média dos quadrados de todas essas diferenças para os pontos vermelho e azul é o valor da função de custo J, nessa configuração particular dos parâmetros para reis. E o que eles farão em cada etapa é tentar atualizar as atribuições de cluster de C1 a C30 neste exemplo. Ou atualize as posições do centralismo do cluster, U1 e U2. Para continuar reduzindo essa função de custo J. A propósito, essa função de custo J também tem um nome na literatura que é chamada de função de distorção. Não sei se esse é um ótimo nome. Mas se você ouvir alguém falar sobre o principal algoritmo de notícias e a distorção ou a função de custo de distorção, é exatamente isso que essa fórmula J está computando.
Reproduza o vídeo começando em :5:6 e siga a transcrição5:06
Vamos agora dar uma olhada mais profunda no algoritmo e por que o algoritmo está tentando minimizar essa função de custo J. Ou por que está tentando minimizar a distorção aqui, além da copiada sobre a função de custo do slide anterior.
Reproduza o vídeo começando em :5:21 e siga a transcrição5:21
Acontece que a primeira parte de K significa onde você atribui pontos ao centróide do agrupamento. Isso acaba sendo tentar atualizar o C1 por meio do CM. Para tentar minimizar a função de custo J o máximo possível enquanto segura uma nova por meio da minha correção K. E na segunda etapa, ao contrário de quando você move o centróide personalizado, acontece que está tentando deixar C1 até CM fixo. Mas atualizar um novo por meio do mu K para tentar minimizar a função de custo ou a distorção o máximo possível. Vamos dar uma olhada em por que esse é o caso. Durante a primeira etapa, se você quiser escolher os valores de C1 a CM ou salvar um valor específico de Ci para tentar minimizar isso. Bem, o que tornaria Xi menos mu CI o menor possível? Essa é a distância ou a distância quadrada entre um exemplo de treinamento XI. E a localização da turma é central para a qual foi atribuída.
Reproduza o vídeo começando em :6:31 e siga a transcrição6:31
Portanto, se você quiser minimizar essa distância ou a distância quadrada, o que você deve fazer é atribuir XI ao santuário mais próximo.
Reproduza o vídeo começando em :6:42 e siga a transcrição6:42
Então, para dar um exemplo simplificado, se você tiver dois clusters centróides, digamos que perto do centro esteja um e dois e apenas um único exemplo de treinamento, XI. Se você assinasse no cluster central, essa distância quadrada aqui seria essa grande distância, bem quadrada.
Reproduza o vídeo começando em :7:4 e siga a transcrição7:04
E se você assinasse muito perto do centro, essa distância quadrada seria o quadrado dessa distância muito menor. Então, se você quiser minimizar esse termo, você pegará X I e o atribuirá ao centróide mais próximo, que é exatamente o que o álbum está fazendo aqui. É por isso que a etapa em que você assinala pontos para agrupar o século é escolher os valores de CI para tentar minimizar J. Sem mudar, passamos pelo Reino Unido por enquanto, mas apenas escolhendo os valores de C1 a CM para tentar tornar esses termos os menores possíveis.
Reproduza o vídeo começando em :7:40 e siga a transcrição7:40
Que tal a segunda etapa do algoritmo K-means, que consiste em passar para os centróides dos clusters? Acontece que escolher mu K como média e a média dos pontos atribuídos é a escolha desses termos mu que minimizará essa expressão. Para dar um exemplo simplificado, digamos que você tenha um cluster com apenas dois pontos à parte, mostrado a seguir. Então, com o centróide mais próximo aqui, a média das distâncias quadradas seria uma distância de um aqui ao quadrado mais essa distância aqui, que é 9 ao quadrado. E então você pega a média desses dois números. E isso acaba sendo metade de 1 mais 81, o que resulta em 41. Mas se você tomasse a média desses dois pontos, então 1+ 11/2, isso é igual a 6. E se você movesse o centróide do cluster aqui para o meio, a média dessas duas distâncias quadradas acabaria sendo uma distância de cinco e cinco anos. Então você acaba com metade de 5 quadrados mais 5 quadrados, o que é igual a 25. E essa é uma distância quadrada média muito menor do que 41. E, de fato, você pode brincar com a localização desse centróide de agrupamento e talvez se convencer de que está tomando essa localização média. Essa localização média no meio desses dois exemplos de treinamento é realmente o valor que minimiza a distância quadrada. Portanto, o fato de o algoritmo K-means estar otimizando uma função de custo J significa que é garantida a convergência, ou seja, em cada iteração. A função de custo de distorção deve diminuir ou permanecer a mesma, mas se alguma vez falhar ou permanecer a mesma, na pior das hipóteses, se alguma vez aumentar. Isso significa que há um bug no código, ele nunca deve subir porque cada etapa de K significa definir o valor CI e mu K para tentar reduzir a função de custo. Além disso, se a função de custo parar de cair, isso também oferece uma maneira de testar se a média K convergiu. Quando há uma única duração em que ela permanece a mesma. Isso geralmente significa que K means convergiu e você deve simplesmente parar de rodar o álbum ainda mais ou, em alguns casos raros, você executará K means por um longo tempo. E a função de custo da distorção está diminuindo muito, muito lentamente, e isso é um pouco como um ótimo inter enviado, onde talvez ficar ainda mais longo possa ajudar um pouco. Mas se a taxa na qual a função de custo está caindo se tornar muito, muito lenta. Você também pode dizer que isso é bom o suficiente. Só vou dizer que está perto o suficiente da convergência e não gaste ainda mais ciclos de computação executando o álbum por ainda mais tempo. Então, essas são algumas das maneiras pelas quais o cálculo da função de custo ajuda você a descobrir se o álbum convergiu. Acontece que há outra maneira muito útil de aproveitar as vantagens da função de custo, que é usar várias inicializações aleatórias diferentes do centróide do cluster. Acontece que, se você fizer isso, geralmente poderá encontrar clusters muito melhores usando meios K, vamos dar uma olhada no próximo vídeo sobre como fazer isso.
