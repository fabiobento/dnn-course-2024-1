No último vídeo, você viu uma ilustração do algoritmo k-means em execução. Agora, vamos escrever o algoritmo K-means em detalhes para que você possa implementá-lo por si mesmo. Aqui está o algoritmo K-means.
Reproduza o vídeo começando em ::17 e siga a transcrição0:17
O primeiro passo é inicializar aleatoriamente os centróides do cluster K, Mu 1 Mu 2, por meio de Mu k. No exemplo que tivemos, isso correspondeu a quando escolhemos aleatoriamente um local para a cruz vermelha e para a cruz azul correspondente aos dois centróides do agrupamento. Em nosso exemplo, K era igual a dois. Se a cruz vermelha fosse o centróide um do agrupamento e a cruz azul fosse o centróide dois do agrupamento. Esses são apenas dois índices para indicar o primeiro e o segundo agrupamento. Então, a cruz vermelha seria a localização de Mu 1 e a cruz azul seria a localização de Mu 2. Só para ficar claro, Mu 1 e Mu 2 são vetores que têm a mesma dimensão de seus exemplos de treinamento, de X1 a, digamos, X30, em nosso exemplo. Todas essas são listas de dois números ou são vetores bidimensionais ou qualquer dimensão que os dados de treinamento tivessem. Tivemos n igual a duas características para cada um dos exemplos de treinamento, então Mu 1 e Mu 2 também serão vetores bidimensionais, ou seja, vetores com dois números neles. Depois de inicializar aleatoriamente os centróides do cluster K, o K-means executará repetidamente as duas etapas que você viu no último vídeo. A primeira etapa é atribuir pontos aos agrupamentos, centróides, ou seja, cor, cada um dos pontos, vermelho ou azul, correspondendo a atribuí-los aos centróides do agrupamento um ou dois quando K é igual a dois. Enxágue o suficiente.
Reproduza o vídeo começando em :2:14 e siga a transcrição2:14
Isso significa que, como I é igual a um a m para todos os m exemplos de treinamento, vamos definir c^i como igual ao índice, que pode ser qualquer coisa de um a K do centróide do cluster mais próximo do exemplo de treinamento x^i. Matematicamente, você pode escrever isso como calcular a distância entre x^i e Mu k. Em matemática, a distância entre dois pontos geralmente é escrita assim. Também é chamada de norma L2.
Reproduza o vídeo começando em :2:44 e siga a transcrição2:44
O que você quer encontrar é o valor de k que minimiza isso, porque isso corresponde ao centróide do cluster Mu k que está mais próximo do exemplo de treinamento x^i. Então, o valor de k que minimiza isso é definido como c^i. Quando você implementa esse algoritmo, você descobre que na verdade é um pouco mais conveniente minimizar a distância quadrada porque o centróide do cluster com a menor distância quadrada deve ser o mesmo o centróide do cluster com a menor distância. Ao analisar os laboratórios opcionais e os laboratórios práticos desta semana, você vê como implementar isso no código por si mesmo. Como um exemplo concreto, este ponto aqui em cima está mais próximo do vermelho ou dos dois centróides do cluster 1. Se esse for o exemplo de treinamento x^1, definiremos c^1 como igual a 1. Já neste ponto, se esse foi o 12º exemplo de treinamento, está mais próximo do segundo centróide do cluster, o azul. Definiremos isso, a variável de atribuição de cluster correspondente, como dois porque está mais próxima do centróide 2 do cluster. Essa é a primeira etapa do algoritmo K-means, atribuir pontos aos centróides do cluster. A segunda etapa é mover os centróides do cluster. O que isso significa é que, para minúsculas, k é igual a 1 para K maiúsculo, o número de clusters.
Reproduza o vídeo começando em :4:26 e siga a transcrição4:26
Vamos definir a localização do centróide do cluster a ser atualizada para ser a média ou a média dos pontos atribuídos a esse cluster k. Concretamente, o que isso significa é que examinaremos todos esses pontos vermelhos, digamos, e analisaremos sua posição no eixo horizontal e veremos o valor da primeira característica x^1, calculando a média disso. Calcule também o valor médio no eixo vertical. Depois de calcular essas duas médias, você descobre que a média está aqui, e é por isso que Mu 1, que é o local em que o centróide do cluster vermelho, é atualizado da seguinte forma. Da mesma forma, veremos todos os pontos que foram coloridos em azul, ou seja, com c^i igual a 2 e calcularemos a média do valor no eixo horizontal, a média de sua característica x1. Calcule a média do recurso x2. Essas duas médias fornecem a nova localização do centróide azul do aglomerado, que, portanto, se move para cá. Só para escrevê-las em matemática. Se o primeiro cluster atribuiu a ele exemplos de treinamento 1,5,6,10. Só como exemplo. Então, o que isso significa é que você calculará a média dessa maneira.
Reproduza o vídeo começando em :5:56 e siga a transcrição5:56
Observe que x^1, x^5, x^6 e x^10 são exemplos de treinamento. Quatro exemplos de treinamento, então dividimos por 4 e isso fornece a nova localização de Mu1, o novo centróide do cluster 1. Para ser claro, cada um desses valores de x são vetores com dois números neles, ou n números neles se você tiver n características e, portanto, Mu também terá dois números ou n números se você tiver n características em vez de duas. Agora, há um caso extremo desse algoritmo, que é o que acontece se um cluster não tiver nenhum exemplo de treinamento atribuído a ele. Nesse caso, a segunda etapa, Mu k, seria tentar calcular a média de zero pontos. Isso não está bem definido. Se isso acontecer, a coisa mais comum a fazer é simplesmente eliminar esse cluster. Você acaba com K menos 1 agrupamento. Ou se você realmente precisa de K clusters, uma alternativa seria simplesmente reinicializar aleatoriamente esse centróide de cluster e esperar que ele receba pelo menos alguns pontos na próxima vez. Mas, na verdade, é mais comum, ao executar o K-means, simplesmente eliminar um cluster se nenhum ponto for atribuído a ele. Embora eu tenha descrito principalmente K-means para clusters que estão bem separados. Clusters que podem ter essa aparência. Onde se você pedisse a ela para encontrar três grupos, espero que eles encontrem esses três grupos distintos. Acontece que o K-means também é frequentemente aplicado a conjuntos de dados em que os clusters não estão tão bem separados. Por exemplo, se você é designer e fabricante de camisetas legais e quer decidir, como faço para dimensionar minhas camisetas pequenas, médias e grandes. Quão pequena deve ser uma pequena, quão grande deve ser uma grande e o que realmente deve ser uma camiseta de tamanho médio? Uma coisa que você pode fazer é coletar dados de pessoas que provavelmente comprarão suas camisetas com base em suas alturas e pesos. Você descobre que a altura e o peso das pessoas tendem a variar continuamente no espectro, sem alguns grupos muito claros. No entanto, se você executasse K-means com, digamos, três centróides de clusters, você poderia descobrir que K-means agruparia esses pontos em um cluster, esses pontos em um segundo agrupamento e esses pontos em um terceiro cluster. Se você está tentando decidir exatamente como dimensionar suas camisetas pequenas, médias e grandes, escolha as dimensões de sua camiseta pequena para tentar ajustá-la bem a essas pessoas. A camiseta de tamanho médio para tentar caber bem nessas pessoas e a camiseta grande para tentar se encaixar bem nessas pessoas com potencialmente os centróides agrupados, dando uma ideia de qual é a altura e o peso mais representativos que você deseja que seus três tamanhos de camiseta caibam. Este é um exemplo de K-means funcionando perfeitamente e fornecendo resultados úteis, mesmo que os dados não estejam em grupos ou clusters bem separados. Esse foi o algoritmo de agrupamento K-means. Atribua centróides do agrupamento aleatoriamente e, em seguida, atribua pontos repetidamente aos centróides do agrupamento e mova os centróides do agrupamento. Mas o que esse algoritmo realmente está fazendo e fazendo, achamos que esse algoritmo convergirá ou eles continuarão funcionando para sempre e nunca convergirão. Para obter uma intuição mais profunda sobre o algoritmo K-means e também ver por que esperamos que esse algoritmo converja, vamos ao próximo vídeo, onde você verá que o K-means está realmente tentando otimizar uma função de custo específica. Vamos dar uma olhada nisso no próximo vídeo.
