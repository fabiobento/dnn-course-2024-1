{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_dl_intro/4%20-%20Usando%20imagens%20do%20mundo%20real/20%20-%20Atividade%20Avaliativa/C1W4_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvJbBW_oDOwC"
   },
   "source": [
    "# Laboratório Prático: Manuseio de imagens complexas - Conjunto de dados feliz ou triste (_Happy or Sad Dataset_)\n",
    "\n",
    "Nesta tarefa, você usará o conjunto de dados feliz ou triste, que contém 80 imagens de rostos semelhantes a emojis, 40 felizes e 40 tristes.\n",
    "\n",
    "Crie uma rede neural convolucional que seja treinada com 99,9% de acurácia nessas imagens e que cancele o treinamento ao atingir esse limite de acurácia de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NFuMFYXtwsT",
    "outputId": "723d6bc3-c7cd-491b-d6f8-49a2e404a0a2",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar e explorar os dados\n",
    "\n",
    "Comece dando uma olhada em algumas imagens do conjunto de dados.\n",
    "\n",
    "Observe que todas as imagens estão contidas no diretório `./data/`. \n",
    "\n",
    "Esse diretório contém dois subdiretórios `happy/` e `sad/` e cada imagem é salva no subdiretório relacionado à classe a que pertence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/cert_prof_dl_intro/4%20-%20Usando%20imagens%20do%20mundo%20real/20%20-%20Atividade%20Avaliativa/happy_sad.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Descompactar o conjunto de treinamento\n",
    "local_zip = './happy_sad.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./happy-or-sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "uaWTfp5Ox9E-",
    "outputId": "1a4b4b15-9a5f-4fd3-8c56-b32d47ae0893",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import zipfile\n",
    "\n",
    "# Descompactar o conjunto de treinamento\n",
    "local_zip = './happy_sad.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./happy-or-sad')\n",
    "\n",
    "\n",
    "base_dir = \"./happy-or-sad\"\n",
    "happy_dir = os.path.join(base_dir, \"happy/\")\n",
    "sad_dir = os.path.join(base_dir, \"sad/\")\n",
    "\n",
    "print(\"Exemplo de imagem feliz\")\n",
    "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É legal poder ver exemplos das imagens para entender melhor o espaço do problema com o qual você está lidando. \n",
    "\n",
    "No entanto, ainda faltam algumas informações relevantes, como a resolução da imagem (embora o matplotlib renderize as imagens em uma grade, fornecendo uma boa ideia desses valores) e o valor máximo de pixel (isso é importante para normalizar esses valores).\n",
    "\n",
    "Para isso, você pode usar o Keras, conforme mostrado na próxima célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Carregue o primeiro exemplo de um rosto feliz\n",
    "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
    "\n",
    "# Converta a imagem em sua representação de matriz numérica\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Cada imagem tem uma forma: {sample_array.shape}\")\n",
    "\n",
    "print(f\"O valor máximo de pixel usado é: {np.max(sample_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que as imagens têm uma resolução de 150x150.**Isso é muito importante porque esse será o tamanho da entrada da primeira camada da rede.**\n",
    "\n",
    "**A última dimensão refere-se a cada um dos 3 canais RGB usados para representar imagens coloridas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da chamada de retorno\n",
    "\n",
    "Como você já codificou o retorno de chamada responsável por interromper o treinamento (quando um nível desejado de acurácia é atingido) nas duas tarefas anteriores, desta vez ele já foi fornecido para que você possa se concentrar nas outras etapas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0UOFLauzIW4",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
    "            print(\"\\nAtingi 99,9% de acurácia, portanto, estou cancelando o treinamento!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma observação rápida sobre callbacks: \n",
    "\n",
    "Até agora, você usou apenas a callback `on_epoch_end`, mas há muitas outras.\n",
    "\n",
    "Por exemplo, talvez você queira dar uma olhada na chamada de retorno [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), que permite salvar os melhores pesos para o seu modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "O Keras oferece excelente suporte para o pré-processamento de dados de imagem. Muito pode ser feito com o uso da classe `ImageDataGenerator`.\n",
    "\n",
    "Não deixe de consultar o [docs](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) se você ficar preso no próximo exercício.\n",
    "\n",
    "Em particular, talvez você queira prestar atenção ao argumento `rescale` ao instanciar o `ImageDataGenerator` e ao método [`flow_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "rrGO8ObGzqht",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def image_generator():\n",
    "    ### INICIE SEU CÓDIGO AQUI\n",
    "\n",
    "    # Instanciar a classe ImageDataGenerator.\n",
    "    # Lembre-se de definir o argumento rescale.\n",
    "    train_datagen = None\n",
    "\n",
    "    # Especifique o método para carregar imagens de um diretório e passe os argumentos apropriados:\n",
    "    # - directory: deve ser um caminho relativo para o diretório que contém os dados\n",
    "    # targe_size: defina isso como igual à resolução de cada imagem (excluindo a dimensão da cor)\n",
    "    # - batch_size: número de imagens que o gerador produz quando solicitado para um próximo lote. Defina esse valor como 10.\n",
    "    # - class_mode: Como os rótulos são representados. Deve ser uma das opções \"binary\" (binário), \"categorical\" (categórico) ou \"sparse\" (esparso).\n",
    "    # Escolha o que for mais adequado aqui, já que os rótulos serão rótulos binários 1D.\n",
    "    train_generator = train_datagen.flow_from_directory(directory=None,\n",
    "                                                        target_size=(None, None),\n",
    "                                                        batch_size=None,\n",
    "                                                        class_mode=None)\n",
    "    ### TERMINE SEU CÓDIGO AQUI\n",
    "\n",
    "    return train_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9uxJFQb1nOx",
    "outputId": "0c6ce535-7764-4bc0-a4a4-e6289a360b04",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Salve seu gerador em uma variável\n",
    "gen = image_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado esperado:**\n",
    "```\n",
    "Encontradas 80 imagens pertencentes a 2 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação e treinamento do modelo\n",
    "\n",
    "Por fim, conclua a função `train_happy_sad_model` abaixo. Essa função deve retornar sua rede neural.\n",
    "\n",
    "**Seu modelo deve atingir uma acurácia de 99,9% ou mais antes de 15 épocas para ser aprovado nesta tarefa.**\n",
    "\n",
    "**Dicas:**\n",
    "- Você pode tentar qualquer arquitetura para a rede, mas tenha em mente que o modelo funcionará melhor com 3 camadas convolucionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUcNTpra1FK0",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses\n",
    "\n",
    "def train_happy_sad_model(train_generator):\n",
    "\n",
    "    # Instanciar a chamada de retorno\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    ### INICIE O CÓDIGO AQUI\n",
    "\n",
    "    # Definir o modelo\n",
    "    model = tf.keras.models.Sequential([\n",
    "        None,\n",
    "    ])\n",
    "\n",
    "    # Compilar o modelo\n",
    "    # Selecione uma função de perda compatível com a última camada de sua rede\n",
    "    model.compile(loss=losses.None,\n",
    "                  optimizer=optimizers.None,\n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "\n",
    "\n",
    "    # Treine o modelo\n",
    "    # Seu modelo deve atingir a acurácia desejada em menos de 15 épocas.\n",
    "    # Você pode programar até 20 épocas na função abaixo, mas a chamada de retorno deve ser acionada antes de 15.\n",
    "    history = model.fit(x=None,\n",
    "                        epochs=None,\n",
    "                        callbacks=[None]\n",
    "                       ) \n",
    "    \n",
    "    ### TERMINE O CÓDIGO AQUI\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSaPPUe_z_OU",
    "outputId": "b6e6306a-8b28-463b-e1a0-8bdeb9116f26",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "hist = train_happy_sad_model(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a mensagem definida no retorno de chamada for impressa após menos de 15 épocas, isso significa que o retorno de chamada funcionou como esperado e o treinamento foi bem-sucedido.\n",
    "\n",
    "Você também pode fazer uma verificação dupla executando a seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0imravDn0Ajz"
   },
   "outputs": [],
   "source": [
    "print(f\"Seu modelo atingiu a acurácia desejada após {len(hist.epoch)} épocas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a sua chamada de retorno não interrompeu o treinamento, uma das causas pode ser o fato de você ter compilado o modelo usando uma métrica diferente de `accuracy` (como `acc`).\n",
    "\n",
    "Certifique-se de que você definiu a métrica como `accuracy`. Você pode verificar executando a seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"accuracy\" in hist.model.metrics_names:\n",
    "    print(\"Use a \"acurácia\" como métrica ao compilar seu modelo.\")\n",
    "else:\n",
    "    print(\"A métrica foi definida corretamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parabéns!**\n",
    "\n",
    "Você implementou com sucesso uma CNN para ajudá-lo na tarefa de classificação de imagens complexas. Bom trabalho!\n",
    "\n",
    "**Continue assim!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
