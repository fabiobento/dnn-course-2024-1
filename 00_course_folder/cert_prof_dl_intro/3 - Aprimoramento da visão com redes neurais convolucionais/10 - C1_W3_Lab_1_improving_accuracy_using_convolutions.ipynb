{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/dnn-course-2024-1/blob/main/00_course_folder/cert_prof_dl_intro/3%20-%20Aprimoramento%20da%20vis%C3%A3o%20com%20redes%20neurais%20convolucionais/10%20-%20C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptado de [Certificado Profissional Desenvolvedor do TensorFlow para DeepLearning.AI](https://www.coursera.org/professional-certificates/tensorflow-in-practice) de [Laurence Moroney](https://laurencemoroney.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6gHiH-I7uFa"
   },
   "source": [
    "Aprimoramento da Acurácia da Visão Computacional usando Convoluções\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6396DKnr-xp"
   },
   "source": [
    "# Rede neural superficial (_Shallow Neural Network_)\n",
    "\n",
    "Nas lições anteriores, você viu como fazer o reconhecimento de usando uma rede neural com três camadas:\n",
    "* a camada de entrada (no formato dos dados),\n",
    "* a camada de saída (no formato da saída desejada) e\n",
    "* apenas uma camada oculta.\n",
    "\n",
    "Você fez experiências com o impacto de diferentes tamanhos de camada oculta, número de épocas de treinamento etc. na precisão final.\n",
    "\n",
    "Por conveniência, aqui está o código inteiro novamente.\n",
    "\n",
    "Execute-o e anote a acurácia do teste que é impressa no final. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnCNAG-VecJ9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Carregar o conjunto de dados Fashion MNIST\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "# Normalize os valores de pixel\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcsRtq9OLorS"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Defina o modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Configuração dos parâmetros de treinamento\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "print(f'\\nTREINO DO MODELO:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "print(f'\\nAVALIAÇÃO DO MODELO:')\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zldEXSsF8Noz"
   },
   "source": [
    "## Rede Neural Convolucional\n",
    "\n",
    "No modelo acima, a acurácia provavelmente será de cerca de 89% no treinamento e 87% na validação. Nada mal. Mas como tornar isso ainda melhor?\n",
    "> Uma maneira é usar algo chamado _convoluções_.\n",
    "\n",
    "Não entraremos em detalhes sobre as convoluções neste notebook, mas o conceito final é que elas reduzem o conteúdo da imagem para se concentrar em partes específicas, o que provavelmente aumentará a precisão do modelo. \n",
    "\n",
    "Se você já fez o processamento de imagens usando um filtro (como [esse](https://en.wikipedia.org/wiki/Kernel_(image_processing))), então as convoluções lhe parecerão muito familiares.\n",
    "\n",
    "\n",
    "Em resumo, você pega uma matriz (geralmente 3x3 ou 5x5) e a aplica em toda a imagem.\n",
    "\n",
    "Ao alterar os pixels subjacentes com base na fórmula dessa matriz, é possível fazer coisas como a detecção de bordas. \n",
    "\n",
    "Assim, por exemplo, se você olhar o link acima, verá uma matriz 3x3 definida para a detecção de bordas em que a célula do meio é 8 e todas as suas vizinhas são -1. Nesse caso, para cada pixel, você multiplicaria seu valor por 8 e, em seguida, subtrairia o valor de cada vizinho. Faça isso para cada pixel e você terá uma nova imagem com as bordas aprimoradas.\n",
    "\n",
    "Isso é perfeito para a visão computacional porque geralmente destaca as características que distinguem um item de outro. Além disso, a quantidade de informações necessárias é muito menor, pois você treinará apenas com as características destacadas.\n",
    "\n",
    "Esse é o conceito de **Redes Neurais Convolucionais**. Adicione algumas camadas para fazer a convolução antes de ter as camadas densas e, assim, as informações que vão para as camadas densas serão mais concentradas e possivelmente mais precisas.\n",
    "\n",
    "Execute o código abaixo. Essa é a mesma rede neural anterior, mas, desta vez, com as camadas [Convolution](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) e [MaxPooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) adicionadas primeiro. Levará mais tempo, mas observe o impacto na precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0tFgT1MMKi6"
   },
   "outputs": [],
   "source": [
    "# Definir o modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "                                                         \n",
    "  # Adicionar convoluções e pooling máximo\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  # Adicione as mesmas camadas de antes\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Imprimir o resumo do modelo\n",
    "model.summary()\n",
    "\n",
    "# Use as mesmas configurações\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "print(f'\\nTREINAMENTO DE MODELO:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "print(f'\\nAVALIAÇÃO DE MODELO:')\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRLfZ0jt-fQI"
   },
   "source": [
    "É provável que tenha aumentado para cerca de 92% nos dados de treinamento e 90% nos dados de validação. Isso é significativo e é um passo na direção certa!\n",
    "\n",
    "Dê uma olhada no código novamente e veja, passo a passo, como as convoluções foram criadas. Em vez da camada de entrada na parte superior, você adicionou uma camada [Conv2D] (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D). Os parâmetros são:\n",
    "\n",
    "1. O número de convoluções que você deseja gerar. O valor aqui é puramente arbitrário, mas é bom usar potências de 2 a partir de 32.\n",
    "2. O tamanho da convolução. Neste caso, uma grade 3x3.\n",
    "3. A função de ativação a ser usada. Nesse caso, você usou uma ReLU, que, como você deve se lembrar, é equivalente a retornar `x` quando `x>0`, caso contrário, retornar `0`.\n",
    "4. Na primeira camada, a forma dos dados de entrada.\n",
    "\n",
    "Você seguirá a convolução com uma camada [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) projetada para compactar a imagem, mantendo o conteúdo dos recursos que foram destacados pela convolução. Ao especificar `(2,2)` para o MaxPooling, o efeito é reduzir o tamanho da imagem em um quarto. Sem entrar em muitos detalhes aqui, a ideia é criar uma matriz 2x2 de pixels e escolher o maior deles. Assim, ele transforma 4 pixels em 1. Ele repete isso em toda a imagem e, ao fazer isso, reduz pela metade o número de pixels horizontais e verticais, reduzindo efetivamente a imagem a 25% da imagem original.\n",
    "\n",
    "Você pode chamar `model.summary()` para ver o tamanho e a forma da rede e perceberá que, após cada camada máxima de pooling, o tamanho da imagem é reduzido dessa forma. \n",
    "\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMorM6daADjA"
   },
   "source": [
    "Em seguida, você adicionou outra convolução e achatou a saída.\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2)\n",
    "  tf.keras.layers.Flatten(),\n",
    "  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPtqR23uASjX"
   },
   "source": [
    "Depois disso, você terá a mesma estrutura de DNN que a versão não convolucional.\n",
    "\n",
    "A mesma camada densa com 128 neurônios e a camada de saída com 10 neurônios, como no exemplo da pré-convolução:\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np6AjBlLYveu"
   },
   "source": [
    "## Sobre o overfitting\n",
    "\n",
    "Tente executar o treinamento por mais épocas, digamos, cerca de 20, e explore os resultados.\n",
    "\n",
    "Mas, embora os resultados possam parecer muito bons, os resultados da validação podem, na verdade, diminuir, devido a algo chamado _overfitting_.\n",
    "\n",
    "Em resumo, o superajuste ocorre quando a rede aprende muito bem os dados do conjunto de treinamento, mas é muito especializada apenas nesses dados e, como resultado, é menos eficiente na interpretação de outros dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXx_LX3SAlFs"
   },
   "source": [
    "# Visualizando as convoluções e o agrupamento\n",
    "\n",
    "Vamos explorar como mostrar as convoluções graficamente.\n",
    "\n",
    "A célula abaixo imprime os primeiros 100 rótulos no conjunto de teste e você pode ver que os rótulos nos índices `0`, `23` e `28` têm o mesmo valor (ou seja, `9`). Todos eles são sapatos.\n",
    "\n",
    "Vamos dar uma olhada no resultado da execução da convolução em cada um deles, e você começará a ver o surgimento de características comuns entre eles.\n",
    "\n",
    "Agora, quando a camada densa está treinando com esses dados, ela está trabalhando com muito menos e talvez esteja encontrando uma semelhança entre os sapatos com base nessa combinação de convolução/pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-6nX4QsOku6"
   },
   "outputs": [],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FGsHhv6JvDx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "\n",
    "f, axarr = plt.subplots(3,4)\n",
    "\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=23\n",
    "THIRD_IMAGE=28\n",
    "CONVOLUTION_NUMBER = 1\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  \n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  \n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KVPZqgHo5Ux"
   },
   "source": [
    "### EXERCÍCIOS\n",
    "\n",
    "1. Tente editar as convoluções. Altere os 32s para 16 ou 64. Que impacto isso terá na precisão e/ou no tempo de treinamento?\n",
    "\n",
    "2. Remova a convolução final. Que impacto isso terá na precisão ou no tempo de treinamento?\n",
    "\n",
    "3. Que tal adicionar mais convoluções? Que impacto você acha que isso terá? Faça uma experiência com isso.\n",
    "\n",
    "4. Remova todas as convoluções, exceto a primeira. Que impacto você acha que isso terá? Faça uma experiência. \n",
    "\n",
    "5. Na lição anterior, você implementou um retorno de chamada para verificar a função de perda e cancelar o treinamento quando ela atingir um determinado valor. Veja se você pode implementar isso aqui."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/25_august_2021_fixes/C1/W3/ungraded_labs/C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb",
     "timestamp": 1638957936408
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
